{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a216e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "def get_response(prompt, instruction):\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction),\n",
    "    contents=prompt\n",
    ")\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3a491bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Entities\": [\"CHEMDNER corpus\"],\n",
      "  \"Properties\": [\"data format\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"\n",
    "You are an expert in entity recognition and relation extraction. \n",
    "You will be given a question and you need to identify and extract all the entities and properties mentioned in the question. \n",
    "Please provide a list of entities and properties found in the following JSON format. Make sure to use double quotes for both the keys and string values. Make sure to use the raw json output instead of a markdown code block.\n",
    "\n",
    "{\n",
    "  \"Entities\": [\"entity1\", \"entity2\", \"...\"],\n",
    "  \"Properties\": [\"property1\", \"property2\", \"...\"]\n",
    "}\n",
    "\n",
    "If no entities or properties are found, please return empty lists.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"What data format does CHEMDNER corpus have?\"\n",
    "# prompt = \"Where did the study with maximal geographic scale take place?\"\n",
    "\n",
    "response = get_response(prompt, instruction)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0e8e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw LLM output: {\n",
      "  \"Entities\": [\"CHEMDNER corpus\"],\n",
      "  \"Properties\": [\"data format\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What data format does CHEMDNER corpus have?\"\n",
    "response = get_response(prompt, instruction)  # <-- LLM output\n",
    "print(\"Raw LLM output:\", response)\n",
    "# print(\"Is response valid?\", validate_response(response))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5e86e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "\n",
      "        SELECT DISTINCT ?resource ?label\n",
      "        WHERE {\n",
      "        ?resource ?p ?o .\n",
      "        ?resource rdfs:label ?label .\n",
      "        FILTER ( CONTAINS(LCASE(STR(?label)), \"chemdner\") || CONTAINS(LCASE(STR(?label)), \"corpus\") )\n",
      "        }\n",
      "        \n",
      "Your database is not installed properly !!!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_sparql_query_entity(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a SPARQL query that filters resources by requiring all words\n",
    "    in `text` to appear in the label (case-insensitive).\n",
    "    \"\"\"\n",
    "    # Split text into lowercase tokens\n",
    "    tokens = text.lower().split()\n",
    "\n",
    "    # Build FILTER expression: require all tokens (AND logic)\n",
    "    filter_parts = [f'CONTAINS(LCASE(STR(?label)), \"{t}\")' for t in tokens]\n",
    "    # filter_expr = \" && \".join(filter_parts)  # AND: all words must appear\n",
    "    filter_expr = \" || \".join(filter_parts)  # OR logic: any word can appear\n",
    "\n",
    "    query = f\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "        SELECT DISTINCT ?resource ?label\n",
    "        WHERE {{\n",
    "        ?resource ?p ?o .\n",
    "        ?resource rdfs:label ?label .\n",
    "        FILTER ( {filter_expr} )\n",
    "        }}\n",
    "        \"\"\"\n",
    "    return query\n",
    "\n",
    "query = build_sparql_query_entity(\"CHEMDNER corpus\")\n",
    "print(f\"query: {query}\")\n",
    "\n",
    "from helper import run_sparql_query\n",
    "results = run_sparql_query(sparql_text = query, SPARQLPATH=\"http://localhost:8890/sparql\")\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c632618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "\n",
      "        SELECT DISTINCT ?p ?label\n",
      "        WHERE {\n",
      "        ?s ?p ?o .\n",
      "        ?p rdfs:label ?label .\n",
      "        FILTER ( CONTAINS(LCASE(STR(?label)), \"maximal\") || CONTAINS(LCASE(STR(?label)), \"geographic\") || CONTAINS(LCASE(STR(?label)), \"scale\") )\n",
      "        }\n",
      "        \n",
      "Your database is not installed properly !!!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_sparql_query_properties(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a SPARQL query that filters resources by requiring all words\n",
    "    in `text` to appear in the label (case-insensitive).\n",
    "    \"\"\"\n",
    "    # Split text into lowercase tokens\n",
    "    tokens = text.lower().split()\n",
    "\n",
    "    # Build FILTER expression: require all tokens (AND logic)\n",
    "    filter_parts = [f'CONTAINS(LCASE(STR(?label)), \"{t}\")' for t in tokens]\n",
    "    # filter_expr = \" && \".join(filter_parts)  # AND: all words must appear\n",
    "    filter_expr = \" || \".join(filter_parts)  # OR logic: any word can appear\n",
    "\n",
    "    query = f\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "        SELECT DISTINCT ?p ?label\n",
    "        WHERE {{\n",
    "        ?s ?p ?o .\n",
    "        ?p rdfs:label ?label .\n",
    "        FILTER ( {filter_expr} )\n",
    "        }}\n",
    "        \"\"\"\n",
    "    return query\n",
    "\n",
    "# query = build_sparql_query(\"CHEMDNER corpus\")\n",
    "query = build_sparql_query_properties(\"maximal geographic scale\")\n",
    "print(f\"query: {query}\")\n",
    "\n",
    "from helper import run_sparql_query\n",
    "results = run_sparql_query(sparql_text = query, SPARQLPATH=\"http://localhost:8890/sparql\")\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be214e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  p               label\n",
      "0     http://www.w3.org/2002/07/owl#equivalentClass     equivalentClass\n",
      "1  http://www.w3.org/2002/07/owl#equivalentProperty  equivalentProperty\n",
      "2        http://www.w3.org/2002/07/owl#complementOf        complementOf\n",
      "3             http://www.w3.org/2002/07/owl#unionOf             unionOf\n",
      "4             http://www.w3.org/2002/07/owl#imports             imports\n"
     ]
    }
   ],
   "source": [
    "# read a csv file with columns: \"p\",\"label\" into a pandas dataframe\n",
    "import pandas as pd\n",
    "property_df = pd.read_csv(\"/Users/sherrypan/GitHub/GAR_SKGQA/datasets/sciqa/project_data/property-labels.csv\")\n",
    "print(property_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc03825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_ls = property_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6412008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6892"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(property_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10145597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## entity embedding \n",
    "# Requires transformers>=4.51.0\n",
    "# Requires sentence-transformers>=2.7.0\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525ee5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start encoding candidate properties...\n",
      "Finish encoding candidate properties...\n",
      "Time taken to encode 6892 candidate properties: 19.817121028900146 seconds\n"
     ]
    }
   ],
   "source": [
    "candidate_properties = property_ls\n",
    "print(\"Start encoding candidate properties...\")\n",
    "start = time.time()\n",
    "candidate_embeddings = model.encode(candidate_properties)\n",
    "print(\"Finish encoding candidate properties...\")\n",
    "end = time.time()\n",
    "print(f\"Time taken to encode {len(candidate_properties)} candidate properties: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35ffb2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/jr1wz_ts529fv9vg79f26xth0000gp/T/ipykernel_2248/2098080840.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  similarity = torch.tensor(similarity)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_property</th>\n",
       "      <th>candidate_property</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maximal geographic scale</td>\n",
       "      <td>Geographic scale (Km²)</td>\n",
       "      <td>0.5569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maximal geographic scale</td>\n",
       "      <td>Geographical scope</td>\n",
       "      <td>0.5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maximal geographic scale</td>\n",
       "      <td>geographical coverage</td>\n",
       "      <td>0.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maximal geographic scale</td>\n",
       "      <td>Scale factor</td>\n",
       "      <td>0.4757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maximal geographic scale</td>\n",
       "      <td>Scale economies evaluated  in the approximatio...</td>\n",
       "      <td>0.4730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data format</td>\n",
       "      <td>Data formats</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data format</td>\n",
       "      <td>Data format</td>\n",
       "      <td>0.6402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data format</td>\n",
       "      <td>text data format</td>\n",
       "      <td>0.5891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data format</td>\n",
       "      <td>dataset format</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data format</td>\n",
       "      <td>file format</td>\n",
       "      <td>0.5095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source_property  \\\n",
       "0  maximal geographic scale   \n",
       "1  maximal geographic scale   \n",
       "2  maximal geographic scale   \n",
       "3  maximal geographic scale   \n",
       "4  maximal geographic scale   \n",
       "5               data format   \n",
       "6               data format   \n",
       "7               data format   \n",
       "8               data format   \n",
       "9               data format   \n",
       "\n",
       "                                  candidate_property similarity_score  \n",
       "0                             Geographic scale (Km²)           0.5569  \n",
       "1                                 Geographical scope           0.5455  \n",
       "2                              geographical coverage           0.4905  \n",
       "3                                       Scale factor           0.4757  \n",
       "4  Scale economies evaluated  in the approximatio...           0.4730  \n",
       "5                                       Data formats           0.6974  \n",
       "6                                        Data format           0.6402  \n",
       "7                                   text data format           0.5891  \n",
       "8                                     dataset format           0.5265  \n",
       "9                                        file format           0.5095  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_properties = [\n",
    "    \"maximal geographic scale\",\n",
    "    \"data format\"\n",
    "]\n",
    "source_embeddings = model.encode(source_properties, prompt_name=\"query\")\n",
    "# Compute the (cosine) similarity between the source and candidates embeddings\n",
    "similarity = model.similarity(source_embeddings, candidate_embeddings)\n",
    "\n",
    "# print the top 5 most similar candidate properties for each source property\n",
    "import torch\n",
    "similarity = torch.tensor(similarity)\n",
    "top_k = 5\n",
    "values, indices = torch.topk(similarity, k=top_k, dim=1)\n",
    "top_candidates = []\n",
    "top_scores = []\n",
    "top_sources = []\n",
    "for i, source_property in enumerate(source_properties):\n",
    "    # print(f\"Source property: {source_property}\")\n",
    "    for j in range(top_k):\n",
    "        candidate_property = candidate_properties[indices[i][j]]\n",
    "        sim_score = values[i][j].item()\n",
    "        # print(f\"  Candidate property: {candidate_property}, similarity score: {sim_score:.4f}\")\n",
    "        top_candidates.append(candidate_property)\n",
    "        top_scores.append(f\"{sim_score:.4f}\")\n",
    "        top_sources.append(source_property)\n",
    "top_df = pd.DataFrame({\n",
    "    \"source_property\": top_sources,\n",
    "    \"candidate_property\": top_candidates,\n",
    "    \"similarity_score\": top_scores\n",
    "})\n",
    "top_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e64d6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing valid output: {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
      "Validation successful!\n",
      "--------------------\n",
      "Testing invalid format output: This is not JSON.\n",
      "Validation failed with error: Expecting value: line 1 column 1 (char 0)\n",
      "--------------------\n",
      "Testing invalid schema output (missing key): {\"name\": \"Bob\", \"age\": 25}\n",
      "Validation failed with error: 1 validation error for User\n",
      "city\n",
      "  Field required [type=missing, input_value={'name': 'Bob', 'age': 25}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "--------------------\n",
      "Testing invalid schema output (wrong data type): {\"name\": \"Charlie\", \"age\": \"35\", \"city\": \"London\"}\n",
      "Validation successful!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "# Define a Pydantic model for the expected JSON structure\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    city: str\n",
    "\n",
    "def validate_llm_output_with_pydantic(llm_output):\n",
    "    \"\"\"\n",
    "    Checks if a string is valid JSON and conforms to the Pydantic schema.\n",
    "\n",
    "    Args:\n",
    "        llm_output (str): The string to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if validation is successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First, parse the string as JSON\n",
    "        data = json.loads(llm_output)\n",
    "\n",
    "        # Then, validate the parsed data against the Pydantic model\n",
    "        _ = User(**data)\n",
    "\n",
    "        # If both steps succeed, the output is valid\n",
    "        print(\"Validation successful!\")\n",
    "        return True\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        # Catch errors from both json.loads() and Pydantic validation\n",
    "        print(f\"Validation failed with error: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Example 1: Valid JSON that matches the schema\n",
    "valid_output = '{\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}'\n",
    "print(f\"Testing valid output: {valid_output}\")\n",
    "validate_llm_output_with_pydantic(valid_output)\n",
    "# Expected output: Validation successful!\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Example 2: Invalid JSON format\n",
    "invalid_format_output = 'This is not JSON.'\n",
    "print(f\"Testing invalid format output: {invalid_format_output}\")\n",
    "validate_llm_output_with_pydantic(invalid_format_output)\n",
    "# Expected output: Validation failed with error: JSONDecodeError\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Example 3: Valid JSON, but fails Pydantic schema (missing a key)\n",
    "invalid_schema_output_1 = '{\"name\": \"Bob\", \"age\": 25}'\n",
    "print(f\"Testing invalid schema output (missing key): {invalid_schema_output_1}\")\n",
    "validate_llm_output_with_pydantic(invalid_schema_output_1)\n",
    "# Expected output: Validation failed with error: ValidationError\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Example 4: Valid JSON, but fails Pydantic schema (wrong data type)\n",
    "invalid_schema_output_2 = '{\"name\": \"Charlie\", \"age\": \"35\", \"city\": \"London\"}'\n",
    "print(f\"Testing invalid schema output (wrong data type): {invalid_schema_output_2}\")\n",
    "validate_llm_output_with_pydantic(invalid_schema_output_2)\n",
    "# Expected output: Validation failed with error: ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: {\"Entities\": [\"entity1\", \"entity2\"], \"Properties\": [\"property1\"]}\n",
      "✅ Validation successful!\n",
      "\n",
      "Validating: {\"Entities\": [], \"Properties\": []}\n",
      "✅ Validation successful!\n",
      "\n",
      "Validating: {\"Entities\": [\"entity1\"]}\n",
      "❌ Validation failed: 1 validation error for EntityProperty\n",
      "Properties\n",
      "  Field required [type=missing, input_value={'Entities': ['entity1']}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "\n",
      "Validating: {\"Entities\": [123, \"entity2\"], \"Properties\": [\"property1\"]}\n",
      "❌ Validation failed: 1 validation error for EntityProperty\n",
      "Entities.0\n",
      "  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, ValidationError, conlist\n",
    "\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# 1. Valid output with content\n",
    "valid_output = '{\"Entities\": [\"entity1\", \"entity2\"], \"Properties\": [\"property1\"]}'\n",
    "print(f\"Validating: {valid_output}\")\n",
    "validate_llm_output_with_pydantic(valid_output)\n",
    "\n",
    "# 2. Valid output with empty lists\n",
    "valid_output_empty = '{\"Entities\": [], \"Properties\": []}'\n",
    "print(f\"\\nValidating: {valid_output_empty}\")\n",
    "validate_llm_output_with_pydantic(valid_output_empty)\n",
    "\n",
    "# 3. Invalid output (missing a key)\n",
    "invalid_output_missing_key = '{\"Entities\": [\"entity1\"]}'\n",
    "print(f\"\\nValidating: {invalid_output_missing_key}\")\n",
    "validate_llm_output_with_pydantic(invalid_output_missing_key)\n",
    "\n",
    "# 4. Invalid output (wrong data type for a list item)\n",
    "invalid_output_wrong_type = '{\"Entities\": [123, \"entity2\"], \"Properties\": [\"property1\"]}'\n",
    "print(f\"\\nValidating: {invalid_output_wrong_type}\")\n",
    "validate_llm_output_with_pydantic(invalid_output_wrong_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1532935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your database is not installed properly !!!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query =\"\"\"\"\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX orkgp: <http://orkg.org/orkg/predicate/>\n",
    "PREFIX orkgr: <http://orkg.org/orkg/resource/>\n",
    "PREFIX orkgc: <http://orkg.org/orkg/class/>\n",
    "\n",
    "SELECT ?s_class ?o_class (COUNT(*) AS ?pairCount)\n",
    "WHERE {\n",
    "  ?s orkgp:HAS_BENCHMARK ?o .\n",
    "  ?s a ?s_class .\n",
    "  ?o a ?o_class .\n",
    "}\n",
    "GROUP BY ?s_class ?o_class\n",
    "ORDER BY DESC(?pairCount)\n",
    "\n",
    "\"\"\"\n",
    "from helper import run_sparql_query\n",
    "results = run_sparql_query(sparql_text = query, SPARQLPATH=\"http://localhost:7200/sparql\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e0df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
