question_id,question_string,gold_sparql,generated_sparql,Exact_Match,Precision,Recall,F1,BLEU_Cumulative,BLEU_4,ROUGE_1,ROUGE_2,ROUGE_L
AQ1475,Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Story Cloze Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?score
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R119651 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Accuracy"" .
    ?eval orkgp:HAS_VALUE ?score .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.9215686274509803,0.6911764705882353,0.7899159663865546,0.49266605826095056,0.3433379196499407,0.7755101991003749,0.6578947319286704,0.5714285664473138
AQ0495,List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Word Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R120926 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?paper orkgp:P31 ?contribution .
    ?paper a orkgc:Paper .
    ?paper rdfs:label ?paper_label .
}",0,0.8888888888888888,0.6857142857142857,0.7741935483870968,0.49565179469709636,0.3408015779693737,0.7272727223140496,0.6666666617447917,0.6666666617079889
AQ0176,What models are being evaluated on the UrbanSound8k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UrbanSound8k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?dataset rdfs:label ""UrbanSound8k"" .
  ?evaluation orkgp:HAS_DATASET ?dataset .
  ?evaluation orkgp:USES_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.9565217391304348,0.5641025641025641,0.7096774193548387,0.3408022157135539,0.22443708184303257,0.7586206848038051,0.6222222175209877,0.7586206848038051
AQ0392,Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""Penn Treebank"" .
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.6666666666666666,0.8,0.5183253397522881,0.4469173282093088,0.8571428522448981,0.761904757086168,0.8571428522448981
AQ1059,What is the top benchmark score and its metric on the MAZEA dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MAZEA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_label
WHERE {
  ?dataset rdfs:label ""MAZEA""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_VALUE ?score .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(xsd:double(?score))
LIMIT 1",0,0.8571428571428571,0.5070422535211268,0.6371681415929203,0.3445121317646572,0.257096041116867,0.6666666617283951,0.5405405357742878,0.6666666617283951
AQ0021,What models are being evaluated on the TDMSci dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TDMSci"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R203385 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METHOD ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.88,0.5641025641025641,0.6875,0.3943525966528814,0.28560453192440743,0.6666666617555557,0.5652173865406428,0.6666666617555557
HQ0038,What is the mean capacity of a carbon-based fuel?,"SELECT (AVG(?numerical_capacity) AS ?mean) 
WHERE {
  ?paper a orkgc:Paper;
         orkgp:P31 [
           orkgp:P15483 ?capacity
         ];
         rdfs:label ?title.
  BIND(
    xsd:double(
      REPLACE(
        STR(
          REPLACE(
            ?capacity,
            ""([0-9]+),([0-9]+)"",
            ""$1$2""
          )
        ),
        ""([0-9]+).*"",
        ""$1""
      ) 
    ) AS ?numerical_capacity
  )
  FILTER(REGEX(STR(?title), ""(fuel|CO2)""))
}","SELECT (AVG(xsd:float(?value)) AS ?mean_capacity)
WHERE {
    ?statement ?p orkgr:R9184 .
    ?capacity_prop rdfs:label ""Capacity (MWth)"" .
    ?statement ?capacity_prop ?capacity_node .
    ?capacity_node orkgp:HAS_VALUE ?value .
}",0,0.64,0.3902439024390244,0.48484848484848486,0.12290034221896493,0.04793567491300442,0.43902438548483047,0.24561403043397972,0.3414634098750744
AQ0566,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Russian dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Russian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
    ?benchmark rdfs:label ""Benchmark MLDoc Zero-Shot English-to-Russian"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?paper orkgp:P31 ?contribution .
    ?paper rdfs:label ?title .
}",0,0.9642857142857143,0.7297297297297297,0.8307692307692307,0.5769772699468826,0.46407195003016444,0.8888888839506174,0.7843137205843906,0.8888888839506174
AQ1807,Indicate the model that performed best in terms of Accuracy metric on the Kuzushiji-MNIST benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Kuzushiji-MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a           orkgc:Metric ;
              rdfs:label  ?metric_lbl .
  FILTER(str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset    a                 orkgc:Dataset ;
                  rdfs:label        ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""Kuzushiji-MNIST"")
      ?benchmark  orkgp:HAS_DATASET     ?dataset ;
                  orkgp:HAS_EVALUATION  ?eval .
      ?eval       orkgp:HAS_VALUE       ?value ;
                  orkgp:HAS_METRIC      ?metric .
      ?cont       orkgp:HAS_BENCHMARK   ?benchmark ;
                  orkgp:HAS_MODEL       ?model .
      ?model      rdfs:label            ?model_lbl .
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1437,Which model has achieved the highest BLEU score score on the WMT2016 Romanian-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 Romanian-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label
WHERE {
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ""WMT2016 Romanian-English"" .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC orkgr:R76072 .
  ?evaluation orkgp:HAS_VALUE ?score .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.9230769230769231,0.6956521739130435,0.7933884297520661,0.4974896115638146,0.3384939163719674,0.8076923026997042,0.7088607545585645,0.6153846103920119
AQ1221,"What is the highest benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
  ?dataset rdfs:label ""Ball in cup, catch (DMControl500k)""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?eval orkgp:P32 ?value .
}
ORDER BY DESC(xsd:double(?value))
LIMIT 1",0,0.8444444444444444,0.5066666666666667,0.6333333333333333,0.3355056447274376,0.24448434239647238,0.6792452780633679,0.5365853610440215,0.6792452780633679
AQ1803,What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the VTAB-1k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 accuracy %"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0573,What are the titles and IDs of research papers that include a benchmark for the arXiv dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""arXiv"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ?dataset_label .
  FILTER(CONTAINS(LCASE(?dataset_label), ""arxiv""))
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:hasContribution ?contribution .
  ?paper rdfs:label ?title .
}",0,0.875,0.875,0.875,0.6746134509480305,0.4827586206896552,0.7999999950000002,0.7391304297920607,0.7333333283333333
AQ0698,Can you list the metrics used to evaluate models on the TDM Tagged Corpus dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TDM Tagged Corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
    ?dataset rdfs:label ""TDM Tagged Corpus"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}",0,1.0,0.8055555555555556,0.8923076923076924,0.580210358667772,0.3927718025274604,0.8749999950781251,0.7916666618055557,0.8749999950781251
AQ0530,Provide a list of research paper titles and IDs that have benchmarked models on the BC5CDR-disease dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R122954 .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper rdfs:label ?paper_title .
}",0,0.9,0.5454545454545454,0.679245283018868,0.36454257855295086,0.24566860082871342,0.7142857093877552,0.6341463367043427,0.7142857093877552
AQ1634,What is the name of the top performing model in terms of Score score when benchmarked on the Lunar Lander (OpenAI Gym) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Lunar Lander (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET <http://orkg.org/orkg/resource/R123333> .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Score"" .
    ?evaluation orkgp:HAS_VALUE ?score .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:float(?score))
LIMIT 1",0,0.8518518518518519,0.6666666666666666,0.7479674796747967,0.4844161180573787,0.3416019206496123,0.7169811270772517,0.617283945654626,0.6037735799074405
AQ0727,What evaluation metrics are commonly used when benchmarking models on the FSNS - Test dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FSNS - Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R114163 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.92,0.6571428571428571,0.7666666666666667,0.49229058557610617,0.3656291160194396,0.7333333284222223,0.6666666618666668,0.7333333284222223
AQ0435,What are the titles and IDs of research papers that include a benchmark for the ImageNet 64x64 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R117685 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.6363636363636364,0.75,0.5117824842351163,0.4208135048545422,0.7586206847086802,0.6976744137371553,0.7586206847086802
AQ0999,"What are the metrics of evaluation over the Classical music, 5 seconds at 12 kHz dataset?","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R126023 .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.9166666666666666,0.55,0.6874999999999999,0.3505749554170272,0.22003590815682514,0.6285714239020408,0.599999995392,0.6285714239020408
AQ1967,Provide a list of papers that have utilized the Flair-TDM model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Flair-TDM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?model rdfs:label ""Flair-TDM"" .
  ?contribution orkgp:P1004 ?model .
  ?contribution orkgp:P31 ?paper .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9166666666666666,0.6285714285714286,0.7457627118644068,0.3241016679584158,0.1505563481395833,0.7499999950781251,0.5652173864555766,0.7499999950781251
AQ2193,Can you provide links to code used in papers that benchmark the Transformer-XL Base model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Transformer-XL Base"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R121009 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5277777777777778,0.6666666666666666,0.3755360357665399,0.299164347507027,0.6451612855775234,0.5909090862809917,0.5806451565452655
AQ1743,What is the best performing model benchmarking the BUCC German-to-English dataset in terms of F1 score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric;
          rdfs:label ?metric_lbl.
  FILTER(str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset;
               rdfs:label ?dataset_lbl.
      FILTER(str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark orkgp:HAS_DATASET ?dataset;
                 orkgp:HAS_EVALUATION ?eval.
      ?eval orkgp:HAS_VALUE ?value;
            orkgp:HAS_METRIC ?metric.
      ?contribution orkgp:HAS_BENCHMARK ?benchmark;
                    orkgp:HAS_MODEL ?model.
      ?model rdfs:label ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2064,Provide a list of papers that have utilized the SAN (single) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SAN (single)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ""SAN (single model)"" .
  ?paper orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.6285714285714286,0.7719298245614035,0.33114695247391107,0.17489165678866064,0.8387096725494276,0.6363636316219009,0.8387096725494276
AQ0059,What are the models that have been benchmarked on the ACE 2005 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ACE 2005"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R116636 .
  ?benchmark orkgp:USES_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.85,0.425,0.5666666666666667,0.22633306860350966,0.15147976989412332,0.6451612854526535,0.5217391257750473,0.6451612854526535
AQ1993,Where can I find code references in papers that have used the PNDec model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PNDec"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model a orkgc:Model;
         rdfs:label ""PNDec"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7647058823529411,0.8666666666666666,0.6619526382809374,0.5753281152456662,0.9032258014984391,0.8260869516068055,0.9032258014984391
AQ1956,Where can I find code references in papers that have used the CATTS-XSUM model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CATTS-XSUM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R225027 .
  ?contribution orkgp:has benchmark ?benchmark .
  ?contribution orkgp:has source code ?code .
}",0,0.9047619047619048,0.5428571428571428,0.6785714285714285,0.393851321562034,0.3137549060754729,0.6666666618666668,0.6046511581179016,0.5999999952
AQ1369,What is the top benchmark result (metric and value) over the dataset IMDb-B?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IMDb-B"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                     rdfs:label       ""IMDb-B"".
      ?benchmark     orkgp:HAS_DATASET    ?dataset;
                     orkgp:HAS_EVALUATION ?eval.
      ?eval          orkgp:HAS_VALUE      ?value;
                     orkgp:HAS_METRIC     ?metric.
      ?metric        rdfs:label           ?metric_lbl.
      ?contribution  orkgp:HAS_BENCHMARK  ?benchmark.
    }
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.7222222222222222,0.8387096774193548,0.638298578564367,0.5834677699914731,0.8695652124763706,0.8395061679317178,0.8695652124763706
AQ1250,What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot German-to-French?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot German-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot German-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2249,Where can I find code references in papers that have used the SemExp model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SemExp"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model rdfs:label ""SemExp""^^xsd:string .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9230769230769231,0.7058823529411765,0.8000000000000002,0.5339295571979469,0.4155147498996477,0.8124999950195313,0.6521739081285445,0.7499999950195314
AQ0952,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Up and Down dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Up and Down"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124992 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}",0,0.9166666666666666,0.5789473684210527,0.7096774193548387,0.3810413387034912,0.23915791961573446,0.6666666618916438,0.6249999953125001,0.6666666618916438
AQ1537,What is the name of the top performing model in terms of Number of params score when benchmarked on the Penn Treebank (Character Level) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""Penn Treebank (Character Level)"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
            orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.9726027397260274,1.0,0.9861111111111112,0.9286129192461133,0.8714285714285714,0.9666666616722221,0.9574468035129019,0.933333328338889
AQ0500,Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank (Character Level) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R121031 .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?paper_title .
}",0,0.85,0.4857142857142857,0.6181818181818183,0.2602257389809393,0.13893133904147492,0.6874999950781251,0.5777777729777778,0.6249999950781252
AQ0924,What are the metrics of evaluation over the Atari 2600 Double Dunk dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Double Dunk"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
    VALUES ?dataset { orkgr:R124933 }
    ?contribution orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}",0,0.8888888888888888,0.6486486486486487,0.75,0.43638560840689106,0.28769939603212885,0.666666661781451,0.6122448931278636,0.666666661781451
AQ1806,Which model has achieved the highest Top 1 Accuracy score on the ImageNet V2 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top 1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet V2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R126096 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ""Top 1 Accuracy""^^xsd:string .
  ?evaluation orkgp:HAS_VALUE ?score .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.8888888888888888,0.6956521739130435,0.7804878048780488,0.4844618975899086,0.31189740581051556,0.7843137204921184,0.6666666617040086,0.5490196028450597
HQ0003,What is the most common Knowledge representation method?,"SELECT (COUNT(?repr) AS ?cnt) ?repr
WHERE {
  orkgr:R8364 orkgp:compareContribution ?cont.
  ?cont orkgp:P7046 ?sys.
  ?sys orkgp:P7056 ?repr.
}
GROUP BY ?repr
ORDER BY DESC(?cnt)
LIMIT 1","SELECT ?method_label (COUNT(?contribution) AS ?count)
WHERE {
  ?contribution orkgp:P30 ?field .
  ?field rdfs:label ""Knowledge representation"" .
  ?contribution orkgp:P31 ?method .
  ?method rdfs:label ?method_label .
}
GROUP BY ?method_label
ORDER BY DESC(?count)
LIMIT 1",0,0.696969696969697,0.7931034482758621,0.7419354838709677,0.4224545280312378,0.26666666666666666,0.6857142807183674,0.5660377308650766,0.6285714235755103
HQ0057,Where can all the data sets used in the compared studies be found?,"SELECT DISTINCT ?URL
WHERE {
  orkgr:R112387 orkgp:compareContribution ?contrib.
  ?contrib orkgp:HAS_DATASET ?URL.
  FILTER(!REGEX(?URL, ""Not""))
}","SELECT DISTINCT ?dataset_label ?url
WHERE {
  ?comparison a orkgc:Comparison .
  ?comparison orkgp:hasContribution ?contribution .
  ?contribution orkgp:P33 ?dataset .
  ?dataset a orkgc:Dataset .
  ?dataset rdfs:label ?dataset_label .
  ?dataset orkgp:hasURL ?url .
}",0,0.4074074074074074,0.6111111111111112,0.4888888888888889,0.07482063542275094,0.0041666666666666675,0.4615384565384616,0.3243243193571951,0.4615384565384616
AQ1891,What are the most commonly used benchmark datasets for the Entity Disambiguation research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Entity Disambiguation"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT ?dataset ?dataset_label (COUNT(?contribution) AS ?count)
WHERE {
  VALUES ?problem { orkgr:R128532 } .
  ?contribution orkgp:P32 ?problem .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ?dataset_label .
}
GROUP BY ?dataset ?dataset_label
ORDER BY DESC(?count)",0,0.631578947368421,0.6857142857142857,0.6575342465753424,0.38560608853121286,0.22857142857142856,0.5555555505709877,0.4285714235969388,0.3333333283487655
AQ0503,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the BIOSSES dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BIOSSES"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""BIOSSES"" .
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,1.0,0.6875,0.8148148148148148,0.4939253029841925,0.367478979386479,0.8461538412721893,0.7499999952,0.7692307643491124
AQ1745,Which model has achieved the highest F1 score score on the BUCC Chinese-to-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC Chinese-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""F1 score"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?benchmark rdfs:label ""Benchmark BUCC Chinese-to-English""^^xsd:string .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
        orkgp:HAS_VALUE ?value .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9152542372881356,0.7714285714285715,0.8372093023255813,0.5864310477197017,0.42977367816017165,0.8727272677289256,0.7294117597231834,0.690909085910744
AQ0661,Provide a list of research paper titles and IDs that have benchmarked models on the ImageNet ReaL dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R126249 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?title .
}",0,0.88,0.6666666666666666,0.7586206896551725,0.48114547232153887,0.3300677441244049,0.7741935433922998,0.6666666617283951,0.7096774143600416
AQ0550,What are the titles and IDs of research papers that include a benchmark for the Gibson PointGoal Navigation dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R123480 .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper a orkgc:Paper .
  ?paper rdfs:label ?paper_title .
}",0,0.8695652173913043,0.5882352941176471,0.7017543859649124,0.3880444971970637,0.24794418926254858,0.709677414401665,0.6222222173432099,0.645161285369407
AQ1214,What is the top benchmark result (metric and value) over the dataset CoNLL++?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL++"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label (MAX(?value) as ?score)
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R122914 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
    ?evaluation orkgp:HAS_VALUE ?value .
}
GROUP BY ?metric_label
ORDER BY DESC(?score)",0,0.9487179487179487,0.5211267605633803,0.6727272727272727,0.3580276790673386,0.28124262640333236,0.772727267820248,0.7199999952000001,0.6818181769111571
AQ1498,What is the best performing model benchmarking the PIQA dataset in terms of Accuracy metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PIQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label (SAMPLE(?value_label) AS ?accuracy)
WHERE {
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""PIQA""^^xsd:string .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Accuracy""^^xsd:string .
    ?evaluation orkgp:REFERS_TO ?model .
    ?model rdfs:label ?model_label .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?value rdfs:label ?value_label .
}
GROUP BY ?model_label
ORDER BY DESC(xsd:decimal(?accuracy))
LIMIT 1",0,0.7777777777777778,0.7424242424242424,0.7596899224806201,0.4448600748557586,0.2542658546222604,0.7199999950079999,0.5365853608536587,0.5199999950080001
AQ1692,Indicate the model that performed best in terms of Score metric on the Atari 2600 Crazy Climber benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Crazy Climber"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Crazy Climber"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.971830985915493,1.0,0.9857142857142858,0.9492177523638845,0.9264705882352942,0.9642857092920919,0.9555555505580249,0.9642857092920919
AQ1997,Provide a list of papers that have utilized the Table-Sequence model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Table-Sequence"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R116615 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution .
  ?paper a orkgc:Paper .
}",0,0.8333333333333334,0.5714285714285714,0.6779661016949152,0.29151856595833514,0.12044507851166664,0.6249999950781252,0.5333333285333334,0.37499999507812504
AQ1920,Provide a list of papers that have utilized the Funnel Transformer model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Funnel Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_label ?code WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R216297 .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?paper orkgp:P31 ?contribution .
    ?paper a orkgc:Paper .
    ?paper rdfs:label ?paper_label .
}",0,0.8571428571428571,0.6857142857142857,0.7619047619047619,0.33725121737907987,0.12460812529142476,0.7058823479584776,0.5714285664806331,0.41176470089965406
AQ0991,What evaluation metrics are commonly used when benchmarking models on the Reuters De-En dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters De-En"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
    ?dataset rdfs:label ""Reuters De-En"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8055555555555556,0.8923076923076924,0.580210358667772,0.3927718025274604,0.8749999950781251,0.7916666618055557,0.8749999950781251
AQ1587,Indicate the model that performed best in terms of F1 metric on the PubMed 20k RCT benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2008,List the code links in papers that use the DocRED-BiLSTM model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DocRED-BiLSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R116669 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5428571428571428,0.6785714285714285,0.393851321562034,0.3137549060754729,0.6666666618666668,0.6046511581179016,0.5999999952
AQ1656,What is the best performing model benchmarking the Oxford-IIIT Pets dataset in terms of FLOPS metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
    ?metric rdfs:label ""FLOPS"" .
    {
        SELECT ?model ?model_lbl
        WHERE {
            ?benchmark rdfs:label ""Benchmark Oxford-IIIT Pets"" .
            ?contribution orkgp:HAS_BENCHMARK ?benchmark .
            ?contribution orkgp:HAS_MODEL ?model .
            ?model rdfs:label ?model_lbl .
            ?benchmark orkgp:HAS_EVALUATION ?evaluation .
            ?evaluation orkgp:HAS_METRIC ?metric .
            ?evaluation orkgp:HAS_VALUE ?value .
        }
        ORDER BY ASC(xsd:float(?value))
        LIMIT 1
    }
}",0,0.9298245614035088,0.7794117647058824,0.8479999999999999,0.5902434436726971,0.4427851245740526,0.8399999950080002,0.73417721022913,0.6799999950080001
AQ1262,What is the top benchmark result (metric and value) over the dataset AESLC?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AESLC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
  ?dataset rdfs:label ""AESLC""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:P32 ?value .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.8333333333333334,0.49295774647887325,0.6194690265486726,0.3179713379363381,0.23138643700518033,0.6521739080812855,0.5066666618666666,0.6086956472117204
AQ0554,What are the titles and IDs of research papers that include a benchmark for the Oxford-IIIT Pets dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT ?paper ?title
WHERE {
  ?benchmark rdfs:label ""Benchmark Oxford-IIIT Pets"" .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper rdfs:label ?title .
}",0,0.95,0.5588235294117647,0.7037037037037037,0.33841491066177637,0.23368720178419272,0.7857142809438777,0.6190476143310658,0.7857142809438777
AQ1333,What is the top benchmark score and its metric on the WOS-46985 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-46985"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_label
WHERE {
    ?dataset rdfs:label ""WOS-46985""^^xsd:string .
    ?dataset a orkgc:Dataset .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_VALUE ?score .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(?score)
LIMIT 1",0,0.9183673469387755,0.625,0.7438016528925621,0.4543741690367925,0.3262878469021026,0.7499999950347224,0.666666661827745,0.541666661701389
AQ2273,Provide a list of papers that have utilized the AcrE model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AcrE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code WHERE {
    ?paper a orkgc:Paper .
    ?paper orkgp:P31 ?contribution .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ""AcrE"" .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9259259259259259,0.7352941176470589,0.819672131147541,0.4426130906068945,0.2572076489051369,0.8124999950195313,0.6382978673970123,0.5624999950195313
AQ1503,What is the best performing model benchmarking the Supervised: dataset in terms of SemEval 2013 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SemEval 2013"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R32036 }
  ?metric rdfs:label ""SemEval 2013"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?evaluation orkgp:HAS_VALUE ?value .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.9107142857142857,0.7611940298507462,0.8292682926829267,0.5357783610192803,0.37207246152480167,0.8235294067666282,0.6835442988174972,0.5882352891195695
AQ0361,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciERC dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  VALUES ?dataset { orkgr:R69260 }
  ?paper orkgp:P31 ?dataset ;
         a orkgc:Paper ;
         rdfs:label ?paper_lbl .
}",0,0.7777777777777778,0.4375,0.56,0.19773446405712689,0.09188516480718534,0.6428571378826532,0.4878048731945272,0.5714285664540818
HQ0081,What quantity of iron oxide was discovered on Elorza crater?,"SELECT ?properties_values, ?property_description
WHERE {
  ?papers rdf:type orkgc:Paper.
  ?papers rdfs:label ?papers_labels.
  FILTER(REGEX(?papers_labels, ""Elorza crater"", ""i""))
  ?papers orkgp:P31 ?contrib.
  ?contrib ?properties ?properties_values.
  ?properties rdfs:label ?properties_labels.
  FILTER(REGEX(?properties_labels, ""FeO""))
  ?properties orkgp:description ?property_description.
}","SELECT ?value
WHERE {
  ?contribution orkgp:hasFactsAbout ?location .
  ?location rdfs:label ""Elorza Crater"" .
  ?contribution ?p ?statement .
  ?statement orkgp:P7000 orkgr:wikidata:Q721849 .
  ?statement rdfs:label ?value .
}",0,0.8,0.5263157894736842,0.6349206349206348,0.2256454418434083,0.08107098381411741,0.5161290273881375,0.4090909042561984,0.38709676932362125
AQ0314,Can you list the models that have been evaluated on the VTAB-1k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""VTAB-1k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET orkgr:R126031 .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}",0,0.9166666666666666,0.55,0.6874999999999999,0.3661938665629843,0.24448434239647238,0.7096774144849116,0.6382978676143052,0.5806451564203955
AQ2336,Provide a list of papers that have utilized the DQN-PixelCNN model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DQN-PixelCNN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?model a orkgc:Model ;
    rdfs:label ""DQN-PixelCNN"" .
  ?contribution orkgp:HAS_MODEL ?model ;
    orkgp:HAS_SOURCE_CODE ?code ;
    orkgp:P31 ?paper .
}",0,0.96,0.6857142857142857,0.7999999999999999,0.5138427500018953,0.39609820902105963,0.8484848435261708,0.7499999950781251,0.8484848435261708
AQ0942,Can you list the metrics used to evaluate models on the Atari 2600 Freeway dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label WHERE {
  VALUES ?dataset { orkgr:R124971 }
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8888888888888888,0.6666666666666666,0.761904761904762,0.4528510721893832,0.29855471273907885,0.6874999950781251,0.624999995138889,0.6874999950781251
AQ2092,List the code links in papers that use the Dynamic Coattention Networks (single model) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Dynamic Coattention Networks (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL <http://orkg.org/orkg/resource/R119700> .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.76,0.5,0.6031746031746031,0.3782441661427439,0.2972602739850972,0.5714285665306124,0.530612240066639,0.5714285665306124
AQ1826,"Indicate the model that performed best in terms of Macro Precision metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1302,What is the top benchmark score and its metric on the Atari 2600 Tennis dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
    ?dataset rdfs:label ""Atari 2600 Tennis"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?cont orkgp:HAS_BENCHMARK ?benchmark .
    OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
    }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.6712328767123288,0.8032786885245902,0.5388005755057549,0.43958254957273335,0.8749999950781251,0.799999995153125,0.8333333284114584
AQ0742,What are the metrics of evaluation over the DuIE dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DuIE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  VALUES ?dataset { orkgr:R116613 }
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.8928571428571429,0.7352941176470589,0.806451612903226,0.5365941293866912,0.3874165185625869,0.7333333283555556,0.6521739081285445,0.7333333283555556
AQ0888,"List the metrics that are used to evaluate models on the Cheetah, run (DMControl500k) benchmark dataset?","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R123348 .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6111111111111112,0.7333333333333334,0.41415537407181474,0.2599417113054143,0.7096774144849116,0.6521739082797733,0.7096774144849116
AQ0217,Could you provide a list of models that have been tested on the Reuters RCV1/RCV2 English-to-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters RCV1/RCV2 English-to-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ?dataset_label .
  FILTER(CONTAINS(LCASE(STR(?dataset_label)), ""rcv1"") && CONTAINS(LCASE(STR(?dataset_label)), ""english-to-german""))
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.8780487804878049,0.8181818181818182,0.8470588235294119,0.6035657009696681,0.44026206216480096,0.8292682877096967,0.6999999950500001,0.8292682877096967
HQ0097,What types of nanocarriers do have therapeutic effect?,"SELECT ?types_of_nanocarriers, ?types_of_nanocarriers_labels
WHERE {
  orkgr:R144364 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P41740 ?types_of_nanocarriers.
  ?contrib orkgp:P41743 ?therapeutic_effect.
  FILTER(?therapeutic_effect = ""T""^^xsd:string)
  ?types_of_nanocarriers rdfs:label ?types_of_nanocarriers_labels.
}","SELECT DISTINCT ?nanocarrier_type ?nanocarrier_type_label
WHERE {
    ?contribution orkgp:P30940 ?nanocarrier_type .
    ?contribution orkgp:P30941 ?therapeutic_effect .
    ?nanocarrier_type rdfs:label ?nanocarrier_type_label .
}",0,0.8235294117647058,0.5384615384615384,0.6511627906976744,0.18050530754836888,0.0420679506964681,0.49999999531250006,0.3428571381877551,0.49999999531250006
AQ1685,What is the name of the top performing model in terms of ROUGE-2 score when benchmarked on the CL-SciSumm dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CL-SciSumm"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_name
WHERE {
    ?dataset rdfs:label ""CL-SciSumm"" .
    ?metric rdfs:label ""ROUGE-2"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?eval orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_name .
}
ORDER BY DESC(xsd:decimal(?value))
LIMIT 1",0,0.9636363636363636,0.7794117647058824,0.8617886178861789,0.5485727796261082,0.3795641986399225,0.879999995008,0.7435897386423406,0.7199999950079999
AQ2033,List the code links in papers that use the Unsupervised NMT + weight-sharing model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Unsupervised NMT + weight-sharing"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL orkgr:R117252 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5135135135135135,0.6551724137931034,0.35807246653363134,0.2852522943426942,0.6249999953125001,0.5777777731950617,0.6249999953125001
AQ1740,Which model has achieved the highest Permuted Accuracy score on the Sequential MNIST benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Permuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""Permuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
            orkgp:HAS_METRIC ?metric .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.9714285714285714,1.0,0.9855072463768115,0.9484696017312617,0.9253731343283582,0.9629629579698218,0.9545454495480372,0.9629629579698218
AQ0026,Can you list the models that have been evaluated on the SciTLDR dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0699,List the metrics that are used to evaluate models on the CommonsenseQA benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R162694 .
  orkgr:R162694 rdfs:label ""CommonsenseQA"" .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8620689655172413,0.7352941176470589,0.7936507936507937,0.5191129257921043,0.3237041692566475,0.7999999950222222,0.680851058886374,0.7999999950222222
AQ1327,"What is the highest benchmark result achieved on the IMDb-M dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IMDb-M"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?value
WHERE {
    ?dataset rdfs:label ""IMDb-M"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric ;
          orkgp:HAS_VALUE ?value .
    ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.9024390243902439,0.5138888888888888,0.6548672566371682,0.3413709720543733,0.24710264863945242,0.7234042503757356,0.6133333285902223,0.6382978673970123
AQ1037,"Can you provide the highest benchmark result, including the metric and score, for the Scholarly entity usage detection dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Scholarly entity usage detection"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?score
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R147640 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
    ?evaluation orkgp:P32 ?score .
    FILTER(isNumeric(?score))
}
ORDER BY DESC(xsd:double(?score))
LIMIT 1",0,0.7948717948717948,0.4189189189189189,0.5486725663716814,0.24807272345700673,0.18116154831626263,0.5599999950720002,0.4615384568047337,0.5199999950720001
AQ0142,Can you list the models that have been evaluated on the MultiNLI dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MultiNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""MultiNLI"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.717948717948718,0.835820895522388,0.5334319888546144,0.4050751122916418,0.8275862020451843,0.7391304300189037,0.8275862020451843
AQ0759,List the metrics that are used to evaluate models on the 200k Short Texts for Humor Detection benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""200k Short Texts for Humor Detection"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""200k Short Texts for Humor Detection"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P30003 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.967741935483871,0.7692307692307693,0.8571428571428572,0.5183070521278785,0.33109088094047473,0.8421052582132964,0.7407407358504802,0.8421052582132964
AQ1355,"Can you provide the highest benchmark result, including the metric and score, for the Sequential MNIST dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset a orkgc:Dataset ;
        rdfs:label ""Sequential MNIST"" .
      ?benchmark orkgp:HAS_DATASET ?dataset .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value .
      OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
      }
      ?cont orkgp:HAS_BENCHMARK ?benchmark .
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8194444444444444,0.9007633587786259,0.7511300478241829,0.687640117538823,0.9387755052228238,0.9195402249015723,0.9387755052228238
AQ1971,Provide a list of papers that have utilized the CRF with sentence expansion model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CRF with sentence expansion"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?model rdfs:label ""CRF with sentence expansion"" .
  ?paper orkgp:HAS_MODEL ?model ;
         orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.5945945945945946,0.7457627118644068,0.3935120027556855,0.2927717779901156,0.8571428522448981,0.7083333285503473,0.8571428522448981
AQ1092,What is the top benchmark result (metric and value) over the dataset NYT-single?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT-single"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
  ?dataset rdfs:label ""NYT-single"" .
  ?dataset a orkgc:Dataset .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_VALUE ?value .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.9523809523809523,0.5555555555555556,0.7017543859649122,0.3801470565703209,0.2761517053911018,0.7555555506765433,0.675675670971512,0.7111111062320988
AQ0712,List the metrics that are used to evaluate models on the SciTLDR benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ""SciTLDR"".
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?eval           orkgp:HAS_METRIC         ?metric.
  ?metric          rdfs:label               ?metric_lbl.
}",0,1.0,0.8529411764705882,0.9206349206349206,0.7433282700750228,0.647408338513295,0.8965517191914388,0.8510638248438207,0.8965517191914388
AQ0085,Can you list the models that have been evaluated on the WMT2016 English-German dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""WMT2016 English-German"" .
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.6097560975609756,0.7575757575757575,0.4409686379518052,0.35951756184753314,0.8124999951757814,0.7083333286458334,0.8124999951757814
AQ1603,Indicate the model that performed best in terms of FLOPS metric on the CIFAR-100 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CIFAR-100"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""CIFAR-100"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY ASC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.9565217391304348,0.9850746268656716,0.9705882352941176,0.9094348892358506,0.8484848484848485,0.9230769180843196,0.9302325531422391,0.8846153796227811
AQ1160,What is the top benchmark result (metric and value) over the dataset RotoWire (Relation Generation)?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?value
WHERE {
  ?dataset rdfs:label ""RotoWire"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric ;
        orkgp:HAS_VALUE ?value .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:float(?value))
LIMIT 1",0,0.8974358974358975,0.4794520547945205,0.625,0.2949217170326166,0.20910012968234049,0.6521739081947071,0.5405405359057708,0.6086956473251418
AQ1631,"What is the best performing model benchmarking the Reacher, easy (DMControl100k) dataset in terms of Score metric?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_label (xsd:double(?score_value) as ?score)
WHERE {
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""Reacher, easy (DMControl100k)""^^xsd:string .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?value orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Score""^^xsd:string .
    ?value rdfs:label ?score_value .
}
ORDER BY DESC(?score)
LIMIT 1",0,0.8548387096774194,0.7794117647058824,0.8153846153846154,0.552439956318576,0.3846444751160522,0.8235294067666282,0.6666666616857188,0.6274509753940792
AQ0248,Can you list the models that have been evaluated on the Atari 2600 Assault dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Assault"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
    ?evaluation orkgp:HAS_DATASET orkgr:R124963 .
    ?evaluation orkgp:HAS_METHOD ?model .
    ?model rdfs:label ?model_label .
}",0,0.85,0.4146341463414634,0.5573770491803278,0.20715555806730873,0.12350744086276075,0.5806451565452655,0.4782608650283554,0.5806451565452655
AQ2342,Where can I find code references in papers that have used the DQNMMCe+SR model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DQNMMCe+SR"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R124987 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5428571428571428,0.6785714285714285,0.393851321562034,0.3137549060754729,0.6666666618666668,0.6046511581179016,0.5999999952
AQ1230,"Can you provide the highest benchmark result, including the metric and score, for the Ball in cup, catch (DMControl100k) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?score
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R123347 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
    ?eval orkgp:HAS_VALUE ?score .
}
ORDER BY DESC(xsd:double(str(?score)))
LIMIT 1",0,0.8421052631578947,0.4266666666666667,0.5663716814159292,0.2640423312541369,0.2050311638023581,0.5999999951280002,0.5194805148524203,0.5199999951280001
AQ1402,What is the name of the top performing model in terms of F1 score when benchmarked on the NYT-single dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT-single"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""F1"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""NYT-single""^^xsd:string .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?evaluation .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
      ?evaluation orkgp:HAS_VALUE ?value ;
        orkgp:HAS_METRIC ?metric .
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,0.9649122807017544,0.8208955223880597,0.8870967741935484,0.6753274990759734,0.5593926123969486,0.8979591786755519,0.7948717899013809,0.734693872553103
AQ2083,Can you provide links to code used in papers that benchmark the MEMEN (single model) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MEMEN (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ""MEMEN (single model)"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5575281360502197,0.44394286847177306,0.8749999950781251,0.7391304299338375,0.8749999950781251
AQ2050,Provide a list of papers that have utilized the MMV TSM-50x2 model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MMV TSM-50x2"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?model rdfs:label ""MMV TSM-50x2"" .
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_SOURCE_CODE ?code ;
                orkgp:P31 ?paper .
  ?paper a orkgc:Paper .
}",0,0.9259259259259259,0.6944444444444444,0.7936507936507936,0.4546097502206481,0.29855471273907885,0.8333333283487654,0.679999995072,0.6111111061265434
AQ1583,Which model has achieved the highest Accuracy score on the Yelp-5 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-5"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-5"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9710144927536232,1.0,0.9852941176470589,0.9476990614658233,0.9242424242424242,0.961538456545858,0.9534883670957275,0.961538456545858
AQ1428,What is the best performing model benchmarking the WMT2016 German-English dataset in terms of BLEU score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_lbl
WHERE {
    ?dataset rdfs:label ""WMT2016 German-English"" .
    ?metric rdfs:label ""BLEU score"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?eval orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:float(?value))
LIMIT 1",0,0.9649122807017544,0.7971014492753623,0.8730158730158731,0.5793638573513205,0.4200817884834805,0.8846153796227811,0.74999999505,0.6923076873150887
AQ2246,Provide a list of papers that have utilized the SAC model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SAC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?model rdfs:label ""SAC"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution .
}",0,0.9583333333333334,0.6764705882352942,0.7931034482758621,0.4006070698156106,0.2197468767334812,0.7999999950888891,0.6363636315289257,0.5999999950888889
AQ2077,Provide a list of papers that have utilized the MEMEN model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MEMEN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?paper orkgp:HAS_MODEL orkgr:R119649 .
  ?paper orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8823529411764706,0.4411764705882353,0.5882352941176471,0.2114971969209445,0.10510841176326924,0.6428571380867347,0.5499999954500001,0.6428571380867347
AQ2152,Where can I find code references in papers that have used the Past Decode Reg. + AWD-LSTM-MoS + dyn. eval. model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Past Decode Reg. + AWD-LSTM-MoS + dyn. eval."")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""Past Decode Reg. + AWD-LSTM-MoS + dyn. eval."" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7560975609756098,0.8611111111111112,0.6318774062804976,0.5432081399806608,0.9090909041322315,0.7931034433709869,0.8636363586776858
AQ1702,What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Assault dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Assault"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model_lbl
WHERE {
    ?metric rdfs:label ""Score"" .
    {
        SELECT ?model_lbl
        WHERE {
            VALUES ?dataset { orkgr:R124963 }
            ?benchmark orkgp:HAS_DATASET ?dataset .
            ?benchmark orkgp:HAS_EVALUATION ?eval .
            ?eval orkgp:HAS_METRIC ?metric .
            ?eval orkgp:HAS_VALUE ?value .
            ?contribution orkgp:HAS_BENCHMARK ?benchmark .
            ?contribution orkgp:HAS_MODEL ?model .
            ?model rdfs:label ?model_lbl .
        }
        ORDER BY DESC(xsd:decimal(?value))
        LIMIT 1
    }
}",0,0.9122807017543859,0.7647058823529411,0.8319999999999999,0.5538617871383299,0.3817113142879764,0.7843137204921184,0.7160493777351015,0.7058823479430989
AQ1415,What is the best performing model benchmarking the 200k Short Texts for Humor Detection dataset in terms of F1-score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1-score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""200k Short Texts for Humor Detection"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?value
WHERE {
  ?dataset rdfs:label ""200k Short Texts for Humor Detection""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ""F1-score""^^xsd:string .
  ?eval orkgp:HAS_VALUE ?value .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.9354838709677419,0.8055555555555556,0.8656716417910448,0.6105636866589106,0.4615837058544953,0.8965517191438764,0.7674418555083831,0.7586206846611178
AQ1977,Where can I find code references in papers that have used the STREET model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""STREET"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""STREET"")
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0,1.0,0.8529411764705882,0.9206349206349206,0.8416308400672835,0.8416308400672835,0.9696969647015611,0.959999995008,0.9696969647015611
AQ0156,Can you list the models that have been evaluated on the enwiki8 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwiki8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""enwiki8"" .
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:P31 ?contribution .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9629629629629629,0.6666666666666666,0.7878787878787878,0.46203208355221154,0.34730604373289203,0.7586206848038051,0.6521739082797733,0.7586206848038051
AQ0407,Provide a list of research paper titles and IDs that have benchmarked models on the SciERC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  VALUES ?dataset { orkgr:R69289 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,0.8888888888888888,0.75,0.8135593220338982,0.5996634153412169,0.4847210607757537,0.7586206846611178,0.6818181768595042,0.7586206846611178
AQ1465,Indicate the model that performed best in terms of Accuracy metric on the CommonsenseQA benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
            orkgp:HAS_METRIC ?metric .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
            orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0813,What evaluation metrics are commonly used when benchmarking models on the SQuAD2.0 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SQuAD2.0"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  VALUES ?dataset { orkgr:R70896 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8888888888888888,0.6857142857142857,0.7741935483870968,0.46993780187145967,0.30981961633579436,0.709677414401665,0.6382978674513355,0.709677414401665
AQ0769,What evaluation metrics are commonly used when benchmarking models on the WMT2014 English-German dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?dataset rdfs:label ""WMT2014 English-German"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8055555555555556,0.8923076923076924,0.580210358667772,0.3927718025274604,0.8749999950781251,0.7916666618055557,0.8749999950781251
AQ1860,Provide a list of benchmarked datasets related to the Reading Comprehension research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Reading Comprehension"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  VALUES ?problem { orkgr:R119127 }
  ?contribution orkgp:P32 ?problem .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset a orkgc:Dataset .
  ?dataset rdfs:label ?dataset_lbl .
}",0,0.9,0.7714285714285715,0.8307692307692307,0.5158614620834666,0.31351174995948666,0.7499999950195314,0.666666661701389,0.43749999501953124
AQ1388,Which model has achieved the highest RE+ Micro F1 score on the CoNLL04 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL04"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL04"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2455,Provide a list of papers that have utilized the XLNet (base) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""XLNet (base)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
    ?model rdfs:label ""XLNet (base)"" .
    ?contribution orkgp:HAS_MODEL ?model ;
                  orkgp:HAS_SOURCE_CODE ?code ;
                  orkgp:P31 ?paper .
}",0,0.9565217391304348,0.6285714285714286,0.7586206896551724,0.3975038672591152,0.2670693739902125,0.8124999950781252,0.6521739081947071,0.8124999950781252
AQ0639,List the title and ID of research papers that contain a benchmark over the Ohsumed dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Ohsumed"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""Ohsumed"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.8125,0.896551724137931,0.698740649251784,0.6213307756836141,0.8888888839506174,0.8095238046258505,0.8888888839506174
AQ0053,Could you provide a list of models that have been tested on the NYT29 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NYT29"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R116604 .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.92,0.5897435897435898,0.71875,0.43984990189152645,0.3375326286379361,0.7333333284222223,0.6521739082797733,0.7333333284222223
HQ0043,Which are 3 the most common variables for the atmosphere models?,"SELECT ?variables
WHERE {
  orkgr:R68871 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P7144 ?models.
  ?models rdfs:label ?models_labels.
  FILTER(REGEX(?models_labels, ""tmospher""))
  ?models orkgp:P26032 ?variables.
}
ORDER BY DESC(COUNT(?variables))
LIMIT 3","SELECT ?variable_label (COUNT(?variable) AS ?count)
WHERE {
  ?contribution orkgp:P30004 ?variable .
  ?variable rdfs:label ?variable_label .
}
GROUP BY ?variable ?variable_label
ORDER BY DESC(?count)
LIMIT 3",0,0.84,0.6774193548387096,0.75,0.28582409786252655,0.10726743559998456,0.6857142808163266,0.5098039166166859,0.6285714236734695
AQ2345,List the code links in papers that use the DDQN-PC model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DDQN-PC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DDQN-PC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0638,List the title and ID of research papers that contain a benchmark over the TREC-6 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TREC-6"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?dataset rdfs:label ""TREC-6"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_title .
}",0,1.0,0.8181818181818182,0.9,0.7087694662405772,0.6339171106424729,0.8965517191914388,0.8181818132747933,0.8965517191914388
AQ2304,Can you provide links to code used in papers that benchmark the Rational DQN Average model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rational DQN Average"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?model rdfs:label ""Rational DQN Average"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8235294068339101
AQ1678,What is the name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-French dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model_lbl
WHERE {
  ?metric rdfs:label ""Accuracy score"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?benchmark rdfs:label ""Benchmark MLDoc Zero-Shot English-to-French"" .
      ?contribution orkgp:P31 ?benchmark .
      ?contribution orkgp:P32 ?model .
      ?model rdfs:label ?model_lbl .
      ?contribution orkgp:P2007 ?evaluation .
      ?evaluation orkgp:P2006 ?metric .
      ?evaluation orkgp:P2008 ?value .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.8545454545454545,0.6619718309859155,0.7460317460317459,0.3256433554831472,0.14376608405342717,0.7017543809664513,0.49411764209273357,0.6666666616682057
AQ1593,Indicate the model that performed best in terms of 1-of-100 Accuracy metric on the PolyAI Reddit benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""1-of-100 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PolyAI Reddit"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?score
WHERE {
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""PolyAI Reddit"" .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""1-of-100 Accuracy"" .
    ?eval orkgp:HAS_VALUE ?score .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(?score)
LIMIT 1",0,1.0,0.8,0.888888888888889,0.6116912321726297,0.47021934072235766,0.919999995032,0.799999995078125,0.679999995032
AQ1923,List the code links in papers that use the Long Short Transformer model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Long Short Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_MODEL <http://orkg.org/orkg/resource/R216337> .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8,0.6666666666666666,0.7272727272727272,0.5754501639392356,0.48517377960176705,0.6285714236081633,0.5999999950720001,0.514285709322449
AQ1472,What is the name of the top performing model in terms of Accuracy score when benchmarked on the TriviaQA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""TriviaQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""TriviaQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
HQ0091,What is Raman spectroscopy?,"SELECT ?definitions
WHERE {
  ?terms orkgp:P24009 ?definitions.
  ?terms rdfs:label ?terms_labels.
  FILTER(REGEX(?terms_labels, ""Raman spectroscopy""))
}","SELECT ?definition
WHERE {
    orkgr:R144136 orkgp:P24009 ?definition .
}",0,0.75,0.375,0.5,0.08505277875811797,0.007357588823428847,0.5555555508024692,0.3636363592975207,0.5555555508024692
AQ1244,"Can you provide the highest benchmark result, including the metric and score, for the DTD dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""DTD"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?score
WHERE {
  VALUES ?dataset { orkgr:R5276 }
  ?benchmark orkgp:P3001 ?dataset .
  ?benchmark orkgp:P4005 ?eval .
  ?eval orkgp:P4004 ?score .
  ?eval orkgp:P4003 ?metric .
  ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(?score)
LIMIT 1",0,0.7352941176470589,0.352112676056338,0.47619047619047616,0.13612829242266136,0.06518909821151665,0.41860464629529476,0.3098591502876414,0.41860464629529476
AQ1241,What is the top benchmark score and its metric on the CINIC-10 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CINIC-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""CINIC-10"")
      ?benchmark     orkgp:HAS_DATASET       ?dataset ;
                     orkgp:HAS_EVALUATION    ?eval .
      ?eval          orkgp:HAS_VALUE         ?value .
      OPTIONAL {
        ?eval   orkgp:HAS_METRIC   ?metric .
        ?metric rdfs:label         ?metric_lbl .
      }
      ?cont          orkgp:HAS_BENCHMARK     ?benchmark .
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8611111111111112,0.9253731343283582,0.8402014065542222,0.8221959760533197,0.9803921518646674,0.977777772780247,0.9803921518646674
AQ0344,What are the titles and IDs of research papers that include a benchmark for the SemEval-2018 Task 7 dataset dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SemEval-2018 Task 7 dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""SemEval-2018 Task 7 dataset"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.8333333333333334,0.9090909090909091,0.7352085973517355,0.6671139469524296,0.9090909041322315,0.8333333284114584,0.9090909041322315
AQ0756,List the metrics that are used to evaluate models on the AG News benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AG News"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  VALUES ?dataset { orkgr:R116787 }
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.8928571428571429,0.7142857142857143,0.7936507936507937,0.5177682311018288,0.3738243758742743,0.709677414401665,0.6382978674513355,0.709677414401665
AQ1571,What is the name of the top performing model in terms of F1 entity level score when benchmarked on the NCBI Disease dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 entity level"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NCBI Disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_name
WHERE {
    ?benchmark rdfs:label ""Benchmark NCBI Disease""^^xsd:string .
    ?metric rdfs:label ""F1 entity level score""^^xsd:string .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?eval orkgp:HAS_VALUE ?value .
    ?cont orkgp:HAS_BENCHMARK ?benchmark .
    ?cont orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_name .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.8909090909090909,0.7101449275362319,0.7903225806451614,0.5201618552182763,0.3876344063991846,0.8461538411612427,0.6999999950500001,0.6923076873150887
AQ0525,Provide a list of research paper titles and IDs that have benchmarked models on the NCBI-disease dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?benchmark rdfs:label ""Benchmark NCBI Disease"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?paper_title .
}",0,0.92,0.696969696969697,0.793103448275862,0.5134649082668885,0.3630745185368454,0.866666661688889,0.7391304298204161,0.7999999950222222
AQ2290,Can you provide links to code used in papers that benchmark the GCN Hybrid model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""GCN Hybrid"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""GCN Hybrid"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7142857142857143,0.8333333333333333,0.5605810063146194,0.4570363950242995,0.8749999950781251,0.7391304299338375,0.8124999950781252
HQ0085,What data format does CHEMDNER corpus have?,"SELECT ?data_format, ?data_format_label
WHERE {
  orkgr:R150596 orkgp:P31 ?contrib.
  ?contrib orkgp:P42011 ?data_format.
  ?data_format rdfs:label ?data_format_label.
}","SELECT ?data_format
WHERE {
  orkgr:R150599 orkgp:P42011 ?data_format .
}",0,0.875,0.4117647058823529,0.56,0.0824832752169873,0.006493049347166995,0.7058823480968859,0.47619047174603185,0.7058823480968859
AQ0447,What are the titles and IDs of research papers that include a benchmark for the CUB-200-2011 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CUB-200-2011"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R121969 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper a orkgc:Paper .
  ?paper rdfs:label ?title .
}",0,0.8888888888888888,0.7058823529411765,0.7868852459016393,0.5143534578983784,0.3536605172445633,0.7499999950195314,0.680851058886374,0.6874999950195313
AQ1976,Can you provide links to code used in papers that benchmark the SEE model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SEE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""SEE"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7058823529411765,0.8275862068965517,0.5459471157272342,0.4394937534669624,0.8666666617555556,0.7272727224380167,0.7999999950888891
AQ2294,Provide a list of papers that have utilized the Duel hs model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Duel hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?paper_label ?code
WHERE {
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?model rdfs:label ""Duel hs"" .
  ?model a orkgc:Model .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_label .
}",0,0.8484848484848485,0.8,0.823529411764706,0.4509282096101877,0.18823878802496652,0.8484848435261708,0.734693872603082,0.36363635867768596
AQ1372,What is the top benchmark result (metric and value) over the dataset DocRED (Human-annotated)?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""DocRED (Human-annotated)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
    ?dataset rdfs:label ""DocRED (Human-annotated)""^^xsd:string .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric ?metric_lbl
ORDER BY DESC(?score)",0,0.9622641509433962,0.6986301369863014,0.8095238095238095,0.5216834542290237,0.35654851623278533,0.839999995032,0.7710843324372187,0.759999995032
AQ2194,Provide a list of papers that have utilized the Adaptive Input Large model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Adaptive Input Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R121011 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution .
}",0,0.8571428571428571,0.5,0.631578947368421,0.24968207959650526,0.1087870354571007,0.5806451565452655,0.4999999953719009,0.3870967694484912
AQ0259,What models are being evaluated on the Atari 2600 Solaris dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Solaris"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R124983 .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.8421052631578947,0.3902439024390244,0.5333333333333333,0.18518176807872558,0.11780506761889291,0.5806451565452655,0.4782608650283554,0.5806451565452655
AQ0489,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SNLI dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?contribution (orkgp:HAS_DATASET|orkgp:P41655) orkgr:R120776 .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?title .
}",0,0.8181818181818182,0.5625,0.6666666666666666,0.31999285992375565,0.1670358997211268,0.7333333283333333,0.5909090859504132,0.6666666616666668
AQ2046,Where can I find code references in papers that have used the MMV model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MMV"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R118768 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5588235294117647,0.6909090909090908,0.41305986302894704,0.3290570614672478,0.6896551675624257,0.6190476143310658,0.6206896503210465
AQ1273,What is the top benchmark score and its metric on the Atari 2600 Centipede dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark     orkgp:HAS_DATASET       ?dataset ;
                     orkgp:HAS_EVALUATION    ?eval .
      ?eval          orkgp:HAS_VALUE         ?value .
      OPTIONAL {
        ?eval        orkgp:HAS_METRIC        ?metric .
        ?metric      rdfs:label              ?metric_lbl .
      }
      ?cont          orkgp:HAS_BENCHMARK     ?benchmark .
      OPTIONAL {
        ?cont        orkgp:HAS_MODEL         ?model .
        ?model       rdfs:label              ?model_lbl .
      }
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0042,What are the models that have been benchmarked on the MNIST dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MNIST"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R114182 }
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.8695652173913043,0.5128205128205128,0.6451612903225806,0.3513840605696613,0.27431198891926206,0.6666666617555557,0.5652173865406428,0.6666666617555557
HQ0078,Where did the study with maximal geographic scale take place?,"SELECT ?location, ?location_label
WHERE {
  {
    SELECT (MAX(?geo_scale) AS ?max_geo_scale)
    WHERE {
      orkgr:R149849 orkgp:compareContribution ?contrib.
      ?contrib orkgp:P41568 ?geo_scale.
    }
  }
  orkgr:R149849 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P41568 ?geo_scale;
           orkgp:P37524 ?location.
  ?location rdfs:label ?location_label.
  FILTER(?geo_scale = ?max_geo_scale)
}","SELECT ?location
WHERE {
  ?study ?p_scale ?scale .
  ?p_scale rdfs:label ""Geographic scale (Km)""@en .
  ?study ?p_location ?location .
  ?p_location rdfs:label ""location""@en .
}
ORDER BY DESC(xsd:decimal(?scale))
LIMIT 1",0,0.4827586206896552,0.3684210526315789,0.417910447761194,0.106315308501939,0.028199772580053743,0.3225806402081166,0.22222221724444458,0.3225806402081166
AQ0409,Provide a list of research paper titles and IDs that have benchmarked models on the WLPC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WLPC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
  ?contribution orkgp:P2005 orkgr:R4004 .
}",0,0.8333333333333334,0.46875,0.6,0.27516309648780557,0.15314194134530887,0.6153846105029586,0.578947363767313,0.3846153797337278
AQ0507,What are the titles and IDs of research papers that include a benchmark for the TempEval-3 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?dataset rdfs:label ""TempEval-3"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper a orkgc:Paper .
  ?paper rdfs:label ?title .
}",0,0.967741935483871,0.9090909090909091,0.9374999999999999,0.7146712340338787,0.5692091742205014,0.9032258014568159,0.8085106333182437,0.8387096724245579
AQ0064,Could you provide a list of models that have been tested on the SciERC benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R69289 .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}",0,0.9166666666666666,0.5641025641025641,0.6984126984126983,0.381774282284796,0.2548863945328525,0.7333333284222223,0.6521739082797733,0.7333333284222223
AQ1545,Indicate the model that performed best in terms of F1 metric on the CoNLL 2012 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL 2012"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""F1"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""CoNLL 2012"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
        orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9649122807017544,0.8208955223880597,0.8870967741935484,0.6705880659418626,0.5438539287192555,0.8979591786755519,0.7948717899013809,0.8163265256143275
AQ0083,What are the models that have been benchmarked on the WMT2014 English-German dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R117257 .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}",0,0.92,0.5609756097560976,0.6969696969696971,0.4060326343926262,0.31158188693452876,0.6874999951757813,0.6249999953125001,0.6874999951757813
AQ1335,"What is the highest benchmark result achieved on the Yelp-14 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-14"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
    ?dataset a orkgc:Dataset ;
             rdfs:label ""Yelp-14""^^xsd:string .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?cont orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
    ?eval orkgp:HAS_VALUE ?value .
}
GROUP BY ?metric_lbl
ORDER BY DESC(?score)",0,0.9615384615384616,0.6944444444444444,0.8064516129032258,0.5418467465515077,0.4167626928510523,0.8571428521615995,0.8095238045691611,0.6938775460391503
AQ2309,List the code links in papers that use the A3C FF (1 day) hs model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C FF (1 day) hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model a orkgc:Model;
    rdfs:label ""A3C FF (1 day) hs"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7894736842105263,0.8823529411764706,0.7011942886281765,0.62408975718601,0.9230769181065088,0.8518518469135803,0.9230769181065088
AQ0141,Could you provide a list of models that have been tested on the RTE benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RTE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?evaluation orkgp:USES ?model .
  ?evaluation orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ""RTE"" .
  ?model rdfs:label ?model_lbl .
}",0,0.9545454545454546,0.5384615384615384,0.6885245901639344,0.3003240683216209,0.19442190559273168,0.7142857095153062,0.5909090862809917,0.6428571380867347
AQ1332,"What is the highest benchmark result achieved on the WOS-5736 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-5736"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-5736"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0460,Provide a list of research paper titles and IDs that have benchmarked models on the WebQuestions dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WebQuestions"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R119611 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?paper_lbl .
}",0,0.88,0.6875,0.7719298245614036,0.5007813915461432,0.343538064298057,0.7999999950000002,0.6818181768595042,0.7333333283333333
AQ0717,List the metrics that are used to evaluate models on the ART/CoreSC benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ART/CoreSC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?dataset rdfs:label ""ART/CoreSC"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8,0.888888888888889,0.5660013298771387,0.3738243758742743,0.8666666617555556,0.7826086908034027,0.8666666617555556
AQ0107,What are the models that have been benchmarked on the Natural Questions (short) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Natural Questions (short)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  VALUES ?dataset { orkgr:R119452 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.8928571428571429,0.6097560975609756,0.7246376811594203,0.4381697406158226,0.3268636453672852,0.666666661781451,0.5999999952,0.666666661781451
AQ1105,"Can you provide the highest benchmark result, including the metric and score, for the WMT2014 French-English dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label (MAX(?score) AS ?highest_score)
WHERE {
    ?dataset rdfs:label ""WMT2014 French-English""^^xsd:string .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
    ?evaluation orkgp:HAS_VALUE ?score .
}
GROUP BY ?metric_label",0,0.9574468085106383,0.6164383561643836,0.7500000000000001,0.4388615420870223,0.3136971361998109,0.7916666617447918,0.7088607546739304,0.6249999950781252
AQ1535,Which model has achieved the highest Test perplexity score on the WikiText-2 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Test perplexity"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WikiText-2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_lbl
WHERE {
    ?dataset rdfs:label ""WikiText-2"" .
    ?metric rdfs:label ""Test perplexity"" .
    ?benchmark orkgp:HAS_DATASET ?dataset ;
               orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric ;
          orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                  orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:float(?value))
LIMIT 1",0,0.9622641509433962,0.75,0.8429752066115702,0.5685305973939531,0.4370332309708256,0.879999995008,0.7435897386423406,0.7199999950079999
AQ2214,Where can I find code references in papers that have used the All-attention network - 18 layers model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""All-attention network - 18 layers"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R121047 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5,0.6440677966101696,0.34142100644952944,0.27198719401502147,0.606060601432507,0.5652173867674859,0.5454545408264463
HQ0022,"Does paper ""Disambiguating authors in citations on the web and authorship correlations"" employe Cosine similarity?","ASK
WHERE {
  orkgr:R6187 orkgp:compareContribution ?cont.
  ?paper orkgp:P31 ?cont;
         rdfs:label ?paper_title.
  ?cont orkgp:P5002 orkgr:R6006.
  FILTER(REGEX(STR(?paper_title), ""Disambiguating authors in citations on the web and authorship correlations"", ""i""))
}","ASK
WHERE {
    orkgr:R6129 orkgp:P31 ?contribution .
    ?contribution orkgp:P32 ?method .
    ?method rdfs:label ""Cosine similarity"" .
}",0,0.75,0.36363636363636365,0.48979591836734687,0.06128615740247358,0.002658390404438266,0.4324324280496713,0.3636363592975207,0.3783783739956173
AQ0168,Can you list the models that have been evaluated on the STS Benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STS Benchmark"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?dataset rdfs:label ""STS Benchmark"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_CONTRIBUTION ?contribution .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_label .
}",0,0.9285714285714286,0.65,0.7647058823529412,0.40415490156486167,0.26057562301242226,0.7333333284222223,0.5957446760344047,0.7333333284222223
AQ1710,Indicate the model that performed best in terms of Score metric on the Atari 2600 Freeway benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0517,What are the titles and IDs of research papers that include a benchmark for the DCASE dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DCASE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""DCASE"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.875,0.9333333333333333,0.8152493638313232,0.7628525517801599,0.9285714235969389,0.8888888839111112,0.9285714235969389
AQ0864,What evaluation metrics are commonly used when benchmarking models on the Yelp Fine-grained classification dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp Fine-grained classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label
WHERE {
  ?dataset rdfs:label ""Yelp Fine-grained classification""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(COUNT(?eval))",0,0.7948717948717948,0.8378378378378378,0.8157894736842105,0.5021256908876751,0.3055555555555556,0.6999999950125001,0.5762711814421144,0.6999999950125001
AQ1704,Which model has achieved the highest Score score on the Atari 2600 River Raid benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 River Raid"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_lbl
WHERE {
    ?dataset rdfs:label ""Atari 2600 River Raid"" .
    ?metric rdfs:label ""Score"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.9655172413793104,0.8115942028985508,0.8818897637795277,0.5910265872319592,0.4211425738221119,0.9056603723602706,0.7654320938027741,0.6037735799074405
AQ1949,Provide a list of papers that have utilized the BERT + BiLSTM + CRF Decoding model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BERT + BiLSTM + CRF Decoding"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_label ?code
WHERE {
  ?paper a orkgc:Paper .
  ?paper rdfs:label ?paper_label .
  ?paper orkgp:P31 ?contribution .
  ?contribution orkgp:HAS_MODEL orkgr:R224885 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8571428571428571,0.6486486486486487,0.7384615384615384,0.3637061275267774,0.17402698126131164,0.6666666617283951,0.5490196029373319,0.6666666617283951
AQ1541,Indicate the model that performed best in terms of Pearson Correlation metric on the MedSTS benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Pearson Correlation"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MedSTS"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
    rdfs:label ?metric_lbl .
  FILTER(str(?metric_lbl) = ""Pearson Correlation"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
        rdfs:label ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""MedSTS"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
        orkgp:HAS_METRIC ?metric .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0570,What are the titles and IDs of research papers that include a benchmark for the WSC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WSC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?paper a orkgc:Paper .
  ?paper rdfs:label ?title .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ""WSC"" .
}",0,0.9615384615384616,0.78125,0.8620689655172413,0.591433142090305,0.44873889354927676,0.8571428521683674,0.7142857093877552,0.6428571378826532
AQ1964,List the code links in papers that use the linear-chain CRFs model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""linear-chain CRFs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R226473 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5277777777777778,0.6666666666666666,0.3755360357665399,0.299164347507027,0.6451612855775234,0.5909090862809917,0.5806451565452655
AQ2059,List the code links in papers that use the DrQA model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DrQA"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R119444 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5588235294117647,0.6909090909090908,0.41305986302894704,0.3290570614672478,0.6896551675624257,0.6190476143310658,0.6206896503210465
AQ1559,Which model has achieved the highest Accuracy score on the SST-5 Fine-grained classification benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SST-5 Fine-grained classification"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label (MAX(?score) AS ?max_score)
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R122621 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Accuracy"" .
    ?evaluation orkgp:HAS_VALUE ?score .
}
GROUP BY ?model_label
ORDER BY DESC(?max_score)
LIMIT 1",0,0.8909090909090909,0.7,0.7839999999999999,0.49766299953038845,0.351369409244711,0.7307692257988165,0.6265060191319495,0.5384615334911242
AQ0692,What evaluation metrics are commonly used when benchmarking models on the ARC-PDN dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ARC-PDN"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  ?dataset rdfs:label ""ARC-PDN"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.7692307692307693,0.8571428571428571,0.8108108108108107,0.5222789939156585,0.3333333333333333,0.7222222172376543,0.6315789423822715,0.7222222172376543
HQ0026,Which QA benchmarks incorporating more than 10000 questions?,"SELECT ?papers, ?papers_labels
WHERE {
  ?papers rdf:type orkgc:Paper;
          orkgp:P31 ?contrib;
          rdfs:label ?papers_labels.
  ?contrib orkgp:P41923 ?questions_number_str.
  BIND(REPLACE(?questions_number_str, ""[+]"", """") AS ?questions_number_preprocessed)
  BIND(xsd:integer(REPLACE(?questions_number_preprocessed, """","""", """")) AS ?questions_number)
  FILTER(?questions_number > 10000)
}","SELECT DISTINCT ?benchmark ?benchmark_lbl
WHERE {
  ?prop rdfs:label ""Amount of Questions"" .
  ?benchmark ?prop ?num_questions .
  ?benchmark rdfs:label ?benchmark_lbl .
  FILTER(xsd:integer(?num_questions) > 10000)
}",0,0.7391304347826086,0.5,0.5964912280701754,0.1753188925785208,0.06198604731563715,0.5624999951757813,0.39999999529876545,0.4999999951757813
AQ0932,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Berzerk dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset rdfs:label ""Atari 2600 Centipede""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  OPTIONAL {
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
  }
}",0,0.90625,0.8055555555555556,0.8529411764705882,0.6714801582884575,0.5781876258312867,0.7999999950040816,0.7307692257988165,0.7999999950040816
AQ0434,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Stanford Cars dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Stanford Cars"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R128604 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?paper_title .
}",0,0.88,0.6666666666666666,0.7586206896551725,0.48114547232153887,0.3300677441244049,0.7741935433922998,0.6666666617283951,0.7096774143600416
AQ0671,What are the titles and IDs of research papers that include a benchmark for the BUCC German-to-English dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R127150 .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper rdfs:label ?paper_label .
}",0,0.9,0.5142857142857142,0.6545454545454545,0.329851765542023,0.22229014246635986,0.6666666618666668,0.6046511581179016,0.6666666618666668
AQ0777,What are the metrics of evaluation over the Stanford Cars dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Stanford Cars"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R128604 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.9166666666666666,0.6285714285714286,0.7457627118644068,0.4317764035063737,0.27100142665124993,0.7333333284222223,0.6666666618666668,0.7333333284222223
AQ0533,What are the titles and IDs of research papers that include a benchmark for the ShARe/CLEF eHealth corpus dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R123000 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?title .
}",0,0.88,0.6285714285714286,0.7333333333333334,0.44415325048993126,0.3046909300161997,0.7272727223140496,0.6382978674513355,0.6666666617079889
HQ0099,For what piezoresistive material the least response time was obtained?,"SELECT ?piezoresistive_materials WHERE {
  orkgr:R138374 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P41021 ?piezoresistive_materials.
  ?contrib orkgp:P41022 ?response_time.
}
ORDER BY ASC(?response_time)
LIMIT 1","SELECT ?material_label
WHERE {
    ?contribution ?p_material ?material .
    ?p_material rdfs:label ""Piezoresistive Material"" .
    ?material rdfs:label ?material_label .
    ?contribution ?p_response_time ?response_time .
    ?p_response_time rdfs:label ""Response time (ms)"" .
    ?response_time rdfs:label ?response_time_label .
    BIND(xsd:float(?response_time_label) AS ?response_time_value)
}
ORDER BY ASC(?response_time_value)
LIMIT 1",0,0.35,0.6363636363636364,0.45161290322580644,0.19783691883509516,0.10810810810810814,0.4848484799632691,0.39999999512098766,0.4848484799632691
AQ2454,List the code links in papers that use the GPT-2 (small) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""GPT-2 (small)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL orkgr:R128672 .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5277777777777778,0.6666666666666666,0.3755360357665399,0.299164347507027,0.6451612855775234,0.5909090862809917,0.6451612855775234
AQ0946,List the metrics that are used to evaluate models on the Atari 2600 Fishing Derby benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Fishing Derby"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label WHERE {
  VALUES ?dataset { orkgr:R124984 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8888888888888888,0.6486486486486487,0.75,0.43638560840689106,0.28769939603212885,0.666666661781451,0.6122448931278636,0.666666661781451
AQ1776,What is the best performing model benchmarking the ImageNet dataset in terms of Number of params metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl (?value AS ?score)
WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET orkgr:R157437 .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Number of params"" .
    ?evaluation orkgp:HAS_VALUE ?value .
}
ORDER BY ASC(xsd:decimal(?value))
LIMIT 1",0,0.8909090909090909,0.7205882352941176,0.7967479674796749,0.48907161546418954,0.30365135891193806,0.7692307642307693,0.649999995028125,0.4999999950000001
AQ0278,Can you list the models that have been evaluated on the Atari 2600 Battle Zone dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Battle Zone"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R125010 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9333333333333333,0.6666666666666666,0.7777777777777778,0.5262759322571994,0.4220533623187359,0.7058823480968859,0.6666666618992695,0.7058823480968859
AQ2361,List the code links in papers that use the BiT-M model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-M"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code_link
WHERE {
  ?model rdfs:label ""BiT-M"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code_link .
}",0,1.0,0.7142857142857143,0.8333333333333333,0.5605810063146194,0.4570363950242995,0.8749999950781251,0.7391304299338375,0.8124999950781252
AQ1317,"What is the highest benchmark result achieved on the Atari 2600 Star Gunner dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Star Gunner"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ""Atari 2600 Star Gunner"" .
      ?benchmark     orkgp:HAS_DATASET       ?dataset ;
                     orkgp:HAS_EVALUATION    ?eval .
      ?eval          orkgp:HAS_VALUE         ?value .
      OPTIONAL {
        ?eval   orkgp:HAS_METRIC  ?metric .
        ?metric rdfs:label        ?metric_lbl .
      }
      ?cont          orkgp:HAS_BENCHMARK     ?benchmark .
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8108108108108109,0.8955223880597014,0.7604565629770905,0.7224255692896955,0.9433962214311145,0.9230769180920179,0.9433962214311145
AQ2205,Can you provide links to code used in papers that benchmark the NASCell model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""NASCell"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R121036 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5588235294117647,0.6909090909090908,0.41305986302894704,0.3290570614672478,0.6896551675624257,0.6190476143310658,0.6206896503210465
AQ1980,Where can I find code references in papers that have used the TCN model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""TCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model rdfs:label ""TCN"" .
    ?contribution orkgp:HAS_MODEL ?model ;
                  orkgp:HAS_BENCHMARK ?benchmark ;
                  orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.6470588235294118,0.7857142857142858,0.4689406752451061,0.36604943923251126,0.8666666617555556,0.6976744138236886,0.7999999950888891
AQ1358,What is the top benchmark result (metric and value) over the dataset BUCC French-to-English?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC French-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ""BUCC French-to-English"".
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8108108108108109,0.8955223880597014,0.7604565629770905,0.7224255692896955,0.9433962214311145,0.9230769180920179,0.9433962214311145
AQ1156,What is the top benchmark result (metric and value) over the dataset SQuAD2.0?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SQuAD2.0"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?value
WHERE {
  ?dataset rdfs:label ""SQuAD2.0"" .
  ?cont orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.9545454545454546,0.5833333333333334,0.7241379310344828,0.4241232020872696,0.3226910618902746,0.7555555506765433,0.675675670971512,0.533333328454321
AQ1213,What is the top benchmark result (metric and value) over the dataset BC2GM?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC2GM"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  ?dataset rdfs:label ""BC2GM""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric ?metric_lbl
ORDER BY DESC(?score)",0,0.9555555555555556,0.6056338028169014,0.7413793103448275,0.4294207829900558,0.307293125687911,0.7999999950617285,0.7272727224152472,0.7555555506172841
AQ0807,List the metrics that are used to evaluate models on the Story Cloze Test benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Story Cloze Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""Story Cloze Test""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9,0.75,0.8181818181818182,0.4086577414363176,0.18194016735066265,0.7647058773702423,0.639999995072,0.7647058773702423
HQ0037,Who has contributed to the largest number of articles about coronavirus?,"SELECT ?author_name
WHERE {
  {
    SELECT (COUNT(?paper_) as ?max_n_papers)
    WHERE {
      ?paper_ a orkgc:Paper;
      rdfs:label ?title_;
      orkgp:P27 ?author_.
      FILTER(REGEX(STR(?title_), ""2019-nCoV""))
    }
    GROUP BY ?author_
    ORDER BY DESC(?max_n_papers)
    LIMIT 1
  }
  ?paper a orkgc:Paper;
  rdfs:label ?title;
  orkgp:P27 ?author.
  OPTIONAL {
    ?author rdfs:label ?author_label
  }
  BIND(IF(BOUND(?author_label), ?author_label, ?author) as ?author_name)
  FILTER(REGEX(STR(?title), ""2019-nCoV""))
}
GROUP BY ?author ?type ?author_name ?max_n_papers
HAVING(COUNT(?paper) = ?max_n_papers)","SELECT ?creatorLabel (COUNT(DISTINCT ?paper) AS ?count)
WHERE {
  ?paper orkgp:P32 orkgr:R248409 .
  ?paper orkgp:P31 ?contribution .
  ?contribution orkgp:P27 ?creator .
  ?creator rdfs:label ?creatorLabel .
}
GROUP BY ?creator ?creatorLabel
ORDER BY DESC(?count)
LIMIT 1",0,0.8285714285714286,0.4084507042253521,0.5471698113207547,0.18181029822379793,0.10055175046289136,0.6382978674513355,0.5555555506944445,0.46808510149388866
AQ0056,What are the models that have been benchmarked on the DuIE dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DuIE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R116613 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:P20004 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.8181818181818182,0.46153846153846156,0.5901639344262295,0.2501441577658162,0.14581642919454876,0.5999999950888889,0.47826086480151236,0.5999999950888889
HQ0031,What coolant does ASTRID reactor use?,"SELECT ?coolant ?coolant_label
WHERE {
  ?ASTRID_reactor ?rdfs_label ""ASTRID""^^xsd:string.
  ?contrib ?reactor_predicate ?ASTRID_reactor.
  ?contrib ?predicates ?coolant.
  ?predicates rdfs:label ?predicates_label.
  FILTER(REGEX(?predicates_label, ""coolant""))
  ?coolant rdfs:label ?coolant_label.
}","SELECT ?coolant_label
WHERE {
  ?reactor rdfs:label ""ASTRID reactor"" .
  ?property rdfs:label ""coolant"" .
  ?reactor ?property ?coolant .
  ?coolant rdfs:label ?coolant_label .
}",0,0.8421052631578947,0.5925925925925926,0.6956521739130435,0.32181421826061885,0.16408888886771006,0.7368421003878117,0.5714285665306124,0.6315789424930748
AQ1275,"Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Berzerk dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.863013698630137,0.9264705882352942,0.8425368556473993,0.8247856781928445,0.9811320704734782,0.9782608645675803,0.9811320704734782
AQ0262,Can you list the models that have been evaluated on the Atari 2600 Skiing dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124988 .
    ?contribution orkgp:P32 ?benchmark .
    ?contribution orkgp:P31 ?model .
    ?model rdfs:label ?model_lbl .
}",0,0.8260869565217391,0.4634146341463415,0.59375,0.24350979651588148,0.1371635183924263,0.5624999951757813,0.4583333286458333,0.5624999951757813
AQ1884,What are the most commonly used benchmark datasets for the Text Summarization research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Text Summarization"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT ?dataset_label (COUNT(?contribution) AS ?count)
WHERE {
    ?contribution orkgp:P32 orkgr:R124682 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ?dataset_label .
}
GROUP BY ?dataset_label
ORDER BY DESC(?count)
LIMIT 10",0,0.6857142857142857,0.6857142857142857,0.6857142857142857,0.37684787447900675,0.1875,0.5405405355734113,0.4285714235969388,0.3243243193571951
AQ0958,What are the metrics of evaluation over the Atari 2600 Tutankham dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  VALUES ?dataset { orkgr:R124999 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.8928571428571429,0.6944444444444444,0.78125,0.4996028216796326,0.3607091006761372,0.6874999950781251,0.624999995138889,0.6874999950781251
AQ1722,What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Tutankham dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0339,Can you list the models that have been evaluated on the PROTEINS dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PROTEINS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?benchmark rdfs:label ""Benchmark PROTEINS""^^xsd:string .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.8846153846153846,0.5897435897435898,0.7076923076923076,0.41502870569456635,0.3164507789805044,0.7333333284222223,0.5957446760344047,0.7333333284222223
AQ1484,What is the name of the top performing model in terms of F1 score when benchmarked on the Natural Questions (long) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (long)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model_lbl
WHERE {
  ?metric rdfs:label ""F1 score"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      VALUES ?dataset { orkgr:R119751 }
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.8928571428571429,0.7352941176470589,0.806451612903226,0.5643492395221629,0.4264018286066208,0.7692307642307693,0.6829268242801905,0.6923076873076923
AQ0829,What are the metrics of evaluation over the CommitmentBank dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommitmentBank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""CommitmentBank"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,1.0,0.7941176470588235,0.8852459016393442,0.550724136546217,0.3536605172445633,0.8571428522448981,0.7727272678925621,0.8571428522448981
AQ2387,Can you provide links to code used in papers that benchmark the BiT-M (ResNet) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-M (ResNet)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?model rdfs:label ""BiT-M"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.6944444444444444,0.819672131147541,0.4987588854228141,0.38056697609458356,0.8484848435996327,0.6808510590131281,0.7878787829935721
AQ1391,What is the best performing model benchmarking the ACE 2004 dataset in terms of RE+ Micro F1 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2004"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2004"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1370,What is the top benchmark score and its metric on the Nottingham dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Nottingham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_label
WHERE {
  ?dataset rdfs:label ""Burfoot and Baldwin Dataset"" .
  ?benchmark orkgp:P41003 ?dataset .
  ?benchmark orkgp:P32889 ?evaluation .
  ?evaluation orkgp:P32891 ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:P32892 ?score_node .
  ?score_node rdfs:label ?score .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.7441860465116279,0.4507042253521127,0.5614035087719298,0.23533335989209264,0.1303597748939221,0.4347826037334594,0.3243243195580716,0.4347826037334594
AQ0689,What evaluation metrics are commonly used when benchmarking models on the STEM-ECR v1.0 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STEM-ECR v1.0"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  ?dataset rdfs:label ""STEM-ECR v1.0 dataset""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.7441860465116279,0.8648648648648649,0.8,0.4573063396217801,0.275,0.6829268242950625,0.5396825347140337,0.6829268242950625
AQ2091,Can you provide links to code used in papers that benchmark the Multi-Perspective Matching (single model) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Multi-Perspective Matching (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model rdfs:label ""Multi-Perspective Matching (single model)""^^xsd:string .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9333333333333333,0.7368421052631579,0.8235294117647058,0.5626410428860615,0.425515743535916,0.8421052581717452,0.7169811271199715,0.8421052581717452
AQ0060,What models are being evaluated on the GAD dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""GAD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  VALUES ?dataset { orkgr:R116678 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P31 ?model .
  ?model rdfs:label ?model_label .
}",0,0.8518518518518519,0.5897435897435898,0.6969696969696971,0.3999340721052891,0.29387434469706253,0.645161285369407,0.5416666618055557,0.645161285369407
AQ0995,What are the metrics of evaluation over the PubMed 20k RCT dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""PubMed 20k RCT"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,1.0,0.8055555555555556,0.8923076923076924,0.580210358667772,0.3927718025274604,0.8749999950781251,0.7916666618055557,0.8749999950781251
AQ0893,List the metrics that are used to evaluate models on the Gibson PointGoal Navigation benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R123480 .
  ?benchmark orkgp:P30 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8421052631578947,0.4444444444444444,0.5818181818181818,0.24092742994958527,0.153268177914744,0.5999999952,0.4999999953719009,0.5999999952
AQ0559,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AAPD dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AAPD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""AAPD"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.8125,0.896551724137931,0.698740649251784,0.6213307756836141,0.8888888839506174,0.8095238046258505,0.8888888839506174
AQ2452,Where can I find code references in papers that have used the AxCell model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AxCell"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?model a orkgc:Model ;
           rdfs:label ""AxCell"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                  orkgp:HAS_MODEL ?model ;
                  orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.8529411764705882,0.9206349206349206,0.7677086435933281,0.6797787554389597,0.9374999950195313,0.8749999950347224,0.9374999950195313
AQ2164,Can you provide links to code used in papers that benchmark the AWD-LSTM model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AWD-LSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?model rdfs:label ""AWD-LSTM"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7142857142857143,0.8333333333333333,0.5605810063146194,0.4570363950242995,0.8749999950781251,0.7391304299338375,0.8124999950781252
AQ0452,What are the titles and IDs of research papers that include a benchmark for the PubMedQA dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMedQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""PubMedQA"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.875,0.9333333333333333,0.8152493638313232,0.7628525517801599,0.9285714235969389,0.8888888839111112,0.9285714235969389
AQ1839,Name the datasets that have been used for benchmarking in the Image Classification research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Image Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.
  FILTER (str(?problem_lbl) = ""Image Classification"")
  ?dataset       a                orkgc:Dataset;
                 rdfs:label       ?dataset_lbl.
  ?benchmark     orkgp:HAS_DATASET ?dataset.
  ?cont          orkgp:HAS_BENCHMARK ?benchmark;
                 orkgp:P32        ?problem.
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1236,"Can you provide the highest benchmark result, including the metric and score, for the Gibson PointGoal Navigation dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(xsd:double(?score)) AS ?highest_score)
WHERE {
  VALUES ?dataset { orkgr:R123480 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation ?metric ?score .
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(isLiteral(?score))
}
GROUP BY ?metric_lbl",0,0.8421052631578947,0.4383561643835616,0.5765765765765766,0.19781485269938287,0.1023685117883436,0.6530612195418576,0.4871794823898752,0.5714285664806331
AQ1639,"Which model has achieved the highest Score score on the Cheetah, run (DMControl500k) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl
WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""Cheetah, run (DMControl500k)"" .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Score"" .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:double(?value))
LIMIT 1",0,0.9636363636363636,0.7794117647058824,0.8617886178861789,0.567769981822329,0.40992933453111635,0.879999995008,0.7435897386423406,0.6799999950080001
AQ1119,What is the top benchmark score and its metric on the Stanford Dogs dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Stanford Dogs"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_label
WHERE {
  orkgr:R135174 orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation rdfs:label ?score .
}
ORDER BY DESC(xsd:double(?score))
LIMIT 1",0,0.8064516129032258,0.3472222222222222,0.48543689320388356,0.18513091449772978,0.1522553196006583,0.5454545406198348,0.43478260425120774,0.5454545406198348
AQ1505,Indicate the model that performed best in terms of Senseval 2 metric on the Supervised: benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Senseval 2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Senseval 2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1531,Indicate the model that performed best in terms of Test perplexity metric on the WikiText-103 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Test perplexity"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WikiText-103"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""Test perplexity"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?benchmark orkgp:HAS_DATASET orkgr:R120966 .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric .
      ?eval orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark .
      ?contribution orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY ASC(?value)
    LIMIT 1
  }
}",0,0.9454545454545454,0.7647058823529411,0.8455284552845528,0.5925491376424664,0.455477038367907,0.8163265256309872,0.7272727223410357,0.7346938725697626
AQ1103,"What is the highest benchmark result achieved on the WMT2016 English-Russian dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-Russian"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metricLabel ?value
WHERE {
  ?dataset rdfs:label ""WMT2016 English-Russian""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_VALUE ?value .
  OPTIONAL {
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metricLabel .
  }
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.8695652173913043,0.547945205479452,0.6722689075630252,0.3988309924836392,0.31033503498517556,0.7450980342329875,0.6172839457460754,0.7058823479584776
HQ0032,What is the most common lead compound?,"SELECT ?compound
WHERE {
  orkgr:R75638 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P35194 ?compound.
}
ORDER BY DESC(COUNT(?compound))
LIMIT 1","SELECT ?lead_compound ?label (COUNT(?lead_compound) AS ?count)
WHERE {
    ?property rdfs:label ""Lead compound"" .
    ?statement ?property ?lead_compound .
    ?lead_compound rdfs:label ?label .
}
GROUP BY ?lead_compound ?label
ORDER BY DESC(?count)
LIMIT 1",0,0.43333333333333335,0.6842105263157895,0.5306122448979592,0.1519905256861676,0.037037037037037035,0.6206896501783592,0.439024385318263,0.5517241329369797
AQ1712,What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Enduro dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model_lbl
WHERE {
    ?metric rdfs:label ""Score"" .
    {
        SELECT ?model
        WHERE {
            ?dataset rdfs:label ""Atari 2600 Enduro"" .
            ?benchmark orkgp:HAS_DATASET ?dataset .
            ?contribution orkgp:HAS_BENCHMARK ?benchmark .
            ?contribution orkgp:HAS_MODEL ?model .
            ?benchmark orkgp:HAS_EVALUATION ?evaluation .
            ?evaluation orkgp:HAS_METRIC ?metric .
            ?evaluation orkgp:HAS_VALUE ?value .
        }
        ORDER BY DESC(xsd:float(?value))
        LIMIT 1
    }
    ?model rdfs:label ?model_lbl .
}",0,0.9661016949152542,0.8382352941176471,0.8976377952755905,0.5874176665296684,0.36793822076270893,0.901960779315648,0.7901234518091754,0.7058823479430989
AQ2292,Provide a list of papers that have utilized the C51 noop model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""C51 noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_title ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R124890 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_title .
}",0,0.88,0.6285714285714286,0.7333333333333334,0.3158200251708089,0.12187637200647988,0.6874999950781251,0.5652173864555766,0.43749999507812504
AQ2069,Can you provide links to code used in papers that benchmark the FABIR model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FABIR"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""FABIR"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7058823529411765,0.8275862068965517,0.5459471157272342,0.4394937534669624,0.8666666617555556,0.7272727224380167,0.7999999950888891
HQ0084,What is the emergency type of AMBER Alert?,"SELECT DISTINCT ?emergency_type
WHERE {
  orkgr:R153500 orkgp:P31 ?contrib.
  ?contrib orkgp:P43093 ?emergency_type.
}","SELECT DISTINCT ?value_lbl
WHERE {
  orkgr:R172760 ?p ?value .
  ?p rdfs:label ""Emergency Type"" .
  ?value rdfs:label ?value_lbl .
}",0,0.47058823529411764,0.6153846153846154,0.5333333333333333,0.2545984531673679,0.14285714285714285,0.5263157844875347,0.39999999500800004,0.5263157844875347
AQ0799,List the metrics that are used to evaluate models on the CoQA benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CoQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""CoQA"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8529411764705882,0.9206349206349206,0.7433282700750228,0.647408338513295,0.8965517191914388,0.8510638248438207,0.8965517191914388
AQ1544,Indicate the model that performed best in terms of F1 metric on the OntoNotes benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""OntoNotes"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric;
    rdfs:label ?metric_lbl.
  FILTER(STR(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset;
        rdfs:label ?dataset_lbl.
      FILTER(STR(?dataset_lbl) = ""OntoNotes"")
      ?benchmark orkgp:HAS_DATASET ?dataset;
        orkgp:HAS_EVALUATION ?eval.
      ?eval orkgp:HAS_VALUE ?value;
        orkgp:HAS_METRIC ?metric.
      ?cont orkgp:HAS_BENCHMARK ?benchmark;
        orkgp:HAS_MODEL ?model.
      ?model rdfs:label ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0612,What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Defender dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Defender"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""Atari 2600 Defender"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.8235294117647058,0.9032258064516129,0.7181510302157944,0.6456941976043116,0.9032258014984391,0.8260869516068055,0.9032258014984391
AQ2287,Where can I find code references in papers that have used the Pointer + Coverage + EntailmentGen + QuestionGen model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Pointer + Coverage + EntailmentGen + QuestionGen"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model a orkgc:Model ;
         rdfs:label ""Pointer + Coverage + EntailmentGen + QuestionGen"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7837837837837838,0.8787878787878788,0.6922602820200721,0.6129719091722332,0.9189189139517896,0.8461538412204143,0.9189189139517896
AQ1931,Provide a list of papers that have utilized the Switch Transformer model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Switch Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_label ?code WHERE {
    ?paper orkgp:HAS_MODEL orkgr:R216400 .
    ?paper rdfs:label ?paper_label .
    ?paper orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5428571428571428,0.6785714285714285,0.29282785973797093,0.14261586639794224,0.7096774144849116,0.5909090861673554,0.7096774144849116
AQ0013,Can you list the models that have been evaluated on the CommonsenseQA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R162694 .
  ?paper orkgp:P31 ?contribution .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.875,0.5384615384615384,0.6666666666666667,0.3699762240135595,0.2803750339861378,0.6666666617555557,0.5652173865406428,0.6666666617555557
AQ0977,What evaluation metrics are commonly used when benchmarking models on the Amazon-2 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Amazon-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R125894 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6285714285714286,0.7457627118644068,0.4317764035063737,0.27100142665124993,0.7333333284222223,0.6666666618666668,0.7333333284222223
AQ2337,List the code links in papers that use the A3C-CTS model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C-CTS"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model rdfs:label ""A3C-CTS"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7142857142857143,0.8333333333333333,0.5605810063146194,0.4570363950242995,0.8749999950781251,0.7391304299338375,0.8124999950781252
AQ1180,What is the top benchmark score and its metric on the Hutter Prize dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Hutter Prize"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?value ?metric_lbl
WHERE {
  orkgr:R130788 orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.8666666666666667,0.3611111111111111,0.5098039215686274,0.18812246673694777,0.15526475507434484,0.604651158009735,0.5217391259903382,0.604651158009735
AQ1568,Which model has achieved the highest F1 score on the CoNLL 2003 (English) benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL 2003 (English)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_label
WHERE {
    ?dataset rdfs:label ""CoNLL 2003 (English)""^^xsd:string .
    ?metric rdfs:label ""F1 score"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}
ORDER BY DESC(xsd:decimal(?value))
LIMIT 1",0,0.9152542372881356,0.7941176470588235,0.8503937007874015,0.5739026718015495,0.4139304983580476,0.8461538411538462,0.6913580197104101,0.6153846103846154
AQ1804,What is the name of the top performing model in terms of Params score when benchmarked on the VTAB-1k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
            orkgp:HAS_METRIC ?metric .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
            orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9710144927536232,1.0,0.9852941176470589,0.9476990614658233,0.9242424242424242,0.961538456545858,0.9534883670957275,0.961538456545858
AQ2462,Can you list benchmarked problems in the area of Artificial Intelligence?,"SELECT DISTINCT ?problem ?problem_lbl
WHERE {
  ?rf       a            orkgc:ResearchField;
            rdfs:label   ?rf_label.
  FILTER (str(?rf_label) = ""Artificial Intelligence"")
  ?paper    orkgp:P30    ?rf;
            orkgp:P31    ?cont.
  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                orkgp:P32                ?problem.
  ?problem      rdfs:label               ?problem_lbl.
}","SELECT DISTINCT ?problem ?problem_lbl
WHERE {
  ?paper orkgp:P30 orkgr:R133 .
  ?paper orkgp:P31 ?contribution .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:P32 ?problem .
  ?problem rdfs:label ?problem_lbl .
}",0,0.9259259259259259,0.7142857142857143,0.8064516129032259,0.5631691681592138,0.43374746287011207,0.7499999950781251,0.723404250430059,0.7499999950781251
AQ0041,What are the models that have been benchmarked on the FSNS - Test dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FSNS - Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R114163 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}",0,0.92,0.575,0.7076923076923077,0.4226031405495641,0.32429778496465195,0.7096774144849116,0.6382978676143052,0.7096774144849116
AQ1425,What is the best performing model benchmarking the WMT2014 German-English dataset in terms of BLEU metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2355,Can you provide links to code used in papers that benchmark the BiLSTM-Attention + ELMo model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiLSTM-Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL <http://orkg.org/orkg/resource/R126015> .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.76,0.5277777777777778,0.6229508196721312,0.4097470136059329,0.3220182105415707,0.5882352891868513,0.5416666618055557,0.5294117597750866
AQ1197,"What is the highest benchmark result achieved on the STS Benchmark dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""STS Benchmark"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
  ?dataset rdfs:label ""STS Benchmark""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:P32 ?value_literal .
  BIND(xsd:double(?value_literal) AS ?value)
}
ORDER BY DESC(?value)
LIMIT 1",0,0.8260869565217391,0.5277777777777778,0.6440677966101694,0.3548576098561216,0.2510812899773653,0.6666666616753473,0.5569620204133954,0.6249999950086808
AQ2446,Provide a list of papers that have utilized the Shake-Shake (SAM) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Shake-Shake (SAM)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
    ?model rdfs:label ""Shake-Shake (SAM)"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?contribution orkgp:P31 ?paper .
}",0,0.9615384615384616,0.6944444444444444,0.8064516129032258,0.44064179687990734,0.26636572108306383,0.8124999950781252,0.6666666618055556,0.6249999950781252
AQ1854,What are the most commonly used benchmark datasets for the Joint Entity and Relation Extraction research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Joint Entity and Relation Extraction"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT ?dataset_label (COUNT(DISTINCT ?contribution) as ?count)
WHERE {
  VALUES ?problem { orkgr:R116714 }
  ?contribution orkgp:P32 ?problem .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ?dataset_label .
}
GROUP BY ?dataset ?dataset_label
ORDER BY DESC(?count)",0,0.6578947368421053,0.6578947368421053,0.6578947368421053,0.3951681831705829,0.22857142857142856,0.5499999950000001,0.4333333283388889,0.349999995
AQ0798,What evaluation metrics are commonly used when benchmarking models on the MultiRC dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MultiRC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R119491 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:P32 ?metric .
    ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.696969696969697,0.6764705882352942,0.6865671641791046,0.34400182506338783,0.1616919172827717,0.5294117597231834,0.40740740241426615,0.5294117597231834
AQ2117,Where can I find code references in papers that have used the SRU++ Base model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SRU++ Base"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""SRU++ Base"" .
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_BENCHMARK ?benchmark ;
                orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.6571428571428571,0.7931034482758621,0.486146221387841,0.3857668735414181,0.8749999950781251,0.7111111063111111,0.8124999950781252
AQ1706,Indicate the model that performed best in terms of Score metric on the Atari 2600 Asteroids benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Asteroids"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl
WHERE {
    ?dataset rdfs:label ""Atari 2600 Asteroids"" .
    ?metric rdfs:label ""Score"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?eval orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.9642857142857143,0.7941176470588235,0.8709677419354839,0.5659675482492341,0.3959445551347193,0.901960779315648,0.7594936659253325,0.6274509753940792
AQ0424,List the title and ID of research papers that contain a benchmark over the WMT2014 German-English dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R117245 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?title .
}",0,0.9130434782608695,0.6176470588235294,0.7368421052631579,0.4900078632493151,0.4029093075516414,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ0128,What are the models that have been benchmarked on the SearchQA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SearchQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_lbl
WHERE {
  VALUES ?dataset_label { ""SearchQA"" }
  ?dataset rdfs:label ?dataset_label .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9666666666666667,0.7435897435897436,0.8405797101449275,0.49916749460061943,0.30181483064810727,0.7999999950888891,0.7234042505024898,0.6666666617555557
AQ0852,What are the metrics of evaluation over the OntoNotes dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""OntoNotes"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label WHERE {
    ?contribution orkgp:P31 <http://orkg.org/orkg/resource/R46360> .
    ?contribution orkgp:P2009 ?evaluation .
    ?evaluation orkgp:P32 ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.64,0.47058823529411764,0.5423728813559322,0.19674506691253396,0.0634251205519119,0.45161289823100936,0.3829787184608421,0.45161289823100936
AQ0955,What are the metrics of evaluation over the Atari 2600 Defender dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Defender"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""Atari 2600 Defender"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  OPTIONAL {
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
  }
}",0,1.0,0.8888888888888888,0.9411764705882353,0.8371554553148339,0.7912041195586028,0.9411764656055364,0.9056603723745104,0.9411764656055364
AQ1112,"What is the highest benchmark result achieved on the WMT2014 English-German dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?highest_score)
WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET orkgr:R117257 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
    ?evaluation orkgp:HAS_VALUE ?value .
}
GROUP BY ?metric_lbl
ORDER BY DESC(?highest_score)
LIMIT 1",0,0.9130434782608695,0.5753424657534246,0.7058823529411764,0.4255640852438281,0.3232656614428912,0.734693872603082,0.7160493778448408,0.6122448930112453
AQ0678,What are the titles and IDs of research papers that include a benchmark for the PWC Leaderboards (restricted) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PWC Leaderboards (restricted)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?paper a orkgc:Paper ;
         rdfs:label ?paper_title ;
         orkgp:P31 ?contribution .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET orkgr:R128070 .
}",0,0.88,0.6470588235294118,0.7457627118644068,0.4958152504192003,0.3488381630355155,0.7499999950195314,0.6666666617876543,0.6249999950195313
AQ0835,List the metrics that are used to evaluate models on the enwik8 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwik8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R120873 .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6470588235294118,0.7586206896551724,0.4501471532096347,0.28253169865733296,0.7586206847086802,0.6818181769834711,0.7586206847086802
AQ0850,What evaluation metrics are commonly used when benchmarking models on the TempEval-3 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  VALUES ?dataset { orkgr:R121391 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.6756756756756757,0.7142857142857143,0.6944444444444444,0.43830474267749425,0.29411764705882354,0.5555555505709877,0.45614034589104346,0.5555555505709877
HQ0017,What is the most common location in the studies?,"SELECT ?locations
WHERE {
  orkgr:R111045 orkgp:compareContribution ?cont.
  ?cont orkgp:P37537 ?locations.
}
ORDER BY DESC(COUNT(?locations))
LIMIT 1","SELECT ?location_label (COUNT(?location) AS ?count)
WHERE {
  ?contribution orkgp:P30 ?location .
  ?location rdfs:label ?location_label .
}
GROUP BY ?location_label
ORDER BY DESC(?count)
LIMIT 1",0,0.5833333333333334,0.7368421052631579,0.6511627906976745,0.20144990145560465,0.047619047619047616,0.6896551674197384,0.487804873123141,0.6206896501783592
AQ2237,Provide a list of papers that have utilized the BCN+ELMo model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BCN+ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?paper a orkgc:Paper .
  ?paper orkgp:P31 ?contribution .
  ?contribution orkgp:HAS_MODEL orkgr:R122623 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8333333333333334,0.5714285714285714,0.6779661016949152,0.3312290403266935,0.18066761776749996,0.6249999950781252,0.5217391255860114,0.6249999950781252
AQ1447,Indicate the model that performed best in terms of Pre-Training Dataset metric on the HMDB51 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Pre-Training Dataset"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""HMDB51"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""Pre-Training Dataset"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""HMDB51"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
        orkgp:HAS_VALUE ?value .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.9655172413793104,0.8235294117647058,0.888888888888889,0.67582725977877,0.5508856407713129,0.8979591786755519,0.799999995028125,0.8163265256143275
AQ0313,"Can you list the models that have been evaluated on the Classical music, 5 seconds at 12 kHz dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label
WHERE {
  ?dataset rdfs:label ""Classical music, 5 seconds at 12 kHz""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.9428571428571428,0.7333333333333333,0.8250000000000001,0.5259188841717838,0.35225498112904025,0.837209297349919,0.7333333284222223,0.837209297349919
AQ1422,Indicate the model that performed best in terms of BLEU score metric on the IWSLT2014 German-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1569,Indicate the model that performed best in terms of F1 metric on the BC5CDR-disease benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_label
WHERE {
    ?metric a orkgc:Metric ;
            rdfs:label ?metric_label .
    FILTER(CONTAINS(LCASE(?metric_label), ""f1""))
    {
        SELECT ?model ?model_label
        WHERE {
            ?dataset rdfs:label ""BC5CDR-disease""^^xsd:string .
            ?benchmark orkgp:HAS_DATASET ?dataset .
            ?contribution orkgp:HAS_BENCHMARK ?benchmark .
            ?contribution orkgp:HAS_MODEL ?model .
            ?model rdfs:label ?model_label .
            ?benchmark orkgp:HAS_EVALUATION ?evaluation .
            ?evaluation orkgp:HAS_METRIC ?metric .
            ?evaluation orkgp:HAS_VALUE ?value .
        }
        ORDER BY DESC(xsd:decimal(?value))
        LIMIT 1
    }
}",0,0.8985507246376812,0.9253731343283582,0.9117647058823529,0.7110349873059569,0.5454545454545454,0.8888888839163238,0.8045976961553706,0.7407407357681758
AQ0948,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Skiing dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  ?dataset rdfs:label ""Atari 2600 Skiing""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.7317073170731707,0.8333333333333334,0.7792207792207793,0.4492476207464401,0.2631578947368421,0.6666666616962524,0.5333333283555556,0.6666666616962524
AQ0618,List the title and ID of research papers that contain a benchmark over the Atari 2600 Frostbite dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Frostbite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R125005 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.6176470588235294,0.7368421052631579,0.4900078632493151,0.4029093075516414,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ2457,Can you provide links to code used in papers that benchmark the COMET - Direct model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""COMET - Direct"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R171916 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5428571428571428,0.6785714285714285,0.393851321562034,0.3137549060754729,0.6666666618666668,0.6046511581179016,0.5999999952
AQ0331,Could you provide a list of models that have been tested on the BUCC Russian-to-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC Russian-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""BUCC Russian-to-English"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:P5101 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9666666666666667,0.6904761904761905,0.8055555555555556,0.48169749774377824,0.34757335720366483,0.7999999951020409,0.6923076874926036,0.7999999951020409
AQ1310,"What is the highest benchmark result achieved on the Atari 2600 Boxing dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1376,Which model has achieved the highest F1 score score on the Penn Treebank benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Penn Treebank"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
    ?metric rdfs:label ?metric_lbl .
    FILTER(STR(?metric_lbl) = ""F1 score"")
    {
        SELECT ?model ?model_lbl
        WHERE {
            ?dataset rdfs:label ""Penn Treebank"" .
            ?contribution orkgp:HAS_BENCHMARK ?benchmark .
            ?benchmark orkgp:HAS_DATASET ?dataset ;
                orkgp:HAS_EVALUATION ?evaluation .
            ?evaluation orkgp:HAS_METRIC ?metric ;
                orkgp:HAS_VALUE ?value .
            ?contribution orkgp:HAS_MODEL ?model .
            ?model rdfs:label ?model_lbl .
        }
        ORDER BY DESC(xsd:decimal(?value))
        LIMIT 1
    }
}",0,0.9682539682539683,0.8970588235294118,0.9312977099236641,0.7528205164850078,0.6158017587386997,0.9433962214168744,0.8674698745246046,0.7547169761338555
AQ1113,"Can you provide the highest benchmark result, including the metric and score, for the IWSLT2015 German-English dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2015 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?score
WHERE {
    ?benchmark rdfs:label ""Benchmark IWSLT2015 German-English"" .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?score .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(?score)
LIMIT 1",0,0.9444444444444444,0.4657534246575342,0.6238532110091743,0.291882257092216,0.23853412768160343,0.7391304299338375,0.6027397214411709,0.6956521690642723
AQ0961,What are the metrics of evaluation over the Atari 2600 Frostbite dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Frostbite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R125005 .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6111111111111112,0.7333333333333334,0.41415537407181474,0.2599417113054143,0.7096774144849116,0.6521739082797733,0.7096774144849116
AQ1171,What is the top benchmark score and its metric on the MultiNLI dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MultiNLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_lbl
WHERE {
  ?dataset rdfs:label ""MultiNLI""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?score .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:double(str(?score)))
LIMIT 1",0,0.8604651162790697,0.5211267605633803,0.6491228070175438,0.35480762671084065,0.2607195497878442,0.6956521689508507,0.5599999952000001,0.6521739080812855
AQ0318,Can you list the models that have been evaluated on the ImageNet ReaL dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""ImageNet ReaL"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,1.0,0.775,0.8732394366197184,0.6446811937845781,0.5343015936867903,0.8749999950781251,0.8235294068589005,0.8749999950781251
AQ1802,Which model has achieved the highest Accuracy score on the Reuters En-De benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reuters En-De"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric;
    rdfs:label ?metric_lbl.
  FILTER(str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset;
        rdfs:label ?dataset_lbl.
      FILTER(str(?dataset_lbl) = ""Reuters En-De"")
      ?benchmark orkgp:HAS_DATASET ?dataset;
        orkgp:HAS_EVALUATION ?eval.
      ?eval orkgp:HAS_VALUE ?value;
        orkgp:HAS_METRIC ?metric.
      ?contribution orkgp:HAS_BENCHMARK ?benchmark;
        orkgp:HAS_MODEL ?model.
      ?model rdfs:label ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1125,"Can you provide the highest benchmark result, including the metric and score, for the Kinetics-600 dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Kinetics-600"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?score
WHERE {
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset rdfs:label ""Kinetics-600"" .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:HAS_VALUE ?value .
  ?value rdfs:label ?score .
  BIND(xsd:decimal(REPLACE(?score, ""%"", """")) as ?score_numeric)
}
ORDER BY DESC(?score_numeric)
LIMIT 1",0,0.88,0.6111111111111112,0.7213114754098361,0.45754603557821993,0.34257256440592626,0.6938775460391503,0.6329113875404583,0.5714285664473138
AQ0980,List the metrics that are used to evaluate models on the Yelp-5 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp-5"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?dataset rdfs:label ""Yelp-5"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8,0.888888888888889,0.5660013298771387,0.3738243758742743,0.8666666617555556,0.7826086908034027,0.8666666617555556
AQ1985,Provide a list of papers that have utilized the BART model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BART"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_label ?code WHERE {
    VALUES ?model { orkgr:R116395 }
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?paper orkgp:P31 ?contribution .
    ?paper rdfs:label ?paper_label .
}",0,0.8571428571428571,0.7058823529411765,0.7741935483870968,0.3905072788929565,0.19370825928129345,0.6874999950195313,0.5531914844182889,0.37499999501953135
AQ1136,What is the top benchmark score and its metric on the Natural Questions (short) dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (short)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R119452 .
  ?benchmark orkgp:metric ?metric .
  ?metric rdfs:label ?metric_label .
  ?benchmark orkgp:P62001 ?score_literal .
  BIND(xsd:double(?score_literal) as ?score)
}
ORDER BY DESC(?score)
LIMIT 1",0,0.7647058823529411,0.3561643835616438,0.4859813084112149,0.1610994853626434,0.09219757496363538,0.5416666617447917,0.4473684163331025,0.4999999950781251
AQ1013,What evaluation metrics are commonly used when benchmarking models on the Sequential CIFAR-10 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  ?benchmark orkgp:HAS_DATASET <http://orkg.org/orkg/resource/R127024> .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.6578947368421053,0.6944444444444444,0.6756756756756757,0.41520313827696,0.2571428571428571,0.5128205078500987,0.43333332835555555,0.5128205078500987
AQ1062,What is the top benchmark score and its metric on the Automatically labeled Medline abstracts corpus dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R207063 .
  ?benchmark orkgp:P50002 ?performance .
  ?performance orkgp:P50003 ?metric_iri .
  ?metric_iri rdfs:label ?metric .
  ?performance orkgp:P50004 ?score .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.7352941176470589,0.3333333333333333,0.45871559633027525,0.13292282615522114,0.06761270239247874,0.4489795870054144,0.34210525857686985,0.4489795870054144
AQ1844,Name the datasets that have been used for benchmarking in the citation classification research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""citation classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""citation classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?contribution   orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1945,List the code links in papers that use the H-NLI model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""H-NLI"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code_link
WHERE {
    ?model rdfs:label ""H-NLI"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model ;
                  orkgp:HAS_SOURCE_CODE ?code_link .
}",0,1.0,0.6857142857142857,0.8135593220338984,0.549235822445573,0.48178031404666655,0.8749999950781251,0.7391304299338375,0.8749999950781251
AQ0652,What are the titles and IDs of research papers that include a benchmark for the PubMed 20k RCT dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?dataset rdfs:label ""PubMed 20k RCT""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?title .
}",0,0.90625,0.8529411764705882,0.8787878787878787,0.6458828820162775,0.453509754461678,0.8571428521469389,0.7450980342176087,0.7999999950040816
AQ1827,"Indicate the model that performed best in terms of Macro Recall metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Recall"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Recall"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1748,What is the name of the top performing model in terms of NLL score when benchmarked on the Nottingham dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""NLL"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Nottingham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model_lbl
WHERE {
  VALUES ?metric { orkgr:R116774 }
  {
    SELECT ?model
    WHERE {
      ?dataset rdfs:label ""Nottingham"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
        orkgp:HAS_METRIC ?metric .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
    }
    ORDER BY ASC(xsd:float(?value))
    LIMIT 1
  }
  ?model rdfs:label ?model_lbl .
}",0,0.8888888888888888,0.7272727272727273,0.7999999999999999,0.5457156805440041,0.40821906815366676,0.7755101990837152,0.6999999950031252,0.7755101990837152
AQ2068,Where can I find code references in papers that have used the DCN model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1813,What is the best performing model benchmarking the iNaturalist 2018 dataset in terms of Top-1 Accuracy metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""iNaturalist 2018"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""Top-1 Accuracy"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""iNaturalist 2018"" .
      ?cont orkgp:HAS_BENCHMARK ?benchmark .
      ?cont orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
      ?benchmark orkgp:HAS_DATASET ?dataset .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric .
      ?eval orkgp:HAS_VALUE ?value .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.967741935483871,0.8695652173913043,0.9160305343511451,0.6661014225908226,0.49960719053726255,0.901960779315648,0.8048780438072577,0.6666666616685891
AQ1300,What is the top benchmark score and its metric on the Atari 2600 Ice Hockey dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Ice Hockey"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?value ?metric_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124998 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.8421052631578947,0.43243243243243246,0.5714285714285715,0.27108304835449065,0.21049834178943352,0.6122448930612245,0.5263157848199447,0.5714285665306124
AQ1904,Provide a list of benchmarked datasets related to the Scientific Results Extraction research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Scientific Results Extraction"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem a orkgc:Problem ;
           rdfs:label ""Scientific Results Extraction""^^xsd:string .
  ?contribution orkgp:P32 ?problem ;
                orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset a orkgc:Dataset ;
           rdfs:label ?dataset_lbl .
}",0,0.9411764705882353,0.8888888888888888,0.9142857142857143,0.7124564407050595,0.5170594659849314,0.888888883888889,0.830188674247063,0.7222222172222222
AQ0547,"What are the titles and IDs of research papers that include a benchmark for the Walker, walk (DMControl500k) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl500k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?dataset rdfs:label ""Walker, walk (DMControl500k)"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?paper_title .
}",0,0.9666666666666667,0.8529411764705882,0.90625,0.6999930008016724,0.5510350527307447,0.9090909040955004,0.8163265256309872,0.84848484348944
AQ1870,Provide a list of benchmarked datasets related to the Semantic Role Labeling research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Semantic Role Labeling"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_label
WHERE {
  ?contribution orkgp:P32 orkgr:R122111 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?dataset a orkgc:Dataset .
  ?dataset rdfs:label ?dataset_label .
}",0,0.9259259259259259,0.6944444444444444,0.7936507936507936,0.4589193291351196,0.268699241465171,0.7499999950781251,0.6808510589406972,0.43749999507812504
AQ0498,Provide a list of research paper titles and IDs that have benchmarked models on the WikiText-2 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WikiText-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
    ?contribution orkgp:HAS_DATASET orkgr:R121022 .
    ?paper orkgp:P31 ?contribution .
    ?paper rdfs:label ?paper_title .
}",0,0.8947368421052632,0.5151515151515151,0.6538461538461537,0.304801882423781,0.179483614691712,0.7142857093877552,0.6341463367043427,0.6428571379591838
AQ1021,What are the metrics of evaluation over the PWC Leaderboards (restricted) dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PWC Leaderboards (restricted)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  VALUES ?dataset { orkgr:R128070 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8888888888888888,0.6666666666666666,0.761904761904762,0.4528510721893832,0.29855471273907885,0.6874999950781251,0.624999995138889,0.6874999950781251
AQ2293,List the code links in papers that use the Duel noop model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Duel noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""Duel noop"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                orkgp:HAS_MODEL ?model ;
                orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.6571428571428571,0.7931034482758621,0.486146221387841,0.3857668735414181,0.8749999950781251,0.7111111063111111,0.8749999950781251
AQ1903,List the datasets benchmarked under the Fine-Grained Image Classification research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Fine-Grained Image Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_label
WHERE {
  VALUES ?problem { orkgr:R126762 }
  ?contribution orkgp:P32 ?problem .
  ?contribution orkgp:P30 ?benchmark .
  ?benchmark orkgp:P31 ?dataset .
  ?dataset a orkgc:Dataset .
  ?dataset rdfs:label ?dataset_label .
}",0,0.8214285714285714,0.6216216216216216,0.7076923076923075,0.27343207157511523,0.08701349063065583,0.5882352891868513,0.479999995072,0.2941176421280277
AQ0721,What evaluation metrics are commonly used when benchmarking models on the DRI Corpus dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DRI Corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
    VALUES ?dataset { orkgr:R114640 }
    ?benchmark orkgp:P31 ?dataset .
    ?benchmark orkgp:P2000 ?evaluation .
    ?evaluation orkgp:P32 ?metric .
    ?metric rdfs:label ?metric_lbl .
}",0,0.75,0.5142857142857142,0.6101694915254237,0.17751779446587368,0.060222539255833325,0.4666666617555556,0.3478260821077505,0.4666666617555556
AQ0897,List the metrics that are used to evaluate models on the Oxford-IIIT Pets benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R123801 .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6111111111111112,0.7333333333333334,0.41415537407181474,0.2599417113054143,0.7096774144849116,0.6521739082797733,0.7096774144849116
AQ1742,What is the name of the top performing model in terms of Unpermuted Accuracy score when benchmarked on the Sequential CIFAR-10 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Unpermuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Unpermuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0437,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STL-10 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STL-10"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R117736 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_title .
}",0,0.9130434782608695,0.6363636363636364,0.75,0.5117824842351163,0.4208135048545422,0.7586206847086802,0.6976744137371553,0.7586206847086802
AQ0023,Could you provide a list of models that have been tested on the SciCite benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciCite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?dataset rdfs:label ""SciCite"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?evaluation .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,1.0,0.8205128205128205,0.9014084507042254,0.683400020385238,0.5818611740506991,0.8666666617555556,0.7916666618055557,0.8666666617555556
AQ0605,Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Skiing dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  VALUES ?dataset { orkgr:R124988 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,0.8888888888888888,0.7058823529411765,0.7868852459016393,0.5568491900436832,0.4501133855839897,0.709677414401665,0.6521739081285445,0.709677414401665
AQ1000,List the metrics that are used to evaluate models on the VTAB-1k benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""VTAB-1k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R126031 .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6285714285714286,0.7457627118644068,0.4317764035063737,0.27100142665124993,0.7333333284222223,0.6666666618666668,0.7333333284222223
AQ1637,What is the name of the top performing model in terms of Score score when benchmarked on the Cart Pole (OpenAI Gym) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_name
WHERE {
  ?dataset rdfs:label ""Cart Pole (OpenAI Gym)""@en .
  ?benchmark orkgp:P30004 ?dataset .
  ?benchmark orkgp:P27005 ?evaluation .
  ?evaluation orkgp:P27006 ?model .
  ?model rdfs:label ?model_name .
  ?evaluation orkgp:P4006 ?score_literal .
  BIND(xsd:decimal(str(?score_literal)) AS ?score_value)
}
ORDER BY DESC(?score_value)
LIMIT 1",0,0.7954545454545454,0.5072463768115942,0.6194690265486726,0.22400904944993147,0.09672883450307951,0.6153846103920119,0.455696197596539,0.5769230719304734
AQ2025,List the code links in papers that use the Rfa-Gate-arccos model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rfa-Gate-arccos"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model rdfs:label ""Rfa-Gate-arccos"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8823529362456748
AQ1573,Indicate the model that performed best in terms of F1 metric on the ShARe/CLEF eHealth corpus benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label
WHERE {
    ?dataset rdfs:label ""ShARe/CLEF eHealth corpus"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC orkgr:R218312 .
    ?eval orkgp:HAS_VALUE ?value .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.9607843137254902,0.7101449275362319,0.8166666666666667,0.535535221237625,0.39522291899793494,0.8627450930565167,0.7692307643129521,0.6666666616839678
AQ0797,What are the metrics of evaluation over the BioASQ dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BioASQ"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset rdfs:label ""BioASQ"" .
  ?comparison orkgp:HAS_DATASET ?dataset .
  ?comparison orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8235294117647058,0.9032258064516129,0.6118566868848531,0.4519859383230181,0.8571428522448981,0.7727272678925621,0.8571428522448981
AQ1698,What is the best performing model benchmarking the Atari 2600 Centipede dataset in terms of Score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric ;
              rdfs:label  ?metric_lbl .
  FILTER(str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset ;
                      orkgp:HAS_EVALUATION    ?eval .
      ?eval           orkgp:HAS_VALUE         ?value ;
                      orkgp:HAS_METRIC        ?metric .
      ?cont           orkgp:HAS_BENCHMARK     ?benchmark ;
                      orkgp:HAS_MODEL         ?model .
      ?model          rdfs:label              ?model_lbl .
    }
    ORDER BY DESC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.9714285714285714,1.0,0.9855072463768115,0.9484696017312617,0.9253731343283582,0.9629629579698218,0.9545454495480372,0.9629629579698218
AQ1866,What are the most commonly used benchmark datasets for the Natural Language Inference research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Natural Language Inference"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT ?dataset ?dataset_label (COUNT(DISTINCT ?contribution) AS ?count)
WHERE {
    ?problem rdfs:label ""Natural Language Inference""^^xsd:string .
    ?contribution orkgp:P32 ?problem .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ?dataset_label .
}
GROUP BY ?dataset ?dataset_label
ORDER BY DESC(?count)",0,0.6976744186046512,0.8333333333333334,0.759493670886076,0.3974660977835381,0.2,0.6999999950500001,0.5333333283833334,0.5499999950500001
AQ0299,What models are being evaluated on the Classic dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classic"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R162659 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:COMPARES_CONTRIBUTION ?contribution .
  ?contribution orkgp:USES_METHOD ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.75,0.5384615384615384,0.6268656716417911,0.29897919876405005,0.1620300449166567,0.545454540459137,0.43999999507200005,0.545454540459137
AQ2397,Where can I find code references in papers that have used the DeiT-Ti model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DeiT-Ti"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DeiT-Ti"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
HQ0027,For which country of study overall prevalence of epilepsy is the highest?,"SELECT ?country, ?country_label
WHERE {
  orkgr:R75729 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P15512 ?country.
  ?contrib orkgp:P16013 ?overall_prevalence.
  ?country rdfs:label ?country_label.
  ?overall_prevalence rdfs:label ?overall_prevalence_value
}
ORDER BY DESC(?overall_prevalence_value)
LIMIT 1","SELECT ?country_label
WHERE {
    ?contribution orkgp:P32 orkgr:R238923 .
    ?s ?contribution ?value .
    ?s ?p_country ?country_resource .
    ?p_country rdfs:label ""Country of study"" .
    ?country_resource rdfs:label ?country_label .
    ?s ?p_prevalence ?prevalence_literal .
    ?p_prevalence rdfs:label ""Has frequency (%)"" .
}
ORDER BY DESC(xsd:decimal(?prevalence_literal))
LIMIT 1",0,0.625,0.8064516129032258,0.7042253521126761,0.2806126514424086,0.10810810810810814,0.6486486437399562,0.45833332836805557,0.5405405356318481
AQ0190,Can you list the models that have been evaluated on the ShARe/CLEF eHealth corpus dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""ShARe/CLEF eHealth corpus"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.8333333333333334,0.9090909090909091,0.7080918075521493,0.6140480648084865,0.8888888839506174,0.8148148099245544,0.8888888839506174
AQ0101,Could you provide a list of models that have been tested on the HMDB51 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""HMDB51"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R118776 .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_label .
}",0,0.8333333333333334,0.38461538461538464,0.5263157894736842,0.14832449806913514,0.06228064478291955,0.6206896503210465,0.4999999953719009,0.6206896503210465
AQ0604,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Venture dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Venture"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R124986 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,0.9166666666666666,0.6470588235294118,0.7586206896551724,0.4815405425337515,0.3453165205811848,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ0816,List the metrics that are used to evaluate models on the Rotowire (Content Selection) benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Rotowire (Content Selection)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""Rotowire (Content Selection)""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9354838709677419,0.8055555555555556,0.8656716417910448,0.527381709978155,0.30394462773900927,0.823529406782007,0.7199999950720002,0.823529406782007
AQ2380,Where can I find code references in papers that have used the Tsetlin Machine model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Tsetlin Machine"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R126155 .
    ?contribution orkgp:hasBenchmark ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.85,0.4857142857142857,0.6181818181818183,0.2906174127238367,0.19450387465806487,0.5999999952,0.5116279023039481,0.5333333285333334
AQ1272,What is the top benchmark score and its metric on the Atari 2600 Breakout dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Breakout"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric_lbl (MAX(xsd:float(?value)) AS ?score)
WHERE {
    VALUES ?dataset { orkgr:R124955 }
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric_lbl
ORDER BY DESC(?score)",0,0.8888888888888888,0.547945205479452,0.6779661016949152,0.36653516884619963,0.2555953965645966,0.7199999950320001,0.6585365804729328,0.679999995032
AQ0963,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Bowling dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Bowling"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""Atari 2600 Bowling"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8888888888888888,0.9411764705882353,0.7414686106633376,0.6086185535066176,0.9090909041322315,0.8627450930872741,0.9090909041322315
AQ2321,List the code links in papers that use the FQF model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FQF"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code_link
WHERE {
  ?model rdfs:label ""FQF"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code_link .
}",0,1.0,0.7058823529411765,0.8275862068965517,0.5459471157272342,0.4394937534669624,0.8666666617555556,0.7272727224380167,0.7999999950888891
AQ1373,Indicate the model that performed best in terms of Sequence error metric on the FSNS - Test benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Sequence error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(str(?metric_lbl) = ""Sequence error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY ASC(?value)
    LIMIT 1
  }
}",0,0.9852941176470589,0.9852941176470589,0.9852941176470589,0.9381838671227531,0.8769230769230769,0.9615384565384616,0.9534883670930233,0.9230769180769233
AQ1163,What is the top benchmark result (metric and value) over the dataset ARC (Challenge)?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ARC (Challenge)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset a orkgc:Dataset ;
        rdfs:label ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""ARC (Challenge)"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value .
      OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
      }
      ?cont orkgp:HAS_BENCHMARK ?benchmark .
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8611111111111112,0.9253731343283582,0.8402014065542222,0.8221959760533197,0.9803921518646674,0.977777772780247,0.9803921518646674
AQ0348,What are the titles and IDs of research papers that include a benchmark for the SciREX dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciREX"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:P39051 orkgr:R146863 .
  ?contribution orkgp:P36029 ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.8095238095238095,0.53125,0.6415094339622642,0.35736358903098947,0.2632266739092858,0.592592587654321,0.5365853609994051,0.592592587654321
AQ0696,Can you list the metrics used to evaluate models on the TSE-NER dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TSE-NER"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
    ?dataset rdfs:label ""TSE-NER"" .
    ?dataset orkgp:P41998 ?evaluation .
    ?evaluation rdf:predicate ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.8571428571428571,0.5142857142857142,0.6428571428571428,0.2208057020344203,0.08556951983876535,0.6206896503210465,0.49999999525826455,0.6206896503210465
AQ1939,Where can I find code references in papers that have used the Concept Mention Extraction model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Concept Mention Extraction"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model a orkgc:Model ;
         rdfs:label ""Concept Mention Extraction""^^xsd:string .
  ?cont orkgp:HAS_MODEL ?model ;
        orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9285714285714286,0.7222222222222222,0.8125000000000001,0.5766915464669468,0.4508863758451715,0.8648648598685172,0.7450980342637449,0.8648648598685172
AQ2094,List the code links in papers that use the OTF spelling+lemma (single) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""OTF spelling+lemma (single)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""OTF spelling+lemma (single)"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7297297297297297,0.8437499999999999,0.5872074839067538,0.48908897325461903,0.8888888839506174,0.759999995128,0.8333333283950618
AQ2315,Provide a list of papers that have utilized the A3C LSTM hs model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C LSTM hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
    ?model rdfs:label ""A3C LSTM hs"" .
    ?paper orkgp:P31 ?contribution .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9615384615384616,0.6944444444444444,0.8064516129032258,0.44064179687990734,0.26636572108306383,0.8235294068339101,0.6666666618055556,0.7647058774221455
AQ1812,Which model has achieved the highest Percentage error score on the SVHN benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Percentage error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SVHN"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
    ?metric a orkgc:Metric ;
            rdfs:label ""Percentage error"" .
    {
        SELECT ?model ?model_lbl
        WHERE {
            ?benchmark orkgp:HAS_DATASET orkgr:R126694 ;
                       orkgp:HAS_EVALUATION ?eval .
            ?eval orkgp:HAS_METRIC ?metric ;
                  orkgp:HAS_VALUE ?value .
            ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                          orkgp:HAS_MODEL ?model .
            ?model rdfs:label ?model_lbl .
        }
        ORDER BY DESC(xsd:decimal(REPLACE(str(?value), "","", """")))
        LIMIT 1
    }
}",0,0.9137931034482759,0.7910447761194029,0.848,0.6611953130348351,0.5293290200431733,0.8679245233179067,0.795180717892292,0.7924528252046993
AQ2216,Where can I find code references in papers that have used the LayerNorm HM-LSTM model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""LayerNorm HM-LSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""LayerNorm HM-LSTM"" .
  ?model a orkgc:Model .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.8055555555555556,0.8923076923076924,0.6173931795581932,0.4531982336855312,0.914285709322449,0.799999995072,0.7999999950367347
AQ1905,List the datasets benchmarked under the SPARQL query optimization research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""SPARQL query optimization"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset_label
WHERE {
    ?problem rdfs:label ""SPARQL query optimization"" .
    ?contribution orkgp:P32 ?problem .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ?dataset_label .
}",0,1.0,0.7777777777777778,0.8750000000000001,0.5005990436184606,0.2705318255071029,0.8749999950781251,0.7659574419194206,0.6874999950781251
AQ1320,"What is the highest benchmark result achieved on the Amazon-2 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon-2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET orkgr:R125894 .
  orkgr:R125894 rdfs:label ""Amazon-2"" .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:HAS_VALUE ?value .
}
ORDER BY DESC(xsd:double(REPLACE(STR(?value), ""[^0-9.]"", """")))
LIMIT 1",0,0.7884615384615384,0.5694444444444444,0.661290322580645,0.4276186257298063,0.3195180645191401,0.6792452780206479,0.5783132480708376,0.5660377308508366
AQ2207,Can you provide links to code used in papers that benchmark the Temporal Convolutional Network model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Temporal Convolutional Network"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model rdfs:label ""Temporal Convolutional Network"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8823529362456748
AQ2437,Provide a list of papers that have utilized the BiT-S (ResNet) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-S (ResNet)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?model rdfs:label ""BiT-S (ResNet)"" .
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_SOURCE_CODE ?code ;
                orkgp:P30 ?paper .
}",0,0.9583333333333334,0.6388888888888888,0.7666666666666666,0.4166905900209262,0.28882412367268256,0.8235294068339101,0.6666666618055556,0.8235294068339101
AQ1176,"What is the highest benchmark result achieved on the WNLI dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WNLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""WNLI"")
      ?benchmark     orkgp:P31        ?dataset ;
                     orkgp:P20087     ?eval .
      ?eval          orkgp:P27        ?value .
      OPTIONAL {
        ?eval        orkgp:P32        ?metric .
        ?metric      rdfs:label       ?metric_lbl .
      }
      ?cont          orkgp:P20086     ?benchmark .
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,0.9107142857142857,0.7183098591549296,0.8031496062992126,0.5864048963675923,0.4907656620613498,0.7755101990837152,0.7356321789139914,0.7755101990837152
AQ1245,"Can you provide the highest benchmark result, including the metric and score, for the AAPD dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AAPD"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?score
WHERE {
    ?dataset rdfs:label ""AAPD"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:metric ?metric_label .
    ?evaluation orkgp:value ?score_literal .
    BIND(xsd:decimal(str(?score_literal)) AS ?score) .
}
ORDER BY DESC(?score)
LIMIT 1",0,0.8717948717948718,0.4788732394366197,0.6181818181818182,0.2502208544984634,0.1345073430624633,0.7234042503395203,0.5789473635907203,0.5957446758714352
AQ0002,What models are being evaluated on the FTD dataset dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FTD dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?dataset rdfs:label ""FTD dataset"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:COMPARES_CONTRIBUTION ?model .
  ?model rdfs:label ?model_label .
}",0,0.9310344827586207,0.675,0.7826086956521738,0.4829311014452433,0.3684871079283495,0.7333333284222223,0.6382978675237664,0.7333333284222223
AQ1664,What is the best performing model benchmarking the CIFAR-10 Image Classification dataset in terms of Percentage error metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Percentage error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CIFAR-10 Image Classification"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl (?value AS ?score)
WHERE {
  VALUES ?dataset { orkgr:R116789 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ""Percentage error"" .
  ?eval orkgp:HAS_VALUE ?value .
}
ORDER BY ASC(?value)
LIMIT 1",0,0.9090909090909091,0.7142857142857143,0.8,0.4728342820764911,0.3074482330891221,0.7307692257988165,0.6172839456790125,0.4615384565680473
AQ1233,"What is the highest benchmark result achieved on the Walker, walk (DMControl500k) dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric_lbl ?value
    WHERE {
      ?dataset a orkgc:Dataset ;
        rdfs:label ""Walker, walk (DMControl500k)"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value .
      OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
      }
      ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    }
  }
}
GROUP BY ?metric_lbl
ORDER BY DESC(?score)",0,1.0,0.7671232876712328,0.8682170542635659,0.6806394195189659,0.5988984508164332,0.9411764656055364,0.9213483096225223,0.9019607793310267
AQ0713,What evaluation metrics are commonly used when benchmarking models on the SciGEN dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciGEN"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
    orkgr:R206393 orkgp:P32 ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.7692307692307693,0.29411764705882354,0.4255319148936171,0.08450162511170119,0.03976283774761484,0.5384615337278107,0.3684210483102493,0.5384615337278107
AQ2311,List the code links in papers that use the POP3D model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""POP3D"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?cont           orkgp:HAS_MODEL          orkgr:R124916;
                  orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:HAS_SOURCE_CODE    ?code.
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
}",0,0.9166666666666666,0.6470588235294118,0.7586206896551724,0.47020223210203105,0.3139241096192589,0.7333333284222223,0.6818181769834711,0.4666666617555556
AQ1723,Indicate the model that performed best in terms of Score metric on the Atari 2600 Tennis benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0786,What evaluation metrics are commonly used when benchmarking models on the UCF101 (finetuned) dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UCF101 (finetuned)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?eval) AS ?count)
WHERE {
  ?dataset rdfs:label ""UCF101 (finetuned)""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.725,0.8285714285714286,0.7733333333333333,0.4440264614019057,0.2702702702702703,0.6486486436815194,0.5172413743341262,0.6486486436815194
AQ0522,Provide a list of research paper titles and IDs that have benchmarked models on the MPQA dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MPQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R122689 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.65625,0.7636363636363634,0.5345247103444989,0.4395133161456359,0.7857142807397959,0.7142857093877552,0.7857142807397959
AQ1212,"What is the highest benchmark result achieved on the BC5CDR-chemical dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-chemical"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  VALUES ?dataset { orkgr:R122891 }
  ?cont orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
  ?eval orkgp:HAS_VALUE ?value .
}
GROUP BY ?metric ?metric_lbl
ORDER BY DESC(?score)",0,0.9375,0.625,0.75,0.4700134391088478,0.36391839582758007,0.7659574418650975,0.7249999951125001,0.6382978673970123
AQ1649,Which model has achieved the highest SUCCESS score on the Habitat 2020 Object Nav test-std benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SUCCESS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SUCCESS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1337,"Can you provide the highest benchmark result, including the metric and score, for the Paper Field dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Paper Field"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?score
WHERE {
  VALUES ?dataset { orkgr:R41176 }
  ?benchmark orkgp:P20031 ?dataset .
  ?benchmark orkgp:P30010 ?evaluation .
  ?evaluation orkgp:P30011 ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:P30012 ?score .
  FILTER(isNumeric(?score))
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.6923076923076923,0.375,0.48648648648648646,0.14291687619827712,0.05959194457543176,0.4166666617013889,0.2857142809040311,0.3749999950347223
AQ1673,Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot English-to-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1267,"What is the highest benchmark result achieved on the Atari 2600 Double Dunk dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Double Dunk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124933 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.868421052631579,0.44594594594594594,0.5892857142857143,0.269508878668973,0.1994194816952528,0.6530612195918367,0.5263157848199447,0.5306122400000001
AQ2078,Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (ensemble) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo (ensemble)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R119658 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5,0.6440677966101696,0.34142100644952944,0.27198719401502147,0.606060601432507,0.5652173867674859,0.5454545408264463
AQ1231,"What is the top benchmark score and its metric on the Cheetah, run (DMControl500k) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R123348 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?score .
    OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
    }
}
ORDER BY DESC(?score)
LIMIT 1",0,0.8888888888888888,0.4383561643835616,0.5871559633027523,0.28833120054889344,0.24937658803076723,0.6521739081947071,0.5945945899598247,0.6521739081947071
AQ0511,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STS Benchmark dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STS Benchmark"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?dataset rdfs:label ""STS Benchmark"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?cont orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?cont .
  ?paper rdfs:label ?title .
}",0,1.0,0.8484848484848485,0.9180327868852458,0.69071784037721,0.5687957289592287,0.8888888839506174,0.8095238046258505,0.8888888839506174
AQ1286,What is the top benchmark score and its metric on the Atari 2600 Alien dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Alien"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?score
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124981 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
    BIND(xsd:double(?value) as ?score)
}
ORDER BY DESC(?score)
LIMIT 1",0,0.8292682926829268,0.4657534246575342,0.5964912280701754,0.30452904558543886,0.21703379359622915,0.6122448930112453,0.5641025593129521,0.5714285664806331
AQ1353,"What is the highest benchmark result achieved on the Birdsnap dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Birdsnap"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
  ?dataset rdfs:label ""Birdsnap"" .
  ?benchmark orkgp:P32001 ?dataset .
  ?benchmark orkgp:P32003 ?evaluation .
  ?evaluation orkgp:P32002 ?metric .
  ?metric rdfs:label ?metric_label .
  ?evaluation orkgp:P32004 ?value_resource .
  ?value_resource rdfs:label ?value .
  FILTER(isNumeric(xsd:double(?value)))
}
ORDER BY DESC(xsd:double(?value))
LIMIT 1",0,0.7555555555555555,0.4788732394366197,0.5862068965517241,0.2413647920578301,0.12024513613874775,0.48888888395061736,0.35135134658509865,0.4444444395061729
AQ0287,What models are being evaluated on the Atari 2600 Chopper Command dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Chopper Command"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R124957 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:COMPARES_CONTRIBUTION ?contribution .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.7777777777777778,0.5,0.6086956521739131,0.2640697463247114,0.14343835518435818,0.5142857093877552,0.42307691826183436,0.5142857093877552
AQ1767,Indicate the model that performed best in terms of Accuracy metric on the Stanford Cars benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Stanford Cars"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_label
WHERE {
  ?metric rdfs:label ""Accuracy"" .
  {
    SELECT ?model ?model_label
    WHERE {
      ?dataset rdfs:label ""Stanford Cars"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?evaluation .
      ?evaluation orkgp:HAS_METRIC ?metric ;
        orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_label .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9642857142857143,0.8059701492537313,0.8780487804878049,0.6410687545135503,0.5115996345966022,0.8749999950086805,0.763157889792244,0.7916666616753474
AQ1492,Indicate the model that performed best in terms of Precision metric on the RotoWire (Relation Generation) benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark orkgp:HAS_DATASET ?dataset .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric .
      ?eval orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark .
      ?contribution orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,0.9552238805970149,0.9411764705882353,0.9481481481481482,0.8567559322808546,0.7542826164057763,0.9803921518646674,0.9382715999573237,0.901960779315648
AQ0808,List the metrics that are used to evaluate models on the SQuAD1.1 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SQuAD1.1"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metricLabel
WHERE {
  ?dataset rdfs:label ""SQuAD1.1"" .
  ?evaluation orkgp:HAS_DATASET ?dataset .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metricLabel .
}",0,1.0,0.6571428571428571,0.7931034482758621,0.440334881360926,0.2967437488780139,0.8275862020451843,0.7272727225309917,0.8275862020451843
AQ2130,Provide a list of papers that have utilized the Large mLSTM model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Large mLSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code WHERE {
    ?model rdfs:label ""Large mLSTM"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?paper_resource orkgp:P31 ?contribution .
    ?paper_resource rdfs:label ?paper .
}",0,0.896551724137931,0.7428571428571429,0.8125,0.45970372777600926,0.25018577225201155,0.8124999950781252,0.6808510589406972,0.6249999950781252
AQ0007,What models are being evaluated on the ACL Anthology dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ACL Anthology"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?model orkgp:P17001 orkgr:R221766 .
  ?model rdfs:label ?model_label .
}",0,0.7857142857142857,0.275,0.40740740740740744,0.08754944237938928,0.05677019829671675,0.4999999954081633,0.42857142429705225,0.4999999954081633
AQ1787,Which model has achieved the highest Score score on the Atari 2600 Yars Revenge benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Yars Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric;
          rdfs:label ?metric_lbl.
  FILTER(STR(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset;
               rdfs:label ?dataset_lbl.
      FILTER(STR(?dataset_lbl) = ""Atari 2600 Yars Revenge"")
      ?benchmark orkgp:HAS_DATASET ?dataset;
                 orkgp:HAS_EVALUATION ?eval.
      ?eval orkgp:HAS_VALUE ?value;
            orkgp:HAS_METRIC ?metric.
      ?cont orkgp:HAS_BENCHMARK ?benchmark;
            orkgp:HAS_MODEL ?model.
      ?model rdfs:label ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0182,What models are being evaluated on the NCBI-disease dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_lbl
WHERE {
  ?dataset rdfs:label ""NCBI-disease"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.7,0.8235294117647058,0.49498664293933686,0.3387483099161489,0.8387096725494276,0.7499999952170139,0.8387096725494276
AQ1044,"Can you provide the highest benchmark result, including the metric and score, for the Softcite dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Softcite"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric_lbl ?score
WHERE {
  ?dataset rdfs:label ""Softcite dataset"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?score .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(?score)
LIMIT 1",0,0.9555555555555556,0.6056338028169014,0.7413793103448275,0.43917168084265734,0.33401426705207715,0.772727267820248,0.6575342418465003,0.5909090860020663
AQ0779,What are the metrics of evaluation over the Fashion-MNIST dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Fashion-MNIST"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_label
WHERE {
  ?dataset rdfs:label ?dataset_lbl .
  FILTER(CONTAINS(STR(?dataset_lbl), ""Fashion-MNIST""))
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:P200003 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9259259259259259,0.7142857142857143,0.8064516129032259,0.5386863329321439,0.4027655012365326,0.8124999950195313,0.7083333284114585,0.8124999950195313
AQ1578,What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-2 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""X-Sum"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""X-Sum"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0474,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RotoWire (Relation Generation) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""RotoWire"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.7647058823529411,0.8666666666666666,0.6227409972837211,0.5433654421764624,0.8275862020451843,0.7272727224380167,0.8275862020451843
AQ2095,Can you provide links to code used in papers that benchmark the Fine-Grained Gating model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Fine-Grained Gating"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R119705 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5277777777777778,0.6666666666666666,0.3755360357665399,0.299164347507027,0.6451612855775234,0.5909090862809917,0.5806451565452655
AQ1788,What is the best performing model benchmarking the Atari 2600 Montezuma's Revenge dataset in terms of Average Return (NoOp) metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Average Return (NoOp)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label ?value
WHERE {
    VALUES ?dataset { orkgr:R125001 }
    ?metric rdfs:label ""Average Return (NoOp)""^^xsd:string .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?eval orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}
ORDER BY DESC(xsd:float(?value))
LIMIT 1",0,0.8793103448275862,0.7083333333333334,0.7846153846153847,0.5120160732811889,0.3713478860259626,0.7368421002770082,0.6279069717874528,0.6666666616805171
AQ2295,Provide a list of papers that have utilized the Prior noop model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Prior noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
    ?model rdfs:label ""Prior noop"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?paper orkgp:P31 ?contribution .
    ?paper a orkgc:Paper .
}",0,0.9285714285714286,0.7428571428571429,0.8253968253968255,0.4485664234604612,0.24921625058284957,0.823529406782007,0.6666666617447917,0.5882352891349482
AQ1416,What is the best performing model benchmarking the WMT2016 English-Russian dataset in terms of BLEU score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-Russian"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""BLEU score""^^xsd:string .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""WMT2016 English-Russian""^^xsd:string .
      ?benchmark orkgp:HAS_DATASET ?dataset .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric .
      ?eval orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark .
      ?contribution orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9090909090909091,0.8695652173913043,0.888888888888889,0.6339834680964431,0.45503001727061154,0.888888883888889,0.7294117597121108,0.8148148098148148
AQ1780,What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the Oxford-IIIT Pets dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Error Rate"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Error Rate"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY ASC(?value)
    LIMIT 1
  }
}",0,0.9859154929577465,0.9859154929577465,0.9859154929577465,0.9636162552773174,0.9411764705882353,0.9642857092857144,0.9565217341304348,0.9642857092857144
AQ0445,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Reuters-21578 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters-21578"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R119113 .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,0.8947368421052632,0.5151515151515151,0.6538461538461537,0.304801882423781,0.179483614691712,0.7142857093877552,0.6341463367043427,0.6428571379591838
AQ0157,What models are being evaluated on the Penn Treebank (Character Level) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""Penn Treebank (Character Level)"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.7380952380952381,0.8493150684931507,0.5708091457509625,0.4508270645273133,0.8571428522448981,0.7692307644156804,0.8571428522448981
AQ2376,Provide a list of papers that have utilized the ANODE model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ANODE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R126151 .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution .
  ?paper a orkgc:Paper .
}",0,0.8333333333333334,0.5882352941176471,0.6896551724137931,0.3039217787452866,0.12556964384770355,0.645161285369407,0.5454545406198348,0.3870967692403746
AQ2426,Provide a list of papers that have utilized the DY-MobileNetV3-Small model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DY-MobileNetV3-Small"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?contribution orkgp:HAS_MODEL orkgr:R126652 .
  ?paper orkgp:P31 ?contribution .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8571428571428571,0.5,0.631578947368421,0.2640066559614243,0.1359837943213759,0.5806451565452655,0.4999999953719009,0.5161290275130074
AQ1070,"What is the highest benchmark result achieved on the FSNS - Test dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?value
WHERE {
  VALUES ?dataset { orkgr:R114163 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:decimal(?value))
LIMIT 1",0,0.825,0.4583333333333333,0.5892857142857143,0.3000931828930234,0.23073649508722188,0.5957446759076506,0.5066666619235556,0.5957446759076506
AQ2238,Where can I find code references in papers that have used the MPAD-path model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MPAD-path"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ""MPAD-path"" .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7142857142857143,0.8333333333333333,0.5431773813981758,0.42656730202267956,0.8749999950781251,0.7391304299338375,0.8749999950781251
AQ0114,What are the models that have been benchmarked on the BoolQ dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BoolQ"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""BoolQ"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:compareContribution ?contribution .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9230769230769231,0.6153846153846154,0.7384615384615384,0.35365385414695005,0.21096718598700295,0.6896551675624257,0.5652173865406428,0.6896551675624257
AQ1357,"Can you provide the highest benchmark result, including the metric and score, for the BUCC German-to-English dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8648648648648649,0.927536231884058,0.8448051792695033,0.8273012182153758,0.9818181768198347,0.9787233992575827,0.9818181768198347
AQ1638,"Which model has achieved the highest Score score on the Ball in cup, catch (DMControl100k) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2087,List the code links in papers that use the Multi-Perspective Matching (ensemble) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Multi-Perspective Matching (ensemble)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL orkgr:R119679 .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5135135135135135,0.6551724137931034,0.35807246653363134,0.2852522943426942,0.6249999953125001,0.5777777731950617,0.6249999953125001
AQ1439,What is the best performing model benchmarking the ImageNet 64x64 dataset in terms of Bits per dim metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Bits per dim"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?value
WHERE {
    ?dataset rdfs:label ""ImageNet 64x64""^^xsd:string .
    ?metric rdfs:label ""Bits per dim""^^xsd:string .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?evaluation orkgp:HAS_VALUE ?value_node .
    ?value_node rdfs:label ?value .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY ASC(xsd:double(?value))
LIMIT 1",0,0.8615384615384616,0.8115942028985508,0.835820895522388,0.5721777884513444,0.3943263911994014,0.830188674247063,0.6829268242950625,0.6792452780206479
AQ1144,What is the top benchmark result (metric and value) over the dataset CommonsenseQA?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  ?dataset rdfs:label ""CommonsenseQA"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric_lbl",0,1.0,0.6056338028169014,0.7543859649122806,0.4208706640870544,0.2998274822560208,0.8095238047052155,0.739726022668418,0.7142857094671202
HQ0046,Are children examined in the studies?,"ASK {
  orkgr:R44979 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P23161 ?population.
  FILTER(REGEX(?population, ""ildren""))
}","SELECT DISTINCT ?participant ?label
WHERE {
  ?s orkgp:P33 ?participant .
  ?participant rdfs:label ?label .
  FILTER(STR(?label) = ""children"")
}",0,0.35294117647058826,0.42857142857142855,0.3870967741935484,0.04213287322556837,0.007142857142857146,0.2857142807256236,0.21428570931122462,0.2857142807256236
AQ1142,"What is the highest benchmark result achieved on the CoQA dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label (MAX(?value) AS ?score)
WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET orkgr:R119496 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?score)",0,0.9545454545454546,0.5915492957746479,0.7304347826086957,0.42156276705854717,0.30370021031806654,0.7999999950617285,0.7532467483892732,0.7111111061728396
AQ1345,What is the top benchmark score and its metric on the ImageNet V2 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet V2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_lbl
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R126096 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_VALUE ?score .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.8378378378378378,0.4305555555555556,0.5688073394495412,0.27449803563803765,0.2169979241979128,0.6086956472589792,0.5205479405441922,0.6086956472589792
AQ1633,"Which model has achieved the highest Score score on the Reacher, easy (DMControl500k) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl (MAX(?value) as ?score)
WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""Reacher, easy (DMControl500k)"" .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation . 
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Score"" .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
} 
GROUP BY ?model_lbl
ORDER BY DESC(?score)
LIMIT 1",0,0.9333333333333333,0.8235294117647058,0.8749999999999999,0.5964314348974735,0.4299097005825005,0.862745093041138,0.7228915612715926,0.6666666616685891
AQ0792,List the metrics that are used to evaluate models on the Quasart-T benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Quasart-T"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""Quasart-T"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9629629629629629,0.7428571428571429,0.8387096774193549,0.450561997367229,0.24785569306863545,0.7999999950888891,0.6956521690642723,0.7999999950888891
AQ0097,Can you list the models that have been evaluated on the Multimodal PISA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Multimodal PISA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
    ?contribution orkgp:HAS_DATASET orkgr:R118532 .
    ?contribution orkgp:P31 ?model .
    ?model rdfs:label ?model_label .
}",0,0.8421052631578947,0.4,0.5423728813559322,0.1951892209310469,0.1241713998566292,0.5999999952,0.4888888843061729,0.5999999952
AQ0914,Can you list the metrics used to evaluate models on the Barabasi-Albert dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Barabasi-Albert"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?benchmark rdfs:label ""Benchmark Barabasi-Albert""^^xsd:string .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.84,0.6,0.7000000000000001,0.2907897401427106,0.12187637200647988,0.6874999950195313,0.553191484472612,0.6874999950195313
AQ0933,Can you list the metrics used to evaluate models on the Atari 2600 Zaxxon dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Zaxxon"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label WHERE {
    ?contribution orkgp:HAS_DATASET orkgr:R124957 .
    orkgr:R124957 rdfs:label ""Atari 2600 Zaxxon"" .
    ?contribution orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.8709677419354839,0.75,0.8059701492537312,0.5504831776434913,0.364733553286811,0.823529406782007,0.705882347989235,0.823529406782007
AQ1251,What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-Spanish?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Spanish"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Spanish"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1433,Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric;
          rdfs:label ""BLEU score"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset;
               rdfs:label ""WMT2016 English-German"" .
      ?benchmark orkgp:HAS_DATASET ?dataset;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value;
            orkgp:HAS_METRIC ?metric .
      ?cont orkgp:HAS_BENCHMARK ?benchmark;
            orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9682539682539683,0.8840579710144928,0.9242424242424243,0.8105026698140542,0.742477761682649,0.9259259209259261,0.8735632133914653,0.9259259209259261
AQ1886,Provide a list of benchmarked datasets related to the Sentence Classification research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Sentence Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ""Sentence Classification""^^xsd:string.
  ?dataset       a                orkgc:Dataset;
                 rdfs:label       ?dataset_lbl.
  ?benchmark     orkgp:HAS_DATASET ?dataset.
  ?cont          orkgp:HAS_BENCHMARK ?benchmark;
                 orkgp:P32         ?problem.
}",0,0.9393939393939394,0.8857142857142857,0.9117647058823529,0.7946745379743382,0.7215820207623717,0.8823529361764706,0.8235294067666282,0.8823529361764706
AQ0818,List the metrics that are used to evaluate models on the RotoWire (Content Ordering) benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RotoWire (Content Ordering)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R120301 .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6111111111111112,0.7333333333333334,0.41415537407181474,0.2599417113054143,0.7096774144849116,0.6521739082797733,0.7096774144849116
AQ0912,What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Italian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?dataset rdfs:label ""MLDoc Zero-Shot English-to-Italian"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.9166666666666666,0.8461538461538461,0.8799999999999999,0.65623551735229,0.5018424079796309,0.8717948668244576,0.7857142807716837,0.8717948668244576
AQ1928,Provide a list of papers that have utilized the Tokenlearner model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Tokenlearner"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_title ?code
WHERE {
  ?model rdfs:label ""Tokenlearner"" .
  ?paper a orkgc:Paper ;
         rdfs:label ?paper_title ;
         orkgp:P31 ?contribution .
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8571428571428571,0.7058823529411765,0.7741935483870968,0.44663857199123325,0.2582776790417246,0.8124999950195313,0.666666661701389,0.7499999950195314
AQ0159,What models are being evaluated on the MedSTS dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MedSTS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label
WHERE {
    ?evaluation orkgp:HAS_DATASET orkgr:R121068 .
    ?evaluation orkgp:USES ?model .
    ?model a orkgc:Model .
    ?model rdfs:label ?model_label .
}",0,0.8571428571428571,0.46153846153846156,0.6,0.1616494325945737,0.047152538408549986,0.709677414401665,0.5531914845450431,0.645161285369407
AQ1567,What is the best performing model benchmarking the CoNLL++ dataset in terms of F1 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL++"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ""F1"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ""CoNLL++"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9666666666666667,0.8787878787878788,0.9206349206349207,0.7754826652978721,0.6667223080264965,0.9166666616666667,0.8641975258649597,0.874999995
AQ0443,Provide a list of research paper titles and IDs that have benchmarked models on the UCF101 (finetuned) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UCF101 (finetuned)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R118775 .
  ?cont orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?cont ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.6363636363636364,0.75,0.5117824842351163,0.4208135048545422,0.7586206847086802,0.6976744137371553,0.7586206847086802
AQ0653,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciCite dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciCite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""SciCite"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,1.0,0.84375,0.9152542372881356,0.6798988416478599,0.5539669266008613,0.8888888839506174,0.8095238046258505,0.8888888839506174
AQ2436,Can you provide links to code used in papers that benchmark the ImageNet + iNat on WS-DAN model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ImageNet + iNat on WS-DAN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ""WS-DAN"" .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?benchmark orkgp:HAS_DATASET orkgr:R157437 .
  ?benchmark orkgp:HAS_DATASET ?dataset_inat .
  ?dataset_inat rdfs:label ?dataset_inat_label .
  FILTER(CONTAINS(LCASE(?dataset_inat_label), ""inat""))
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.7333333333333333,0.868421052631579,0.7951807228915663,0.5719029595965851,0.42857142857142855,0.8095238045238096,0.6885245851652781,0.6190476140476191
AQ1017,Can you list the metrics used to evaluate models on the BUCC Russian-to-English dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC Russian-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  orkgr:R131716 orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.9,0.4864864864864865,0.631578947368421,0.30246164826691163,0.22627849338462,0.6451612855775234,0.5777777731950617,0.6451612855775234
AQ1687,What is the best performing model benchmarking the AESLC dataset in terms of ROUGE-1 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AESLC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
          rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""ROUGE-1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""AESLC"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
            orkgp:HAS_METRIC ?metric .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9710144927536232,1.0,0.9852941176470589,0.9476990614658233,0.9242424242424242,0.959999995008,0.9534883670957275,0.959999995008
AQ1361,What is the top benchmark score and its metric on the ModelNet40 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ModelNet40"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?value ?metric_lbl
WHERE {
  ?dataset rdfs:label ""ModelNet40"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value ;
        orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:decimal(REPLACE(STR(?value), ""[^0-9.]"", """")))
LIMIT 1",0,0.8333333333333334,0.49295774647887325,0.6194690265486726,0.3536646731117128,0.2828056452285537,0.6666666616753473,0.5789473635907203,0.6249999950086808
AQ0735,List the metrics that are used to evaluate models on the Penn Treebank benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset rdfs:label ""Penn Treebank"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8285714285714286,0.90625,0.6245054155602469,0.4690983229725217,0.8666666617555556,0.7826086908034027,0.8666666617555556
AQ0102,Could you provide a list of models that have been tested on the Reuters-21578 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters-21578"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""Reuters-21578"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.725,0.8405797101449275,0.5465958389008033,0.42112812334668515,0.8387096725494276,0.7499999952170139,0.8387096725494276
AQ1689,What is the best performing model benchmarking the Atari 2600 Seaquest dataset in terms of Score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""Score"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""Atari 2600 Seaquest"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
            orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0,1.0,0.8235294117647058,0.9032258064516129,0.6969484906702448,0.593916832702079,0.9387755052228238,0.8461538412064432,0.8571428521615995
AQ0726,What are the metrics of evaluation over the seel.cse.lsu.edu/data/re17.zip  dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset rdfs:label ""seel.cse.lsu.edu/data/re17.zip"" .
  ?contribution orkgp:HAS_DATASET ?dataset ;
                orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.825,0.9041095890410958,0.6920840942226401,0.5931688746001991,0.8999999950500001,0.8214285665306122,0.8999999950500001
AQ0666,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ObjectNet dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""ObjectNet"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,1.0,0.84375,0.9152542372881356,0.6798988416478599,0.5539669266008613,0.8888888839506174,0.8095238046258505,0.8888888839506174
AQ0970,List the metrics that are used to evaluate models on the Atari 2600 HERO benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 HERO"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset a orkgc:Dataset;
    rdfs:label ?dataset_lbl.
  FILTER(str(?dataset_lbl) = ""Atari 2600 HERO"")
  ?benchmark orkgp:HAS_DATASET ?dataset;
    orkgp:HAS_EVALUATION ?eval.
  OPTIONAL {
    ?eval orkgp:HAS_METRIC ?metric.
    ?metric rdfs:label ?metric_lbl.
  }
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0634,What are the titles and IDs of research papers that include a benchmark for the Amazon-2 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Amazon-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R125894 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?title .
}",0,0.9130434782608695,0.6363636363636364,0.75,0.5117824842351163,0.4208135048545422,0.7586206847086802,0.6976744137371553,0.7586206847086802
AQ2318,Provide a list of papers that have utilized the Rainbow+SEER model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rainbow+SEER"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  ?paper orkgp:HAS_MODEL orkgr:R124926 .
  ?paper orkgp:HAS_SOURCE_CODE ?code .
}",0,0.8823529411764706,0.42857142857142855,0.5769230769230769,0.19941502697734453,0.0991038986448264,0.6206896504637337,0.5365853613563355,0.6206896504637337
AQ1449,What is the name of the top performing model in terms of Accuracy (High) score when benchmarked on the RACE dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy (High)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RACE"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy (High)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RACE"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0422,Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 English-Romanian dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 English-Romanian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R117312 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,0.9166666666666666,0.6470588235294118,0.7586206896551724,0.4815405425337515,0.3453165205811848,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ1023,Can you list the metrics used to evaluate models on the MUTAG dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MUTAG"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
    ?contribution orkgp:HAS_DATASET orkgr:R128146 .
    ?contribution orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}",0,0.92,0.6764705882352942,0.7796610169491526,0.5123813455010912,0.38055072331147144,0.7586206847086802,0.6818181769834711,0.7586206847086802
AQ0861,What evaluation metrics are commonly used when benchmarking models on the ESC-50 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ESC-50"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  VALUES ?dataset { orkgr:R122340 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.6756756756756757,0.7142857142857143,0.6944444444444444,0.43830474267749425,0.29411764705882354,0.5555555505709877,0.45614034589104346,0.5555555505709877
AQ1466,Which model has achieved the highest F1 score on the SQuAD1.1 dev benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SQuAD1.1 dev"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ""F1"" .
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""SQuAD1.1 dev""^^xsd:string .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
        orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(?value))
    LIMIT 1
  }
}",0,0.9333333333333333,0.8235294117647058,0.8749999999999999,0.6527652863104172,0.5066792899722328,0.879999995,0.7560975559875075,0.7999999950000002
AQ0164,What models are being evaluated on the TempEval-3 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET <http://orkg.org/orkg/resource/R121391> .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}",0,0.7857142857142857,0.55,0.6470588235294117,0.3943673837458209,0.26057562301242226,0.647058818546713,0.5882352892118416,0.5294117597231834
AQ1494,What is the best performing model benchmarking the RotoWire (Content Ordering) dataset in terms of BLEU metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Content Ordering)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl (?value AS ?score)
WHERE {
  ?dataset rdfs:label ""RotoWire (Content Ordering)""^^xsd:string .
  ?metric rdfs:label ""BLEU""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?eval orkgp:HAS_VALUE ?value .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:double(?value))
LIMIT 1",0,0.8870967741935484,0.8088235294117647,0.8461538461538463,0.5641019925302974,0.3846444751160522,0.8461538411538462,0.6829268242801905,0.7307692257692308
AQ1263,What is the top benchmark score and its metric on the Atari 2600 Seaquest dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0172,Could you provide a list of models that have been tested on the GENIA - LAS benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""GENIA - LAS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?model orkgp:HAS_DATASET orkgr:R122302 .
  ?model rdfs:label ?model_lbl .
}",0,0.8666666666666667,0.325,0.4727272727272728,0.12209247494033898,0.0786981678489841,0.6206896504637337,0.5116279025851812,0.6206896504637337
AQ0523,Provide a list of research paper titles and IDs that have benchmarked models on the Yelp Binary classification dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp Binary classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R122706 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.6176470588235294,0.7368421052631579,0.4900078632493151,0.4029093075516414,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ1761,Indicate the model that performed best in terms of Accuracy metric on the Amazon benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0607,What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Bank Heist dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Bank Heist"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R124990 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.6,0.7241379310344828,0.46915967904804723,0.3857668735414181,0.7096774144849116,0.6666666618666668,0.7096774144849116
AQ1513,What is the name of the top performing model in terms of A2 score when benchmarked on the ANLI test dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""A2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ANLI test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model_lbl
WHERE {
  ?metric rdfs:label ""A2"" .
  {
    SELECT ?model_lbl
    WHERE {
      ?dataset rdfs:label ""ANLI test"" .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric ;
            orkgp:HAS_VALUE ?value .
      ?contribution orkgp:HAS_BENCHMARK ?benchmark ;
                    orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:float(?value))
    LIMIT 1
  }
}",0,0.9636363636363636,0.7910447761194029,0.8688524590163933,0.6077560447691343,0.4483730434540088,0.8979591786755519,0.7948717899013809,0.8163265256143275
AQ0148,Could you provide a list of models that have been tested on the QNLI benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""QNLI"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.717948717948718,0.835820895522388,0.5334319888546144,0.4050751122916418,0.8275862020451843,0.7391304300189037,0.8275862020451843
AQ0611,What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Asterix dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Asterix"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R124994 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9130434782608695,0.6176470588235294,0.7368421052631579,0.4900078632493151,0.4029093075516414,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ2328,Can you provide links to code used in papers that benchmark the MFEC model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MFEC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model a orkgc:Model ;
         rdfs:label ""MFEC"" .
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_BENCHMARK ?benchmark ;
                orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7058823529411765,0.8275862068965517,0.5871858468617078,0.5022785753908142,0.9032258014984391,0.7999999951209876,0.9032258014984391
AQ2411,Can you provide links to code used in papers that benchmark the CAIT-XS-36 model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CAIT-XS-36"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?model rdfs:label ""CAIT-XS-36""^^xsd:string .
}",0,0.9285714285714286,0.7222222222222222,0.8125000000000001,0.535185267704692,0.3907681923991487,0.8333333283487654,0.6938775461224491,0.5555555505709877
AQ0040,What models are being evaluated on the seel.cse.lsu.edu/data/re17.zip  dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ?dataset_lbl .
  FILTER(STR(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip"")
  ?eval orkgp:HAS_DATASET ?dataset .
  ?eval orkgp:HAS_RESULT ?result .
  ?result orkgp:P2008 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9459459459459459,0.7777777777777778,0.8536585365853658,0.6186184157791542,0.4975524488535926,0.837209297349919,0.7540983557215802,0.837209297349919
AQ1752,Indicate the model that performed best in terms of Score metric on the Atari 2600 Montezuma's Revenge benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_label
WHERE {
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""Atari 2600 Montezuma's Revenge"" .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Score"" .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
}
ORDER BY DESC(xsd:float(?value))
LIMIT 1",0,0.9649122807017544,0.7857142857142857,0.8661417322834646,0.581481376504393,0.42751821128465034,0.8888888838957477,0.7560975560232005,0.7407407357475996
AQ1810,What is the best performing model benchmarking the ImageNet ReaL dataset in terms of Params metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?score
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R126249 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""Params"" .
    ?eval orkgp:HAS_VALUE ?score .
}
ORDER BY ASC(xsd:float(?score))
LIMIT 1",0,0.9019607843137255,0.6865671641791045,0.7796610169491525,0.48707738963047387,0.3349131455640146,0.7499999950086805,0.639999995072,0.5416666616753474
AQ2418,Can you provide links to code used in papers that benchmark the ResNet-152 (SAM) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ResNet-152 (SAM)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""ResNet-152 (SAM)"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8235294068339101
AQ1073,"Can you provide the highest benchmark result, including the metric and score, for the Pubmed dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Pubmed"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R76744 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric_lbl",0,0.9428571428571428,0.4647887323943662,0.6226415094339622,0.28192701639006207,0.21227591764388176,0.7142857094671202,0.6478873193017258,0.7142857094671202
AQ0536,"Provide a list of research paper titles and IDs that have benchmarked models on the Walker, walk (DMControl100k) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl100k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?dataset rdfs:label ""Walker, walk (DMControl100k)""^^xsd:string .
  ?contribution orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:P31 ?contribution ;
         a orkgc:Paper ;
         rdfs:label ?paper_title .
}",0,0.8888888888888888,0.7058823529411765,0.7868852459016393,0.4749916655288931,0.2893586050182791,0.8235294067647059,0.6938775460391503,0.7647058773529413
AQ1367,"What is the highest benchmark result achieved on the REDDIT-B dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""REDDIT-B"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric ?value
WHERE {
  ?dataset rdfs:label ""REDDIT-B"" ;
           a orkgc:Dataset .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:metric ?metric ;
        orkgp:P32 ?value_literal .
  BIND(xsd:double(?value_literal) AS ?value)
}
ORDER BY DESC(?value)
LIMIT 1",0,0.8461538461538461,0.4583333333333333,0.5945945945945945,0.2290942400895526,0.13110227806594987,0.6938775460391503,0.5384615336226167,0.612244892977926
AQ0015,What models are being evaluated on the Softcite dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Softcite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R166515 }
  ?benchmark orkgp:P30004 ?dataset .
  ?contribution orkgp:P30002 ?benchmark .
  ?contribution orkgp:P31 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.76,0.48717948717948717,0.59375,0.21751683126011548,0.10385619342705725,0.4666666617555556,0.34042552709823454,0.4666666617555556
AQ0181,Could you provide a list of models that have been tested on the SST-2 Binary classification benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SST-2 Binary classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R41325 }
  ?benchmark orkgp:P20084 ?dataset .
  ?contribution orkgp:P32 ?benchmark .
  ?contribution orkgp:P31 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.76,0.4523809523809524,0.5671641791044777,0.19292012297455388,0.09211218043010722,0.42424241946740127,0.319999995288,0.42424241946740127
AQ1134,What is the top benchmark score and its metric on the Hendrycks Test dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Hendrycks Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_label
WHERE {
  VALUES ?dataset { orkgr:R235618 }
  ?benchmark orkgp:P31 ?dataset .
  ?benchmark orkgp:P2005 ?evaluation .
  ?evaluation orkgp:P32 ?score .
  ?evaluation orkgp:P33 ?metric .
  ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(xsd:double(str(?score)))
LIMIT 1",0,0.7027027027027027,0.3611111111111111,0.47706422018348627,0.13535430189888203,0.05710471689418758,0.4255319099502037,0.29333332859022226,0.3829787184608421
AQ2348,Can you provide links to code used in papers that benchmark the KD-LSTMreg model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""KD-LSTMreg"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  VALUES ?model { orkgr:R125942 }
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.875,0.6,0.711864406779661,0.45445844211056047,0.3613352355349999,0.6451612854526535,0.5777777729777778,0.5806451564203955
AQ0379,What are the titles and IDs of research papers that include a benchmark for the NLP-TDMS dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NLP-TDMS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""NLP-TDMS"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.8181818181818182,0.9,0.7087694662405772,0.6339171106424729,0.8965517191914388,0.8181818132747933,0.8965517191914388
AQ0209,Can you list the models that have been evaluated on the ClueWeb09-B dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ClueWeb09-B"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
  ?contribution orkgp:P32 ?model .
  ?contribution orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P27 ?dataset .
  ?dataset rdfs:label ""ClueWeb09-B"" .
  ?model rdfs:label ?model_label .
}",0,0.9259259259259259,0.625,0.7462686567164178,0.3823247377551659,0.25744473099329696,0.7096774144849116,0.5833333285503473,0.5806451564203955
AQ1029,Can you list the metrics used to evaluate models on the DocRED (Human-annotated) dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DocRED (Human-annotated)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R172698 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6111111111111112,0.7333333333333334,0.41415537407181474,0.2599417113054143,0.7096774144849116,0.6521739082797733,0.7096774144849116
AQ2413,Provide a list of papers that have utilized the CvT-21 (384 res) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CvT-21 (384 res)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_label ?code
WHERE {
  VALUES ?model { orkgr:R126452 }
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_label .
}",0,0.8461538461538461,0.5945945945945946,0.6984126984126985,0.34864825841516284,0.19935642220436592,0.6285714236734695,0.5199999951280001,0.3428571379591837
AQ2071,Can you provide links to code used in papers that benchmark the FG fine-grained gate model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FG fine-grained gate"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL orkgr:R119604 .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5135135135135135,0.6551724137931034,0.35807246653363134,0.2852522943426942,0.6249999953125001,0.5777777731950617,0.5624999953125002
AQ1082,"What is the highest benchmark result achieved on the NYT29 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT29"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?value
WHERE {
    ?dataset rdfs:label ""NYT29""^^xsd:string .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(?value)
LIMIT 1",0,0.9111111111111111,0.5774647887323944,0.7068965517241379,0.41551116816600103,0.307293125687911,0.7111111061728396,0.621621616855369,0.5333333283950618
AQ0834,Can you list the metrics used to evaluate models on the QNLI dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_lbl
WHERE {
  ?contribution orkgp:HAS_DATASET orkgr:R120855 .
  ?contribution orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,0.9166666666666666,0.6470588235294118,0.7586206896551724,0.4501471532096347,0.28253169865733296,0.7586206847086802,0.6818181769834711,0.7586206847086802
AQ1405,Which model has achieved the highest Entity F1 score on the SciERC benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Entity F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SciERC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Entity F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SciERC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0863,What evaluation metrics are commonly used when benchmarking models on the SST-5 Fine-grained classification dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SST-5 Fine-grained classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(?metric) AS ?count)
WHERE {
  ?dataset rdfs:label ""SST-5 Fine-grained classification""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.7441860465116279,0.8421052631578947,0.7901234567901234,0.47957600807198436,0.3,0.6976744136289887,0.5624999950195313,0.6976744136289887
AQ1155,"Can you provide the highest benchmark result, including the metric and score, for the Natural Questions (long) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (long)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R119751 ;
               orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value ;
          orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric_lbl
ORDER BY DESC(?score)",0,0.9459459459459459,0.4794520547945205,0.6363636363636364,0.2927572395820815,0.21121166040508862,0.7391304299338375,0.7012986965424186,0.6956521690642723
AQ1116,What is the top benchmark result (metric and value) over the dataset WMT2016 Czech-English?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 Czech-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""WMT2016 Czech-English"")
      ?benchmark     orkgp:HAS_DATASET       ?dataset ;
                     orkgp:HAS_EVALUATION    ?eval .
      ?eval          orkgp:HAS_VALUE         ?value .
      OPTIONAL {
        ?eval        orkgp:HAS_METRIC        ?metric .
        ?metric      rdfs:label              ?metric_lbl .
      }
      ?cont          orkgp:HAS_BENCHMARK     ?benchmark .
      OPTIONAL {
        ?cont        orkgp:HAS_MODEL         ?model .
        ?model       rdfs:label              ?model_lbl .
      }
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
HQ0068,Which sectors are modeled as energy sectors and how often?,"SELECT ?label COUNT(?label)
WHERE {
  ?sector rdfs:label ?label;
          a ?class.
  ?class owl:equivalentClass <http://openenergy-platform.org/ontology/oeo/OEO_00000367>.
  [
    orkgp:P37668 ?sector
  ].
}","SELECT ?sectorLabel (COUNT(?contribution) AS ?count)
WHERE {
  ?contribution orkgp:P37601 ?sector.
  ?sector rdfs:label ?sectorLabel.
}
GROUP BY ?sectorLabel
ORDER BY DESC(?count)",0,0.5909090909090909,0.5416666666666666,0.5652173913043478,0.2608907948088502,0.09611586487181707,0.4666666617555556,0.4186046461654949,0.399999995088889
AQ0439,Provide a list of research paper titles and IDs that have benchmarked models on the Kinetics-600 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Kinetics-600"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
    ?benchmark orkgp:HAS_DATASET <http://orkg.org/orkg/resource/R118363> .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper a orkgc:Paper .
    ?paper rdfs:label ?title .
}",0,0.7407407407407407,0.6060606060606061,0.6666666666666666,0.42247942366173585,0.26691246763893595,0.6666666616712582,0.583333328342014,0.6060606010651974
AQ0473,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Rotowire (Content Selection) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Rotowire (Content Selection)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?dataset rdfs:label ""Rotowire (Content Selection)"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_title .
}",0,1.0,0.8529411764705882,0.9206349206349206,0.7008189028129329,0.5826675046619655,0.9032258014984391,0.8260869516068055,0.9032258014984391
HQ0058,"What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request? ","SELECT ?precision ?recall ?f1
WHERE {
  orkgr:R112387 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P15006 ?algorithms.
  ?algorithms rdfs:label ?alg_names.
  FILTER(REGEX(?alg_names, ""Naive bayes""))
  ?algorithms orkgp:P36075 ?features.
  ?features rdfs:label ?fea_names.
  FILTER(REGEX(?fea_names, ""Bag of words""))
  ?features orkgp:P37029 ?categories.
  ?categories rdfs:label ?cat_names.
  FILTER(REGEX(?cat_names, ""Feature request""))
  ?categories orkgp:P3004 ?precision;
              orkgp:P5015 ?recall;
              orkgp:P18037 ?f1.
}","SELECT ?precision ?recall ?f1
WHERE {
    ?contribution orkgp:P31 ?problem .
    ?problem rdfs:label ""classify user feedback as feature request"" .
    ?contribution orkgp:P32 ?algorithm .
    ?algorithm rdfs:label ""Naive bayes"" .
    ?contribution orkgp:P32 ?feature .
    ?feature rdfs:label ""Bag-of-Words"" .
    ?contribution orkgp:P30 ?evaluation .
    ?evaluation orkgp:P4000 ?precision .
    ?evaluation orkgp:P4001 ?recall .
    ?evaluation orkgp:P4002 ?f1 .
}",0,0.7924528301886793,0.7,0.743362831858407,0.3473454580788936,0.1577294745537771,0.5531914843639657,0.37142856644489797,0.4680851013852422
AQ0551,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Dmlab-30 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Dmlab-30"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""Dmlab-30"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,1.0,0.8484848484848485,0.9180327868852458,0.69071784037721,0.5687957289592287,0.8965517191914388,0.8181818132747933,0.8965517191914388
AQ0425,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 German-English dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 German-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R117250 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_lbl .
}",0,0.9166666666666666,0.6470588235294118,0.7586206896551724,0.4815405425337515,0.3453165205811848,0.7333333284222223,0.6818181769834711,0.7333333284222223
AQ1227,"What is the highest benchmark result achieved on the Cartpole, swingup (DMControl500k) dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cartpole, swingup (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric ?metric_lbl ?value
WHERE {
  ?dataset a orkgc:Dataset ;
           rdfs:label ""Cartpole, swingup (DMControl500k)"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?value .
  OPTIONAL {
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
  }
}
ORDER BY DESC(?value)
LIMIT 1",0,0.9534883720930233,0.5616438356164384,0.7068965517241379,0.4551379084041651,0.4355238100718665,0.7916666617447918,0.7341772103701331,0.7916666617447918
AQ0033,What are the models that have been benchmarked on the Automatically labeled Medline abstracts corpus dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  VALUES ?dataset { orkgr:R207063 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.8518518518518519,0.5348837209302325,0.6571428571428571,0.32196952516950894,0.20733450047955096,0.5714285666285714,0.49999999526627237,0.5714285666285714
AQ2167,"List the code links in papers that use the LSTM (Bai et al., 2018) model in any benchmark?","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""LSTM (Bai et al., 2018)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL orkgr:R68911 .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5,0.6440677966101696,0.34142100644952944,0.27198719401502147,0.606060601432507,0.5652173867674859,0.606060601432507
AQ1240,What is the top benchmark result (metric and value) over the dataset Oxford-IIIT Pets?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?value
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R123801 .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?evaluation orkgp:HAS_VALUE ?value .
    ?metric rdfs:label ?metric_label .
}
ORDER BY DESC(xsd:decimal(?value))
LIMIT 1",0,0.8378378378378378,0.4246575342465753,0.5636363636363636,0.2635914251801876,0.20009525722587343,0.5957446759619739,0.5135135088787436,0.553191484472612
AQ2226,Can you provide links to code used in papers that benchmark the XLNet-Large model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""XLNet-Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_MODEL orkgr:R122148 .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.9047619047619048,0.5428571428571428,0.6785714285714285,0.393851321562034,0.3137549060754729,0.6666666618666668,0.6046511581179016,0.6666666618666668
AQ2385,Where can I find code references in papers that have used the EfficientNetV2-L model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""EfficientNetV2-L"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""EfficientNetV2-L"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0,1.0,0.9714285714285714,0.9855072463768115,0.9474114688990278,0.9083703226445381,0.999999995,0.999999995,0.999999995
AQ0647,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-46985 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WOS-46985"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""WOS-46985"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?cont orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?cont ;
         rdfs:label ?paper_lbl .
}",0,1.0,0.8181818181818182,0.9,0.7087694662405772,0.6339171106424729,0.8965517191914388,0.8181818132747933,0.8965517191914388
AQ1168,"What is the highest benchmark result achieved on the Supervised: dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl ?value
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R120656 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
    }
}
ORDER BY DESC(?value)
LIMIT 1",0,0.8888888888888888,0.4507042253521127,0.5981308411214953,0.30480291178026314,0.2636229101009675,0.6818181769111571,0.6111111064236111,0.6818181769111571
AQ1514,What is the best performing model benchmarking the ANLI test dataset in terms of A3 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""A3"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ANLI test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?value
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R120747 .
    ?paper orkgp:HAS_BENCHMARK ?benchmark .
    ?paper orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation ?metric ?value_lit .
    ?metric rdfs:label ""A3"" .
    FILTER(isLiteral(?value_lit))
    BIND(xsd:double(?value_lit) AS ?value)
}
ORDER BY DESC(?value)
LIMIT 1",0,0.8627450980392157,0.6567164179104478,0.7457627118644067,0.4352601088356641,0.304466495967286,0.719999995,0.5714285664698938,0.5199999950000002
AQ1001,What are the metrics of evaluation over the iNaturalist 2019 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""iNaturalist 2019"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
    ?contribution orkgp:HAS_DATASET orkgr:R126080 .
    ?contribution orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
}",0,0.9166666666666666,0.6285714285714286,0.7457627118644068,0.4317764035063737,0.27100142665124993,0.7333333284222223,0.6666666618666668,0.7333333284222223
AQ0282,What are the models that have been benchmarked on the Atari 2600 Space Invaders dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Space Invaders"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset a orkgc:Dataset;
    rdfs:label ""Atari 2600 Space Invaders"" .
  ?benchmark orkgp:HAS_DATASET ?dataset;
    orkgp:HAS_EVALUATION ?eval .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  OPTIONAL {
    ?paper orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
  }
}",0,1.0,0.9047619047619048,0.9500000000000001,0.8617366679783488,0.8229372582877797,0.9473684160664821,0.915254232301063,0.9473684160664821
AQ1430,Which model has achieved the highest BLEU score score on the WMT2014 English-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model ?model_lbl
WHERE {
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""WMT2014 English-German"" .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ""BLEU score"" .
    ?evaluation orkgp:HAS_VALUE ?value .
}
ORDER BY DESC(xsd:double(str(?value)))
LIMIT 1",0,0.9655172413793104,0.8115942028985508,0.8818897637795277,0.5815671095578764,0.4061017676141794,0.9056603723602706,0.7654320938027741,0.6415094289640443
AQ0543,Provide a list of research paper titles and IDs that have benchmarked models on the Cart Pole (OpenAI Gym) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R123346 .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper a orkgc:Paper .
  ?paper rdfs:label ?paper_title .
}",0,0.8695652173913043,0.5714285714285714,0.689655172413793,0.37153451080172994,0.23739499910241113,0.6874999950781251,0.6086956473251418,0.6249999950781252
AQ2308,Provide a list of papers that have utilized the A3C FF hs model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C FF hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
    ?model rdfs:label ""A3C FF hs"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?contribution orkgp:P31 ?paper .
}",0,0.9615384615384616,0.6944444444444444,0.8064516129032258,0.44064179687990734,0.26636572108306383,0.8235294068339101,0.6666666618055556,0.6470588185986159
AQ2073,Where can I find code references in papers that have used the BiDAF + Self Attention + ELMo model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?model orkgp:P32 ?part1 .
    ?part1 rdfs:label ""BiDAF"" .
    ?model orkgp:P32 ?part2 .
    ?part2 rdfs:label ""Self Attention"" .
    ?model orkgp:P32 ?part3 .
    ?part3 rdfs:label ""ELMo"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.6888888888888889,0.8378378378378378,0.7560975609756098,0.4667355569552777,0.3333333333333333,0.8648648598977356,0.6296296246570645,0.7567567517896275
AQ0874,List the metrics that are used to evaluate models on the NCBI Disease benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI Disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R122956 .
  orkgr:R122956 rdfs:label ""NCBI Disease""^^xsd:string .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8125,0.7428571428571429,0.7761194029850748,0.48946180182144383,0.28257218111794163,0.7647058773529413,0.627450975409458,0.7647058773529413
AQ2203,Where can I find code references in papers that have used the 6-layer QRNN model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""6-layer QRNN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""6-layer QRNN"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8235294068339101
AQ0301,What models are being evaluated on the WOS-11967 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WOS-11967"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""WOS-11967"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.725,0.8405797101449275,0.5465958389008033,0.42112812334668515,0.8387096725494276,0.7499999952170139,0.8387096725494276
AQ0410,List the title and ID of research papers that contain a benchmark over the NYT24 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NYT24"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset rdfs:label ""NYT dataset"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution ;
         rdfs:label ?paper_lbl .
}",0,0.9629629629629629,0.8125,0.8813559322033898,0.6762427827444184,0.5885898595134152,0.8148148098765432,0.7619047570068028,0.8148148098765432
AQ1878,Name the datasets that have been used for benchmarking in the Robot Navigation research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Robot Navigation"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset_label
WHERE {
    ?problem rdfs:label ""Robot Navigation""^^xsd:string .
    ?contribution orkgp:P32 ?problem .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ?dataset_label .
}",0,0.9310344827586207,0.7714285714285715,0.8437500000000001,0.4752518332837487,0.25018577225201155,0.8124999950195313,0.680851058886374,0.6249999950195313
AQ0039,Could you provide a list of models that have been tested on the seel.cse.lsu.edu/data/refsq17.zip benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/refsq17.zip"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label WHERE {
    ?dataset rdfs:label ""seel.cse.lsu.edu/data/refsq17.zip"" .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:P1659 ?model .
    ?model a orkgc:Method .
    ?model rdfs:label ?model_label .
}",0,0.9428571428571428,0.7333333333333333,0.8250000000000001,0.48398856355784836,0.3052876503118349,0.837209297349919,0.7213114704756787,0.7906976694429422
AQ0298,Could you provide a list of models that have been tested on the IMDb-M benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""IMDb-M"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""IMDb-M"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?model orkgp:HAS_BENCHMARK ?benchmark .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.6,0.7499999999999999,0.40295636796185724,0.29338121087576685,0.7999999952000001,0.6956521692533082,0.7999999952000001
AQ2274,Where can I find code references in papers that have used the PEGASUS model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PEGASUS"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_MODEL ?model .
  ?model rdfs:label ""PEGASUS"" .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7058823529411765,0.8275862068965517,0.5278641531590126,0.40810134250503655,0.8666666617555556,0.7272727224380167,0.5333333284222223
AQ1873,Provide a list of benchmarked datasets related to the Audio Classification research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Audio Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset_label
WHERE {
    ?paper orkgp:P32 orkgr:R122330 .
    ?paper orkgp:P2005 ?benchmark .
    ?benchmark orkgp:P2006 ?dataset .
    ?dataset rdfs:label ?dataset_label .
}",0,0.8095238095238095,0.4857142857142857,0.6071428571428571,0.08381109971516153,0.002852317327958844,0.5517241330796672,0.41860464638182804,0.3448275813555292
AQ1229,"Can you provide the highest benchmark result, including the metric and score, for the Cart Pole (OpenAI Gym) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_label ?score
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R123346 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
  ?eval orkgp:P20005 ?score_literal .
  BIND(xsd:double(?score_literal) as ?score)
}
ORDER BY DESC(?score)
LIMIT 1",0,0.8,0.43243243243243246,0.5614035087719298,0.27020501321370716,0.1963798335980636,0.5599999950720002,0.5063291091555842,0.5199999950720001
AQ0537,"What are the titles and IDs of research papers that include a benchmark for the Reacher, easy (DMControl100k) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset a orkgc:Dataset;
           rdfs:label ?dataset_lbl.
  FILTER(STR(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
  ?benchmark orkgp:HAS_DATASET ?dataset.
  ?cont orkgp:HAS_BENCHMARK ?benchmark.
  ?paper orkgp:P31 ?cont;
         rdfs:label ?paper_lbl.
}",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1622,Which model has achieved the highest MACs score on the ImageNet benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""MACs"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT ?model_lbl ?score
WHERE {
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ""ImageNet"" .
    ?benchmark orkgp:HAS_EVALUATION ?evaluation .
    ?evaluation orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_label .
    FILTER(CONTAINS(LCASE(?metric_label), ""macs""))
    ?evaluation orkgp:HAS_VALUE ?score .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_lbl .
}
ORDER BY DESC(xsd:float(?score))
LIMIT 1",0,0.9322033898305084,0.8333333333333334,0.8800000000000001,0.6173523098221455,0.4440619281962569,0.8571428521449397,0.7435897386028928,0.571428566430654
AQ1088,"Can you provide the highest benchmark result, including the metric and score, for the ACE 2005 dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2005"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric ?score
WHERE {
  VALUES ?dataset { orkgr:R116636 }
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:HAS_METRIC ?metric_uri .
  ?metric_uri rdfs:label ?metric .
  ?evaluation orkgp:HAS_VALUE ?score .
  FILTER(isNumeric(?score))
}
ORDER BY DESC(xsd:decimal(str(?score)))
LIMIT 1",0,0.8181818181818182,0.5,0.6206896551724137,0.3326974512143947,0.24524520703660868,0.6399999950080001,0.5316455647556483,0.5199999950080001
AQ0978,List the metrics that are used to evaluate models on the DBpedia benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DBpedia"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  VALUES ?dataset { orkgr:R164340 }
  ?evaluation orkgp:P29 ?dataset .
  ?evaluation orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.75,0.4411764705882353,0.5555555555555556,0.15827521728446392,0.05842180044604818,0.4999999951020409,0.3720930184748513,0.4999999951020409
AQ1287,What is the top benchmark result (metric and value) over the dataset Atari 2600 Enduro?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset a orkgc:Dataset ;
               rdfs:label ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?contribution orkgp:HAS_BENCHMARK ?benchmark .
      ?benchmark orkgp:HAS_DATASET ?dataset ;
                 orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value .
      OPTIONAL {
        ?eval orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label ?metric_lbl .
      }
    }
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,0.8082191780821918,0.8939393939393939,0.7674018815804783,0.7324236997011168,0.9411764656055364,0.9318181768414256,0.9019607793310267
AQ0837,What are the metrics of evaluation over the Hutter Prize dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Hutter Prize"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  VALUES ?benchmark { orkgr:R130788 }
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.8095238095238095,0.4857142857142857,0.6071428571428571,0.23390476682849212,0.11409269311835378,0.5999999950888889,0.4888888840888889,0.5999999950888889
AQ1069,"Can you provide the highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/re17.zip  dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ1296,What is the top benchmark score and its metric on the Atari 2600 Wizard of Wor dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Wizard of Wor"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Wizard of Wor"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ2142,List the code links in papers that use the 12-layer Transformer-XL model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""12-layer Transformer-XL"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code WHERE {
    ?contribution orkgp:HAS_MODEL <http://orkg.org/orkg/resource/R120918> .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,0.76,0.5135135135135135,0.6129032258064517,0.39368060339678357,0.3093916959030704,0.5714285665306124,0.530612240066639,0.5142857093877552
AQ1718,What is the best performing model benchmarking the Atari 2600 Up and Down dataset in terms of Score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Up and Down"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","An error occurred (check API key and internet connection): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",0,0.08695652173913043,0.02857142857142857,0.04301075268817204,0.0012762513501061085,0.0006478861137669156,0.08333332847222251,0.0,0.08333332847222251
AQ0336,"Could you provide a list of models that have been tested on the NLP-TDMS (Exp, arXiv only) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label
WHERE {
  VALUES ?dataset { orkgr:R128074 }
  ?evaluation orkgp:HAS_DATASET ?dataset .
  ?evaluation orkgp:USES_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.8181818181818182,0.4186046511627907,0.5538461538461539,0.19408548043288779,0.10131239445354831,0.5714285666285714,0.47058823061899274,0.5714285666285714
AQ0163,What are the models that have been benchmarked on the  Jacquard dataset dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "" Jacquard dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label "" Jacquard dataset"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?model orkgp:HAS_BENCHMARK ?benchmark ;
         rdfs:label ?model_lbl .
}",0,1.0,0.575,0.7301587301587301,0.36915624769478367,0.2626409376922838,0.7857142809438777,0.6818181771900826,0.7857142809438777
AQ1009,What are the metrics of evaluation over the ObjectNet dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0492,Provide a list of research paper titles and IDs that have benchmarked models on the enwik8 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwik8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R120873 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?paper_title .
}",0,0.9166666666666666,0.6875,0.7857142857142857,0.5233883656885842,0.37532592458627057,0.7857142807397959,0.7142857093877552,0.7857142807397959
AQ1654,Indicate the model that performed best in terms of PARAMS metric on the FGVC Aircraft benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""PARAMS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FGVC Aircraft"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric a orkgc:Metric ;
    rdfs:label ?metric_lbl .
  FILTER(str(?metric_lbl) = ""PARAMS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset a orkgc:Dataset ;
        rdfs:label ?dataset_lbl .
      FILTER(str(?dataset_lbl) = ""FGVC Aircraft"")
      ?benchmark orkgp:HAS_DATASET ?dataset ;
        orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_VALUE ?value ;
        orkgp:HAS_METRIC ?metric .
      ?cont orkgp:HAS_BENCHMARK ?benchmark ;
        orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY ASC(?value)
    LIMIT 1
  }
}",0,0.9850746268656716,0.9850746268656716,0.9850746268656716,0.9613658593861555,0.9375,0.9599999950000001,0.9523809473809525,0.9599999950000001
AQ0964,List the metrics that are used to evaluate models on the Atari 2600 Battle Zone benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Battle Zone"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset rdfs:label ""Atari 2600 Battle Zone"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}",0,1.0,0.8378378378378378,0.911764705882353,0.6474169620293946,0.500303905993537,0.8823529362456748,0.799999995128,0.8823529362456748
AQ0279,What are the models that have been benchmarked on the Atari 2600 Road Runner dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Road Runner"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","An error occurred (check API key and internet connection): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",0,0.043478260869565216,0.023809523809523808,0.030769230769230767,0.0036256430206172588,0.002188794544348965,0.04999999500000051,0.0,0.04999999500000051
AQ0281,Can you list the models that have been evaluated on the Atari 2600 Boxing dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""Atari 2600 Boxing"" .
  ?benchmark orkgp:HAS_DATASET ?dataset ;
             orkgp:HAS_EVALUATION ?eval .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.8292682926829268,0.9066666666666667,0.7003024357140573,0.6038826780841631,0.8823529362456748,0.807692302810651,0.8823529362456748
AQ0762,What evaluation metrics are commonly used when benchmarking models on the WMT2014 French-English dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",1,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
AQ0329,Can you list the models that have been evaluated on the BUCC French-to-English dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC French-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""BUCC French-to-English"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.7380952380952381,0.8493150684931507,0.5708091457509625,0.4508270645273133,0.8571428522448981,0.7692307644156804,0.8571428522448981
AQ2081,Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (single model) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","An error occurred (check API key and internet connection): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",0,0.08695652173913043,0.05128205128205128,0.06451612903225808,0.004912353895221348,0.002493745353811474,0.09756097061273078,0.0,0.048780482807852986
AQ0233,What models are being evaluated on the AESLC dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AESLC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""AESLC"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:USES_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.9642857142857143,0.6923076923076923,0.8059701492537313,0.49444315977667824,0.3780701048055324,0.7999999950888891,0.6808510590131281,0.7999999950888891
AQ0645,What are the titles and IDs of research papers that include a benchmark for the HoC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""HoC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R125976 .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:P31 ?contribution .
  ?paper rdfs:label ?title .
}",0,0.9166666666666666,0.6875,0.7857142857142857,0.5233883656885842,0.37532592458627057,0.7857142807397959,0.7142857093877552,0.7857142807397959
AQ2176,Where can I find code references in papers that have used the PAR Transformer Large model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PAR Transformer Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model rdfs:label ""PAR Transformer Large"" .
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_BENCHMARK ?benchmark .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8235294068339101
AQ2060,Can you provide links to code used in papers that benchmark the BERTwwm + SQuAD 2 model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BERTwwm + SQuAD 2"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
    ?model rdfs:label ""BERTwwm + SQuAD 2"" .
    ?contribution orkgp:HAS_MODEL ?model .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7222222222222222,0.8387096774193548,0.5743071776715343,0.4735390597032246,0.8823529362456748,0.7499999951388889,0.8235294068339101
AQ1953,Provide a list of papers that have utilized the CL-Titles-Parser model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CL-Titles-Parser"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper_label ?code
WHERE {
  ?paper orkgp:HAS_MODEL orkgr:R224967 .
  ?paper orkgp:HAS_SOURCE_CODE ?code .
  ?paper rdfs:label ?paper_label .
}",0,0.9047619047619048,0.5277777777777778,0.6666666666666666,0.2571963658445966,0.1087870354571007,0.6874999951757813,0.5777777730765433,0.5624999951757813
AQ0206,Could you provide a list of models that have been tested on the Habitat 2020 Object Nav test-std benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""Habitat 2020 Object Nav test-std""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:COMPARES_CONTRIBUTION ?contribution .
  ?contribution orkgp:P32 ?model .
  ?model rdfs:label ?model_lbl .
}",0,0.8529411764705882,0.6590909090909091,0.7435897435897436,0.4035228953330251,0.24038348935918724,0.7142857092970523,0.5762711815110602,0.7142857092970523
AQ0235,What models are being evaluated on the Atari 2600 Name This Game dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Name This Game"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_label
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124928 .
    ?benchmark orkgp:COMPARE_CONTRIBUTION ?contribution .
    ?contribution orkgp:P32 ?model .
    ?model rdfs:label ?model_label .
}",0,0.7916666666666666,0.4418604651162791,0.5671641791044777,0.230561771018221,0.12945400493719114,0.5142857094857144,0.4313725443444829,0.5142857094857144
AQ1285,"What is the highest benchmark result achieved on the Atari 2600 Freeway dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?metric_lbl (MAX(?value) AS ?score)
WHERE {
    ?benchmark orkgp:HAS_DATASET orkgr:R124971 .
    ?benchmark orkgp:HAS_EVALUATION ?eval .
    ?eval orkgp:HAS_VALUE ?value .
    ?eval orkgp:HAS_METRIC ?metric .
    ?metric rdfs:label ?metric_lbl .
}
GROUP BY ?metric_lbl
ORDER BY DESC(?score)
LIMIT 1",0,0.9024390243902439,0.5068493150684932,0.6491228070175438,0.34278926580426755,0.25320609252893406,0.7083333284114585,0.6835442989777281,0.6666666617447917
AQ0250,Could you provide a list of models that have been tested on the Atari 2600 River Raid benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 River Raid"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model_label
WHERE {
  VALUES ?dataset { orkgr:R124965 }
  ?evaluation orkgp:HAS_DATASET ?dataset .
  ?evaluation orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_label .
}",0,0.8636363636363636,0.4523809523809524,0.59375,0.26494441945256364,0.19084278388222087,0.6060606012855833,0.5306122402498961,0.6060606012855833
AQ2221,"Provide a list of papers that have utilized the AlexNet, MultiGrasp model and include the links to their code?","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AlexNet, MultiGrasp"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code WHERE {
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ""AlexNet, MultiGrasp"" .
    ?contribution orkgp:HAS_SOURCE_CODE ?code .
    ?paper orkgp:hasContribution ?contribution .
}",0,0.96,0.6857142857142857,0.7999999999999999,0.39950093272945103,0.21328365101133978,0.8124999950781252,0.6521739081947071,0.6874999950781251
AQ0240,Can you list the models that have been evaluated on the Atari 2600 Ms. Pacman dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Ms. Pacman"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset rdfs:label ""Atari 2600 Ms. Pacman"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?paper orkgp:HAS_BENCHMARK ?benchmark .
  ?paper orkgp:HAS_MODEL ?model .
  ?model rdfs:label ?model_lbl .
}",0,1.0,0.7380952380952381,0.8493150684931507,0.5708091457509625,0.4508270645273133,0.8571428522448981,0.7692307644156804,0.8571428522448981
AQ0892,What evaluation metrics are commonly used when benchmarking models on the Habitat 2020 Object Nav test-std dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT ?metric_label (COUNT(DISTINCT ?benchmark) AS ?count)
WHERE {
  ?dataset rdfs:label ""Habitat 2020 Object Nav test-std""^^xsd:string .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_label .
}
GROUP BY ?metric_label
ORDER BY DESC(?count)",0,0.7555555555555555,0.8717948717948718,0.8095238095238095,0.49042352723099636,0.30952380952380953,0.7391304298204161,0.5970149204009801,0.7391304298204161
AQ1216,What is the top benchmark score and its metric on the BC5CDR-disease dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_lbl
WHERE {
  ?benchmark orkgp:HAS_DATASET orkgr:R122954 .
  orkgr:R122954 rdfs:label ""BC5CDR-disease"" .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:HAS_VALUE ?score .
  ?eval orkgp:HAS_METRIC ?metric .
  ?metric rdfs:label ?metric_lbl .
}
ORDER BY DESC(xsd:double(?score))
LIMIT 1",0,0.813953488372093,0.4861111111111111,0.6086956521739131,0.3406974776011568,0.26746257712212534,0.666666661701389,0.5454545406442908,0.666666661701389
AQ0778,List the metrics that are used to evaluate models on the ImageNet 64x64 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric_label
WHERE {
  ?dataset rdfs:label ""ImageNet 64x64"" .
  ?benchmark orkgp:HAS_DATASET ?dataset .
  ?benchmark orkgp:HAS_EVALUATION ?evaluation .
  ?evaluation orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_label .
}",0,0.9629629629629629,0.7428571428571429,0.8387096774193549,0.450561997367229,0.24785569306863545,0.7999999950888891,0.6956521690642723,0.7999999950888891
AQ0635,List the title and ID of research papers that contain a benchmark over the DBpedia dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DBpedia"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?title
WHERE {
  ?paper a orkgc:Paper ;
         rdfs:label ?title ;
         orkgp:P31 ?benchmark .
  ?benchmark a orkgc:Benchmark ;
             orkgp:P44054 ?dataset .
  ?dataset rdfs:label ""DBpedia"" .
}",0,0.875,0.65625,0.75,0.3479130156347995,0.17060269299375935,0.7857142807397959,0.5581395299513251,0.5714285664540818
AQ1994,Provide a list of papers that have utilized the HRLRE model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""HRLRE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?paper ?code
WHERE {
  VALUES ?model { orkgr:R116607 }
  ?contribution orkgp:HAS_MODEL ?model .
  ?contribution orkgp:HAS_SOURCE_CODE ?code .
  ?paper orkgp:P31 ?contribution .
}",0,0.8333333333333334,0.5882352941176471,0.6896551724137931,0.3397948785585557,0.18835446577155532,0.5999999950888889,0.4999999951652893,0.399999995088889
AQ2277,Can you provide links to code used in papers that benchmark the T-ConvS2S model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""T-ConvS2S"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model a orkgc:Model ;
         rdfs:label ""T-ConvS2S"" .
  ?contribution orkgp:HAS_MODEL ?model ;
                orkgp:HAS_BENCHMARK ?benchmark ;
                orkgp:HAS_SOURCE_CODE ?code .
}",0,1.0,0.7142857142857143,0.8333333333333333,0.6004729606571029,0.5179745810275395,0.9090909041322315,0.8085106334087823,0.9090909041322315
AQ1733,Which model has achieved the highest Score score on the Atari 2600 Q*Bert benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Q*Bert"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric rdfs:label ?metric_lbl .
  FILTER(STR(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset rdfs:label ""Atari 2600 Q*Bert""^^xsd:string .
      ?benchmark orkgp:HAS_DATASET ?dataset .
      ?benchmark orkgp:HAS_EVALUATION ?eval .
      ?eval orkgp:HAS_METRIC ?metric .
      ?eval orkgp:HAS_VALUE ?value .
      ?cont orkgp:HAS_BENCHMARK ?benchmark .
      ?cont orkgp:HAS_MODEL ?model .
      ?model rdfs:label ?model_lbl .
    }
    ORDER BY DESC(xsd:decimal(str(?value)))
    LIMIT 1
  }
}",0,0.927536231884058,0.927536231884058,0.927536231884058,0.7412815174711599,0.5757575757575758,0.9285714235778062,0.8275862018972124,0.8571428521492348
AQ1169,What is the top benchmark score and its metric on the Words in Context dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Words in Context"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT ?score ?metric_lbl
WHERE {
  orkgr:R120663 a orkgc:Dataset .
  ?benchmark orkgp:HAS_DATASET orkgr:R120663 .
  ?benchmark orkgp:HAS_EVALUATION ?eval .
  ?eval orkgp:P32 ?metric .
  ?metric rdfs:label ?metric_lbl .
  ?eval orkgp:P33 ?score .
}
ORDER BY DESC(xsd:decimal(?score))
LIMIT 1",0,0.7435897435897436,0.3972602739726027,0.5178571428571428,0.20967084758924512,0.12778341258365253,0.5416666617447917,0.4155844108281329,0.5416666617447917
AQ1864,List the datasets benchmarked under the Common Sense Reasoning research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Common Sense Reasoning"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset_lbl
WHERE {
    ?problem rdfs:label ""Common Sense Reasoning""^^xsd:string .
    ?contribution orkgp:P32 ?problem .
    ?contribution orkgp:HAS_BENCHMARK ?benchmark .
    ?benchmark orkgp:HAS_DATASET ?dataset .
    ?dataset rdfs:label ?dataset_lbl .
}",0,0.9333333333333333,0.7777777777777778,0.8484848484848485,0.4793443579512555,0.24258688980088353,0.823529406782007,0.69387754607247,0.647058818546713
AQ1087,What is the top benchmark result (metric and value) over the dataset ACE 2004?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2004"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset ;
                     rdfs:label       ?dataset_lbl .
      FILTER(STR(?dataset_lbl) = ""ACE 2004"")
      ?benchmark     orkgp:HAS_DATASET    ?dataset ;
                     orkgp:HAS_EVALUATION ?eval .
      ?eval          orkgp:HAS_VALUE      ?value .
      OPTIONAL {
        ?eval   orkgp:HAS_METRIC ?metric .
        ?metric rdfs:label       ?metric_lbl .
      }
      ?cont orkgp:HAS_BENCHMARK ?benchmark .
      OPTIONAL {
        ?cont  orkgp:HAS_MODEL ?model .
        ?model rdfs:label      ?model_lbl .
      }
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0,1.0,1.0,1.0,1.0,1.0,0.999999995,0.999999995,0.999999995
